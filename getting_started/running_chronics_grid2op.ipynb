{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will guide you through the use of the chronics you generated thorugh the Grid2op platform + display a quick analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>WARNING</b>: If you run <b>grid2op in a virtual env</b>, make sure that you either:\n",
    "    \n",
    "    - sourced your virtual env before launching jupyter: source v_env_chronix2grid/bin/activate\n",
    "    \n",
    "    - created an ipython kernel for this virtual env, and that you are actually running this kernerl now\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook uses the last version of grid2op. You can install it with:\n",
      "\t/Users/antoinemarot/dev/ChroniX2Grid/venv_chronix2grid/bin/python -m pip install grid2op\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antoinemarot/dev/ChroniX2Grid/venv_chronix2grid/lib/python3.6/site-packages/grid2op/Plot/EpisodeReplay.py:34: UserWarning:\n",
      "\n",
      "The final video will not be saved as \"imageio\" and \"imageio_ffmpeg\" packages cannot be imported. Please try \"/Users/antoinemarot/dev/ChroniX2Grid/venv_chronix2grid/bin/python -m pip install imageio imageio-ffmpeg\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline\n",
    "print(\"This notebook uses the last version of grid2op. You can install it with:\\n\"\\\n",
    "      \"\\t{} -m pip install grid2op\".format(sys.executable))\n",
    "import grid2op\n",
    "if grid2op.__version__ < \"0.6.0\":\n",
    "    raise RuntimeError(\"Impossible to run this notebook without grid2op version 0.6.0 installed.\")\n",
    "from grid2op.Chronics import ChangeNothing\n",
    "from grid2op.Plot import PlotMatplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "notebook_folder=%pwd\n",
    "root_dir = os.path.abspath(os.path.join( notebook_folder,'..'))\n",
    "\n",
    "# define your input folder\n",
    "INPUT_FOLDER = os.path.join(root_dir, 'input_data')\n",
    "\n",
    "OUTPUT_FOLDER = os.path.join(root_dir, 'output')\n",
    "\n",
    "# Detailed configuration to be set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "start_date = \"2012-01-01\"\n",
    "\n",
    "\n",
    "CASE = 'case118_l2rpn_wcci'\n",
    "path_case = os.path.join(INPUT_FOLDER, 'generation', CASE)\n",
    "grid_path = os.path.join(path_case, \"grid.json\")\n",
    "\n",
    "generation_output_folder=os.path.join(OUTPUT_FOLDER,'generation',CASE,start_date)#='{output_folder}/generation/{CASE}/{start_date}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I Create a Grid2op environment with the chronics this time\n",
    "\n",
    "This is to test the environment can be used by grid2op. This is what the \"case118_l2rpn\" will look like for the competitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/antoinemarot/dev/ChroniX2Grid/output/generation/case118_l2rpn_wcci/2012-01-01'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_output_folder #='{output_folder}/generation/{CASE}/{start_date}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You might need to install the LightSimBackend (provisory name) to gain massive speed up\n"
     ]
    }
   ],
   "source": [
    "from grid2op.Chronics import Multifolder, GridStateFromFileWithForecasts\n",
    "from grid2op.Parameters import Parameters\n",
    "try:\n",
    "    from lightsim2grid.LightSimBackend import LightSimBackend\n",
    "    backend = LightSimBackend()\n",
    "except:\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    backend = PandaPowerBackend()\n",
    "    print(\"You might need to install the LightSimBackend (provisory name) to gain massive speed up\")\n",
    "# don't disconnect powerline on overflow, the thermal limit are not set for now, it would not make sens\n",
    "param = Parameters()\n",
    "param.init_from_dict({\"NO_OVERFLOW_DISCONNECTION\": True})\n",
    "\n",
    "env = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                   grid_path=grid_path, # assign it the 118 grid\n",
    "                   chronics_class=Multifolder, # tell it to change nothing (not the most usable environment...)\n",
    "                   data_feeding_kwargs= {\n",
    "                       \"path\": os.path.abspath(generation_output_folder), \"gridvalueClass\": GridStateFromFileWithForecasts},\n",
    "                   param=param,\n",
    "                   backend=backend\n",
    "                  )\n",
    "# If you remove the \"GridStateFromFileWithForecasts\", from above, chronics will NOT be loaded properly.\n",
    "# GridStateFromFileWithForecasts is the format used for the competition, so it is mandatory that this works!\n",
    "# WITHOUT ANY MODIFICATIONS\n",
    "\n",
    "# Beside the environment should be able to load all data generated, and not one episode.\n",
    "# so please look in grid2op for compatible formats. This is not a valid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have all the chronics been loaded: True\n"
     ]
    }
   ],
   "source": [
    "print(\"Have all the chronics been loaded: {}\".format(len(env.chronics_handler.real_data.subpaths) == n_scenarios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set env thermal limit to 1 by default\n",
    "th_lim = np.ones(env.n_line, dtype=np.float)\n",
    "env.set_thermal_limit(th_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can test that we can use a Runner, store the results, and plot the flows on the powerline for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Run the Grid2op Runner\n",
    "\n",
    "For that we use a runner, that will compute the powerflows with a \"do nothing\" agent, and we prevent it to disconnect any power line, even if they are on overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Runner import Runner\n",
    "import tempfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path_data_saved = os.path.join(os.path.abspath(os.path.join(generation_output_folder, os.pardir)), 'agent_results')#, scenario_name)\n",
    "os.makedirs(path_data_saved, exist_ok=True)\n",
    "\n",
    "nb_episode = 1#10\n",
    "NB_CORE = 1#4\n",
    "# nb_episode = n_scenarios\n",
    "#nb_steps = 400\n",
    "runner = Runner(**env.get_params_for_runner())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409fb1cebf294174a4120c8a9a59eac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='episode', max=1.0, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c9f3f5591794f959bfaa9e9f76b7895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='episode', max=16126.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here you might need to change \"nb_episode\" if you generated more than one scenario\n",
    "# this might really take some times... 4 mins per scenario per week [on one core]\n",
    "res = runner.run(nb_episode=nb_episode,nb_process=NB_CORE, path_save=path_data_saved, pbar=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mScenario_0\u001b[m\u001b[m                       dict_env_modification_space.json\r\n",
      "dict_action_space.json           dict_observation_space.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls $path_data_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/antoinemarot/dev/ChroniX2Grid/output/generation/case118_l2rpn_wcci/agent_results'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Study the results\n",
    "## Load the flow, prod and load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.EpisodeData import EpisodeData\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_this_episode = EpisodeData.from_disk(path_data_saved, 'Scenario_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/antoinemarot/dev/ChroniX2Grid/output/generation/case118_l2rpn_wcci/agent_results'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_data_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_a = pd.DataFrame(np.array([obs.a_or for obs in data_this_episode.observations]))\n",
    "loads_p = pd.DataFrame(np.array([obs.load_p for obs in data_this_episode.observations]))\n",
    "prods_p = pd.DataFrame(np.array([obs.prod_p for obs in data_this_episode.observations]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize energy losses & productions over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16127.000000\n",
       "mean         0.015704\n",
       "std          0.001630\n",
       "min          0.012483\n",
       "25%          0.014593\n",
       "50%          0.015452\n",
       "75%          0.016470\n",
       "max          0.024443\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ProdTotal=prods_p.sum(axis=1)\n",
    "ConsoTotal=loads_p.sum(axis=1)\n",
    "Pertes=(ProdTotal-ConsoTotal)/ConsoTotal\n",
    "\n",
    "tauxDePerte=Pertes.mean()\n",
    "Pertes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "TotalLossesRatio=pd.DataFrame(np.array([(np.sum(obs.prod_p)-np.sum(obs.load_p))/np.sum(obs.load_p) for obs in data_this_episode.observations]))\n",
    "\n",
    "\n",
    "print('average loss rate is: '+ str(TotalLossesRatio.mean()))\n",
    "TotalLossesRatio.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses above 3.5 / 4% might be a sign that productions were not well located with respect to loads given the grid design. In real-life in such cases, you would build some new lines to reduce the losses with are usually around 2% for High Voltage grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Productions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prods_p.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_idx = [i for i in range(len(env.gen_type)) if env.gen_type[i] == 'nuclear'] \n",
    "hydro_idx = [i for i in range(len(env.gen_type)) if env.gen_type[i] == 'hydro']\n",
    "thermal_idx = [i for i in range(len(env.gen_type)) if env.gen_type[i] == 'thermal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colnames_p=prods_p.columns.values\n",
    "prods_p_perType=pd.DataFrame()\n",
    "prods_p_perType['nuclear']=prods_p[colnames_p[nuclear_idx]].sum(axis=1)\n",
    "prods_p_perType['hydro']=prods_p[colnames_p[hydro_idx]].sum(axis=1)\n",
    "prods_p_perType['thermal']=prods_p[colnames_p[thermal_idx]].sum(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prods_p_perType[['nuclear','hydro','thermal']].iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to **getting_started_api notebook** if results are not satisfying to regenerate new chronics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
