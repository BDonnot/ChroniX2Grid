{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook will guide you through the use of the chronix2grid API. You'll be able to separately generate loads, renewable productions and the corresponding dispatch of the other generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook uses the last version of grid2op. You can install it with:\n",
      "\t/home/vrenault/Projects/ChroniX2Grid/venv_test/bin/python -m pip install grid2op\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vrenault/Projects/ChroniX2Grid/venv_test/lib/python3.6/site-packages/grid2op/Plot/EpisodeReplay.py:34: UserWarning:\n",
      "\n",
      "The final video will not be saved as \"imageio\" and \"imageio_ffmpeg\" packages cannot be imported. Please try \"/home/vrenault/Projects/ChroniX2Grid/venv_test/bin/python -m pip install imageio imageio-ffmpeg\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import cufflinks as cf\n",
    "\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.offline\n",
    "print(\"This notebook uses the last version of grid2op. You can install it with:\\n\"\\\n",
    "      \"\\t{} -m pip install grid2op\".format(sys.executable))\n",
    "import grid2op\n",
    "if grid2op.__version__ < \"0.6.0\":\n",
    "    raise RuntimeError(\"Impossible to run this notebook without grid2op version 0.6.0 installed.\")\n",
    "from grid2op.Chronics import ChangeNothing\n",
    "from grid2op.Plot import PlotMatplotlib\n",
    "\n",
    "import chronix2grid.generation.generate_chronics as gen\n",
    "import chronix2grid.generation.generation_utils as gu\n",
    "import chronix2grid.generation.consumption.generate_load as gen_loads\n",
    "import chronix2grid.generation.renewable.generate_solar_wind as gen_enr\n",
    "import chronix2grid.generation.dispatch.generate_dispatch as gen_dispatch\n",
    "import chronix2grid.generation.dispatch.utils as du\n",
    "import chronix2grid.generation.dispatch.EconomicDispatch as ec\n",
    "from chronix2grid.generation.dispatch.EDispatch_L2RPN2020 import run_economic_dispatch\n",
    "import chronix2grid.kpi.main as kpis\n",
    "from chronix2grid.main import create_directory_tree\n",
    "import chronix2grid.constants as cst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_kpis = True  # The computation of KPIs can take some time...\n",
    "seed_reproducible = True  # Make sure to use the same seeds to reproduce results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "root_dir = %pwd\n",
    "\n",
    "# define your input folder\n",
    "INPUT_FOLDER = os.path.join(root_dir, os.pardir, 'input_data')\n",
    "OUPTUT_FOLDER = os.path.join(root_dir, os.pardir, 'output')\n",
    "# Detailed configuration to set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "start_date = \"2012-07-01\"\n",
    "weeks = 4\n",
    "n_scenarios = 2\n",
    "\n",
    "## Generation step of chronix2grid\n",
    "\n",
    "CASE = 'case118_l2rpn_wcci'\n",
    "path_case = os.path.join(INPUT_FOLDER, 'generation', CASE)\n",
    "grid_path = os.path.join(path_case, \"L2RPN_2020_case118_redesigned.json\")\n",
    "\n",
    "generation_output_folder, kpi_output_folder = create_directory_tree(\n",
    "    CASE, start_date, OUPTUT_FOLDER, cst.SCENARIO_FOLDER_BASE_NAME, n_scenarios, \n",
    "    'LRTK', warn_user=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env118_withoutchron = grid2op.make(\n",
    "    \"blank\",  # to generate a blank environment\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Energy Mix apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: the differences in your target energy mix and you energy mix a priori are: 18.928571428571434%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_energy_mix</th>\n",
       "      <th>pmax</th>\n",
       "      <th>capacity_mix</th>\n",
       "      <th>capacity_factor</th>\n",
       "      <th>Apriori_energy_mix</th>\n",
       "      <th>revised_pmax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>solar</th>\n",
       "      <td>4</td>\n",
       "      <td>746.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.998571</td>\n",
       "      <td>746.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wind</th>\n",
       "      <td>6</td>\n",
       "      <td>672.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>672.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nuclear</th>\n",
       "      <td>35</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>95.0</td>\n",
       "      <td>40.714286</td>\n",
       "      <td>1031.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hydro</th>\n",
       "      <td>15</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>23.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>1400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thermal</th>\n",
       "      <td>40</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.537143</td>\n",
       "      <td>3168.421053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target_energy_mix    pmax  capacity_mix  capacity_factor  \\\n",
       "solar                    4   746.4          10.0             15.0   \n",
       "wind                     6   672.0           9.0             25.0   \n",
       "nuclear                 35  1200.0          16.1             95.0   \n",
       "hydro                   15  1750.0          23.4             30.0   \n",
       "thermal                 40  3100.0          41.5              NaN   \n",
       "\n",
       "         Apriori_energy_mix  revised_pmax  \n",
       "solar              3.998571    746.666667  \n",
       "wind               6.000000    672.000000  \n",
       "nuclear           40.714286   1031.578947  \n",
       "hydro             18.750000   1400.000000  \n",
       "thermal           30.537143   3168.421053  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run ../chronix2grid/kpi/Generator_parameter_checker.py\n",
    "Target_EM_percentage=pd.DataFrame(data=[4,6,35,15,40],columns=['target_energy_mix'],\n",
    "                                  index=['solar','wind','nuclear','hydro','thermal'])\n",
    "\n",
    "PeakLoad = 4200\n",
    "AverageLoad = 2800\n",
    "    \n",
    "CapacityFactor=pd.DataFrame(data=[15,25,95,30,np.nan],columns=['capacity_factor'],\n",
    "                            index=['solar','wind','nuclear','hydro','thermal'])\n",
    "Capacity_df=EnergyMix_AprioriChecker(env118_withoutchron,Target_EM_percentage, PeakLoad, AverageLoad, CapacityFactor )\n",
    "Capacity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Generate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can set generation configuration such as number of scenarios, start date, number of weeks, noise intensities, timestep... in INPUT_FOLDER/CASE/params.json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if seed_reproducible:\n",
    "    seeds = [181791698]  # for reproducibility - otherwise comment here and uncomment below\n",
    "else:\n",
    "    seeds = [np.random.randint(low=0, high=2**31) for _ in range(n_scenarios)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading parameters\n",
    "year, params, loads_charac, prods_charac, load_weekly_pattern, solar_pattern, params_opf_auto = \\\n",
    "    gu.read_all_configurations(weeks, start_date, CASE, os.path.join(INPUT_FOLDER, 'generation'), \n",
    "                               generation_output_folder)\n",
    "print(year)\n",
    "\n",
    "scen_name_generator = gu.folder_name_pattern(cst.SCENARIO_FOLDER_BASE_NAME, n_scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II A) Generate loads and renewables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separate generation for load and renewables\n",
    "\n",
    "# Launch load generation\n",
    "for i, seed in enumerate(seeds):\n",
    "    scenario_name = scen_name_generator(i)\n",
    "    scenario_folder_path = os.path.join(generation_output_folder, scenario_name)\n",
    "    print(\"================ Generating scenario number \"+str(i)+\" ================\")\n",
    "    load, load_forecasted = gen_loads.main(scenario_folder_path, seed, params, loads_charac, \n",
    "                                           load_weekly_pattern, write_results = True)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check load hypothesis (peak and average)\n",
    "\n",
    "**if this differs by too much, you should update the computation of the Energy Mix a priori and revise some calibration if not satisfactory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentPeakLoad = load.sum(axis=1).max()\n",
    "print('the expected peak load was: ' + str(PeakLoad))\n",
    "print('the actual peak load is: ' + str(CurrentPeakLoad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentAverageLoad = load.sum(axis=1).mean()\n",
    "print('the expected average load was: ' + str(AverageLoad))\n",
    "print('the actual average load is: ' + str(CurrentAverageLoad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Renewables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Launch solar and wind generation\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(\"================ Generating scenario number \"+str(i)+\" ================\")\n",
    "    \n",
    "    scenario_name = scen_name_generator(i)\n",
    "    scenario_folder_path = os.path.join(generation_output_folder, scenario_name)\n",
    "    \n",
    "    prod_solar, prod_solar_forecasted, prod_wind, prod_wind_forecasted = gen_enr.main(\n",
    "        scenario_folder_path, seed, params, prods_charac, solar_pattern, write_results = True)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(solar_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Ramps and Pmin/Pmax Generator parameters A priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": "true"
   },
   "source": [
    "### Select the scenario you want to check first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ../chronix2grid/kpi/Generator_parameter_checker.py\n",
    "\n",
    "losses_pct = params_opf_auto[\"losses_pct\"]  # losses as pct of load\n",
    "[isThermalInTrouble, isNuclearInTrouble, IsRampUpInTrouble, IsRampDownInTrouble] = Ramps_Pmax_Pmin_APrioriCheckers(\n",
    "    env118_withoutchron, Capacity_df, generation_output_folder, losses_pct, PeakLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are the thermal reactors \\\"in trouble\\\": {}\".format(isThermalInTrouble))\n",
    "print(\"Are the nuclear reactors \\\"in trouble\\\": {}\".format(isNuclearInTrouble))\n",
    "print(\"Are the ramp up \\\"in trouble\\\": {}\".format(IsRampUpInTrouble))\n",
    "print(\"Are the ramp down \\\"in trouble\\\": {}\".format(IsRampDownInTrouble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../chronix2grid/kpi/Generator_parameter_checker.py\n",
    "Aposteriori_renewableCapacityFactor_Checkers(env118_withoutchron, Capacity_df, generation_output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute some KPIs for solar, wind and load only\n",
    "\n",
    "#### Benchmark \"France\" is set as reference in INPUT_FOLDER/kpi/paramsKPI.json\n",
    "Images are saved in OUTPUT_FOLDER/kpi/CASE/start_date/SCENARIO/images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you just want to save a lot of plots without showing it, uncomment this line.\n",
    "# If you want to compute more than 1 scenario, it is recommended not to show the plots on notebook\n",
    "#%%capture\n",
    "if compute_kpis:\n",
    "    # Chose number of scenarios to compute KPIs (it can be long to compute it for a lot of scenarios)\n",
    "    n_scenarios_kpis = 1\n",
    "\n",
    "    # Computation\n",
    "    wind_solar_only = True\n",
    "    scenario_names = gu.folder_name_pattern(cst.SCENARIO_FOLDER_BASE_NAME, n_scenarios_kpis)\n",
    "    kpis.main(os.path.join(INPUT_FOLDER, cst.KPI_FOLDER_NAME), generation_output_folder,\n",
    "              scenario_names, kpi_output_folder, year, CASE,\n",
    "              n_scenarios_kpis, wind_solar_only, params, loads_charac, prods_charac, scenario_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II B) Run an economic dispatch \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to install the solver that pypsa is calling. For instance cbc solver. On Fedora do `dnf install coin-or-Cbc.x86_64`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create The EconomicDispatch instance : a high level wrapper around a Pypsa net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher = ec.Dispatcher.from_gri2op_env(env118_withoutchron)\n",
    "dispatcher.modify_marginal_costs({'hydro': 36})\n",
    "dispatcher.read_hydro_guide_curves(os.path.join(INPUT_FOLDER, 'generation/patterns', 'hydro_french.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher.plot_ramps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispatch Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overwrite the params_opf_auto dictionary\n",
    "\n",
    "losses_pct = 1.0\n",
    "DispatchByCarrierOnly=False\n",
    "\n",
    "params_opf = {\n",
    "    'step_opf_min': 5,\n",
    "    'mode_opf': 'month',\n",
    "    'reactive_comp': 1.0,\n",
    "    'losses_pct': losses_pct,\n",
    "    'dispatch_by_carrier': DispatchByCarrierOnly,\n",
    "    'pyomo': False,\n",
    "    'solver_name': 'cbc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run opf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for scenario_name in os.listdir(generation_output_folder):\n",
    "\n",
    "    if scenario_name in ['.DS_Store']:\n",
    "        continue\n",
    "\n",
    "    scenario_folder_path = os.path.join(generation_output_folder, scenario_name)\n",
    "    print(scenario_folder_path)\n",
    "    dispatcher.read_load_and_res_scenario(os.path.join(scenario_folder_path, 'load_p.csv.bz2'),\n",
    "                                        os.path.join(scenario_folder_path, 'prod_p.csv.bz2'),\n",
    "                                        scenario_name=scenario_name)\n",
    "    hydro_constraints = dispatcher.make_hydro_constraints_from_res_load_scenario()\n",
    "    agg_load_without_renew = dispatcher.net_load(losses_pct, name=dispatcher.loads.index[0])\n",
    "\n",
    "    # Example of how to extract info on the largest ramps\n",
    "    print(f'5 largest ramps reached by the agg_load_without_renew:')\n",
    "    print(dispatcher.nlargest_ramps(5, losses_pct))\n",
    "\n",
    "    # Run Economic Disptach using submodule EDisptach_L2RPN_2020\n",
    "    # **  **  **  **  **  **  **  **  **  **  **  **  **  **\n",
    "    dispatch_results = dispatcher.run(\n",
    "        agg_load_without_renew,\n",
    "        params=params_opf,\n",
    "        gen_constraints=hydro_constraints,\n",
    "        ramp_mode=run_economic_dispatch.RampMode.hard,\n",
    "        by_carrier=DispatchByCarrierOnly,  # True to run the dispatch only aggregated generators by carrier,\n",
    "        pyomo=False,\n",
    "        solver_name='cbc'\n",
    "    )\n",
    "\n",
    "    chronix_scenario = dispatch_results.chronix\n",
    "\n",
    "    # save prods chronics\n",
    "    dispatcher.save_results(params, scenario_folder_path)\n",
    "\n",
    "# TODO if there are failures, write it somewhere, for now it's only detected in the very verbose output cell.\n",
    "# for example you can do a report at the end 'looking like failures for scenariis xxx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chronix_scenario is an object containing all the time series related to the studied scenario : \n",
    "- chronix_scenario.name gives the name of the scenario\n",
    "- chronix_scenario.wind_p (resp. solar_p, prods_dispatch, loads, marginal_prices) gives the Wind DataFrame (resp. Solar, Dispatched generators, loads, marginal_prices)\n",
    "\n",
    "This object should be manipulated in the sequel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below (up until the kpis) will  not run if  run_automated_dispatch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the max net load is similar than after generating loads and renewables\n",
    "agg_load_without_renew.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the slcack bus generation for case 118\n",
    "#dispatch_results.chronix.prods_dispatch['gen_68_37'].iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check That Pypsa does not violate the ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsRamps=dispatch_results.chronix.prods_dispatch.diff().describe()\n",
    "maxRamps=StatsRamps.loc['max']\n",
    "maxRamps[maxRamps>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_names=list(env118_withoutchron.name_gen)\n",
    "matchIDs=[gen_names.index(el) for el in list(StatsRamps)]\n",
    "gen_ramps=env118_withoutchron.gen_max_ramp_up[matchIDs]\n",
    "gen_subIds=env118_withoutchron.gen_to_subid[matchIDs]\n",
    "\n",
    "RampsToHigh=((maxRamps>gen_ramps).values & (gen_ramps!=0))\n",
    "print('\\n generation above their max rated ramps')\n",
    "print(gen_subIds[RampsToHigh])\n",
    "print('\\n max ramps in environement for generation above their max rated ramps')\n",
    "print(pd.DataFrame(gen_ramps,index=list(StatsRamps)).loc[RampsToHigh])\n",
    "print('\\n max ramps after pypsa')\n",
    "print(maxRamps[RampsToHigh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that very high ramps happen when switching months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ramps=dispatch_results.chronix.prods_dispatch.diff()\n",
    "Ramps.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate renewable dispatch\n",
    "\n",
    "#Becareful:check years of opf_dispatch and dispatch\n",
    "print(chronix_scenario.wind_p.index[0])\n",
    "print(chronix_scenario.prods_dispatch.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(chronix_scenario.wind_p.index[0] != chronix_scenario.prods_dispatch.index[0]):\n",
    "    chronix_scenario.prods_dispatch.index=chronix_scenario.wind_p.index\n",
    "if DispatchByCarrierOnly:\n",
    "    chronix_scenario.prods_dispatch=chronix_scenario.prods_dispatch[['nuclear','hydro','thermal']]#makesure nuclear comesfirst, for good plotting after\n",
    "\n",
    "full_opf_dispatch = pd.concat(\n",
    "    [chronix_scenario.prods_dispatch, chronix_scenario.wind_p, chronix_scenario.solar_p],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Keep same order as grid2op\n",
    "if not DispatchByCarrierOnly:\n",
    "    full_opf_dispatch = full_opf_dispatch[env118_withoutchron.name_gen].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DispatchByCarrierOnly:\n",
    "    nuclear_names = dispatcher.generators[dispatcher.generators.carrier == 'nuclear'].index\n",
    "    hydro_names = dispatcher.generators[dispatcher.generators.carrier == 'hydro'].index\n",
    "    thermal_names = dispatcher.generators[dispatcher.generators.carrier == 'thermal'].index\n",
    "\n",
    "    dispatch_by_fleet=pd.concat([ dispatcher.wind_p, dispatcher.solar_p], axis=1)\n",
    "    dispatch_by_fleet['nuclear'] = full_opf_dispatch[nuclear_names].sum(axis=1).to_frame('Nuclear')\n",
    "    dispatch_by_fleet['hydro'] = full_opf_dispatch[hydro_names].sum(axis=1)\n",
    "    dispatch_by_fleet['thermal'] = full_opf_dispatch[thermal_names].sum(axis=1)\n",
    "    #dispatch_by_fleet=pd.concat([dispatch_by_fleet, dispatch.wind_p, dispatch.solar_p], axis=1)\n",
    "\n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['thermal'] < 0, 'thermal'] = 0\n",
    "\n",
    "    # grid2op env starts in 2007 but read loads are in 2012...\n",
    "    #dispatch_by_fleet = dispatch_by_fleet.loc[dispatch_by_fleet.index.year == 2007,:]\n",
    "\n",
    "    dispatch_by_fleet.plot(figsize=(20, 8), title='Dispatch over 1 year', kind='area')\n",
    "\n",
    "else:\n",
    "    dispatch_by_fleet=full_opf_dispatch\n",
    "    \n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['thermal'] < 0, 'thermal'] = 0 #due to numeric approximation,some thermal values  could be negative\n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['hydro'] < 0, 'hydro'] = 0\n",
    "    #full_opf_dispatch[full_opf_dispatch['thermal']<0]['thermal'].hist()\n",
    "    dispatch_by_fleet.plot(figsize=(20, 8), title='Dispatch over 1 year', kind='area')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].plot(figsize=(20, 8), title='Dispatch over 1 year - no renewable', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekNumber=24\n",
    "dispatch_by_fleet.iloc[(288*7*WeekNumber):(288*7*(WeekNumber+1)), :].plot(figsize=(20, 8), title='Dispatch over 1 week', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].iloc[(288*7*WeekNumber):(288*7*(WeekNumber+1)), :].plot(figsize=(20, 8), title='Dispatch over 1 week - no renewable', kind='area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Hydro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In june, Hydro might be high and the minimum hydro production to respect forces nuclear to decrease its production\n",
    "if not(dispatch_by_fleet[['hydro']].sum().values==0):\n",
    "    minHydroPattern=dispatcher._min_hydro_pu\n",
    "    nCols=minHydroPattern.shape[1]\n",
    "    minHydroPattern.iloc[:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In june, Hydro might be high and the minimum hydro production to respect forces nuclear to decrease its production\n",
    "if not(dispatch_by_fleet[['hydro']].sum().values==0):\n",
    "    maxHydroPattern=dispatcher._max_hydro_pu\n",
    "    nCols=maxHydroPattern.shape[1]\n",
    "    maxHydroPattern.iloc[:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate whether they have same order\n",
    "np.all(full_opf_dispatch.columns == env118_withoutchron.name_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Energy Mix of Dispatch and capacity factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentAverageLoad=load.sum(axis=1).mean()\n",
    "dispatch_by_fleet[['nuclear','hydro','thermal']].mean()/CurrentAverageLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].mean()/dispatch_by_fleet[['nuclear','hydro','thermal']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have to set \"eco2mix\" as comparison in INPUT_FOLDER/kpi/paramsKPI.json\n",
    "**Images were not designed to be plot on a notebook but to be saved as png or zoomable in IMAGES_FOLDER**. In particular, yearly productions and energy mix are better to watch in their written files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "if compute_kpis:\n",
    "    wind_solar_only = False\n",
    "    n_scenarios_kpis = 1\n",
    "    scenario_names = gu.folder_name_pattern(cst.SCENARIO_FOLDER_BASE_NAME, n_scenarios_kpis)\n",
    "    kpis.main(os.path.join(INPUT_FOLDER, cst.KPI_FOLDER_NAME), generation_output_folder, \n",
    "              scenario_names, kpi_output_folder, year, CASE,\n",
    "              n_scenarios, wind_solar_only, params, loads_charac, prods_charac, scenario_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Html Link to jump here\n",
    "<a id='load_generated_chronics'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Create an environment with the chronics this time\n",
    "\n",
    "This is to test the environment can be used by grid2op. This is what the \"case118_l2rpn\" will look like for the competitions.\n",
    "\n",
    "**NB** The \"Balthazar code\" is fully compatible with the \"GridStateFromFileWithForecasts\". So it is useful to use this class to load back the data. If the data generation process does not provide the same utilities, it is not a problem to write another class, like \"GridStateFromFileWithForecasts\" that can read its format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the bug in element 7_4_173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO YOU SHOULD NOT DO THAT BUT BE ABLE TO RUN ALL SCENARIOS IN THE RUNNER.\n",
    "\n",
    "# Chose generated scenario\n",
    "# scenario = 'Scenario_15'\n",
    "# scenario_path = os.path.join(OUTPUT_FOLDER, str(year), scenario)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_output_folder #='{output_folder}/generation/{CASE}/{start_date}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from grid2op.Chronics import Multifolder, GridStateFromFileWithForecasts\n",
    "from grid2op.Parameters import Parameters\n",
    "try:\n",
    "    from lightsim2grid.LightSimBackend import LightSimBackend\n",
    "    backend = LightSimBackend()\n",
    "except:\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    backend = PandaPowerBackend()\n",
    "    print(\"You might need to install the LightSimBackend (provisory name) to gain massive speed up\")\n",
    "# don't disconnect powerline on overflow, the thermal limit are not set for now, it would not make sens\n",
    "param = Parameters()\n",
    "param.init_from_dict({\"NO_OVERFLOW_DISCONNECTION\": True})\n",
    "\n",
    "env = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                   grid_path=grid_path, # assign it the 118 grid\n",
    "                   chronics_class=Multifolder, # tell it to change nothing (not the most usable environment...)\n",
    "                   data_feeding_kwargs= {\n",
    "                       \"path\": os.path.abspath(generation_output_folder), \"gridvalueClass\": GridStateFromFileWithForecasts},\n",
    "                   param=param,\n",
    "                   backend=backend\n",
    "                  )\n",
    "# If you remove the \"GridStateFromFileWithForecasts\", from above, chronics will NOT be loaded properly.\n",
    "# GridStateFromFileWithForecasts is the format used for the competition, so it is mandatory that this works!\n",
    "# WITHOUT ANY MODIFICATIONS\n",
    "\n",
    "# Beside the environment should be able to load all data generated, and not one episode.\n",
    "# so please look in grid2op for compatible formats. This is not a valid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Have all the chronics been loaded: {}\".format(len(env.chronics_handler.real_data.subpaths) == n_scenarios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set env thermal limit to 1 by default\n",
    "th_lim = np.ones(env.n_line, dtype=np.float)\n",
    "env.set_thermal_limit(th_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can test that we can use a Runner, store the results, and plot the flows on the powerline for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Validate the generation process\n",
    "\n",
    "For that we use a runner, that will compute the powerflows with a \"do nothing\" agent, and we prevent it to disconnect any power line, even if they are on overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Runner import Runner\n",
    "import tempfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path_data_saved = os.path.join(os.path.abspath(os.path.join(generation_output_folder, os.pardir)), 'agent_results')#, scenario_name)\n",
    "os.makedirs(path_data_saved, exist_ok=True)\n",
    "\n",
    "nb_episode = 1#10\n",
    "NB_CORE = 1#4\n",
    "# nb_episode = n_scenarios\n",
    "#nb_steps = 400\n",
    "runner = Runner(**env.get_params_for_runner())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you might need to change \"nb_episode\" if you generated more than one scenario\n",
    "# this might really take some times... 4 mins per scenario per week [on one core]\n",
    "res = runner.run(nb_episode=nb_episode,nb_process=NB_CORE, path_save=path_data_saved, pbar=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls $path_data_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can study the results, for example by loading the chronics, extracting prod p, load p etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.EpisodeData import EpisodeData\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_this_episode = EpisodeData.from_disk(path_data_saved, 'Scenario_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_a = pd.DataFrame(np.array([obs.a_or for obs in data_this_episode.observations]))\n",
    "loads_p = pd.DataFrame(np.array([obs.load_p for obs in data_this_episode.observations]))\n",
    "prods_p = pd.DataFrame(np.array([obs.prod_p for obs in data_this_episode.observations]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check losses & prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProdTotal=prods_p.sum(axis=1)\n",
    "ConsoTotal=loads_p.sum(axis=1)\n",
    "Pertes=(ProdTotal-ConsoTotal)/ConsoTotal\n",
    "\n",
    "tauxDePerte=Pertes.mean()\n",
    "Pertes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TotalLossesRatio=pd.DataFrame(np.array([(np.sum(obs.prod_p)-np.sum(obs.load_p))/np.sum(obs.load_p) for obs in data_this_episode.observations]))\n",
    "\n",
    "\n",
    "print('average loss rate is: '+ str(TotalLossesRatio.mean()))\n",
    "TotalLossesRatio.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prods_p.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_idx = [i for i in range(len(env.gen_type)) if env.gen_type[i] == 'nuclear'] \n",
    "hydro_idx = [i for i in range(len(env.gen_type)) if env.gen_type[i] == 'hydro']\n",
    "thermal_idx = [i for i in range(len(env.gen_type)) if env.gen_type[i] == 'thermal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colnames_p=prods_p.columns.values\n",
    "prods_p_perType=pd.DataFrame()\n",
    "prods_p_perType['nuclear']=prods_p[colnames_p[nuclear_idx]].sum(axis=1)\n",
    "prods_p_perType['hydro']=prods_p[colnames_p[hydro_idx]].sum(axis=1)\n",
    "prods_p_perType['thermal']=prods_p[colnames_p[thermal_idx]].sum(axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods_p_perType[['nuclear','hydro','thermal']].iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R3 zone load and production balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = env118_withoutchron.backend._grid\n",
    "\n",
    "load_p_with_names = loads_p.copy()\n",
    "load_p_with_names.columns = data_this_episode.load_names\n",
    "# Sort same order as net\n",
    "load_p_with_names = load_p_with_names[net.load.name]\n",
    "\n",
    "prods_p_with_names = prods_p.copy()\n",
    "prods_p_with_names.columns = data_this_episode.prod_names\n",
    "# Sort same order as net\n",
    "prods_p_with_names = prods_p_with_names[net.gen.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'R3'\n",
    "\n",
    "prods_names = net.gen[net.gen.zone.isin([region])].name.tolist()\n",
    "loads_names = net.load[net.load.zone.isin([region])].name.tolist()\n",
    "\n",
    "agg_vals = pd.concat([prods_p_with_names[prods_names].sum(axis=1).to_frame(f'agg_prods_in_{region}'), \n",
    "                      load_p_with_names[loads_names].sum(axis=1).to_frame(f'agg_loads_in_{region}'),\n",
    "                      ], axis=1)\n",
    "\n",
    "agg_vals.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_mw = pd.DataFrame(np.array([obs.p_or for obs in data_this_episode.observations]))\n",
    "flows_mw.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexHighFlow=np.abs(flows_mw).max()[np.abs(flows_mw).max()>200].index\n",
    "np.abs(flows_mw).max()[np.abs(flows_mw).max()>200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(flows_mw).max()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.line_or_to_subid[indexHighFlow])\n",
    "print(env.line_ex_to_subid[indexHighFlow])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to **II)** if results are not satisfying."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
