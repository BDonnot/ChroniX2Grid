{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatize the generation of an Environment for Grid2op\n",
    "\n",
    "This notebook will automatize processes to generate an environment for the IEEE 118 grid using *grid2op*. It takes as an input a pre-processed cased and it will generate the respective environment to be used with grid2op.\n",
    "\n",
    "`case_full_grid_ieee_118 --> | run all notebook | --> subnet ENV grid2op`\n",
    "\n",
    "The input folder should contain the follwing:\n",
    "```\n",
    "|---case_full_grid_ieee_118\n",
    "    |--- config.py\n",
    "    |--- grid.json\n",
    "    |--- grid_layout.json\n",
    "    |--- loads_charac.csv\n",
    "    |--- prods_chatac.csv\n",
    "    |--- params.json\n",
    "    |--- params_opf.json\n",
    "```\n",
    "\n",
    "**Remainder** <br>\n",
    "**++ ++ ++ +** <br>\n",
    " - **It only works for now if you have generated the subgrid case** for grid2op (otherwise go through notebook subgrid_design.ipynb) and preferably for region R2 (not tested for the 2 others\n",
    "\n",
    " - **Make sure to have the right slack ids**\n",
    "\n",
    " - You need to have **a virtualEnv of Chronix2Grid installed** in Chronix2Grid_folder\n",
    "\n",
    " - If you change AWS machine type, you might need to **recompile lightSim2Grid**\n",
    " \n",
    " - Create virtualenv for Chronix2grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure and levels:\n",
    "```\n",
    "|---main_root\n",
    "    |---Chronix2grid\n",
    "    |   |---input_data\n",
    "    |   |   |---generation\n",
    "    |   |       |---case_runner_grid (full ieee 118 full grid)\n",
    "    |   |       |---case_subgrid\n",
    "    |   |--output_data\n",
    "    |---Grid2Op_Environment\n",
    "        |---case_subgrid\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes:\n",
    "\n",
    " - Parameters Configuration:\n",
    "   - number of scenarios\n",
    "   - number of cores\n",
    "   - chronix version (for data)\n",
    "   - subgrid to generate ENV {1, 2, 3}\n",
    "   - home directory or main_root\n",
    "   - Slack gen\n",
    " - Pre-process input case changing Pmax and Ramps\n",
    " \n",
    " 1) **Chronics Generation For Full IEEE 118** <br>\n",
    "   *(Run Economic Dispatch using Chronix2grid)* <br>\n",
    " 2) **Run the runner with the do nothing agent** <br>\n",
    "   *(Run Grid2op runner from Economic Dispatch results)* <br>\n",
    " 3) **Correct the slack bus chronic with it** <br>\n",
    "   *(Run sub-process to compensate slack gen)* <br>\n",
    " 4) **Create the subgrid chronics** <br>\n",
    "   *(Using Economic dispatch rel and runner agent, only* <br>\n",
    "   *specified subnet chronix are created)* <br>\n",
    " 4) **Run runner in subgrid chronics** <br>\n",
    "   *(Run Grid2op runner on subgrid chronics)* <br>\n",
    " 5) **Correct the slack bus chronic** <br>\n",
    "   *(Correct slack in subgrid chronic)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import shutil\n",
    "import psutil\n",
    "from glob import glob\n",
    "from chronix2grid.main import generate_mp_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--> specify Home directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chronix2Grid_directory='/Users/antoinemarot/ChroniX2Grid'\n",
    "#/Users/camiloromero/Rte/\"#/home/ubuntu/\n",
    "# home_directory = '/Users/camiloromero/Rte/'\n",
    "#home_directory = '/home/ubuntu/'\n",
    "home_directory = '/Users/antoinemarot/ChroniX2Grid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(Chronix2Grid_directory):\n",
    "    print('WARNING: you need to change your home directory '+home_directory+' which does not exist')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_config = {\n",
    "    'full_case_name': 'case118_l2rpn_icaps_2x',\n",
    "    'subgrid_case_name': 'ieee118_R2subgrid_icaps_2x',\n",
    "    'num_scenarios': 3,\n",
    "    'num_cores': 3,#psutil.cpu_count(logical=True),\n",
    "    'agent_rel_version': '1x',\n",
    "    'region': 2, \n",
    "    'mode_test': True,\n",
    "    'withseeds': True,\n",
    "    'path_read_seeds': os.path.join(Chronix2Grid_directory,\"tests/data/input/generation\",\"seeds_chronix2grid_118ieee.json\"),\n",
    "    'chronix_env_name': 'venv_chronix2grid',\n",
    "    'ref_chronix': os.path.join(Chronix2Grid_directory,\"input_data/generation\",\"case118_l2rpn_icaps_2x\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--> Replace the number of cores and scenarios**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace variables to initialize automated process in notebook\n",
    "n_scenarios = notebook_config['num_scenarios'] #number of scenarios to generate for each month\n",
    "nb_core = notebook_config['num_cores'] # number of cores on which to run the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--> Replace the name of your virtual env for chronix2grid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venv_chronix2grid_name = notebook_config['chronix_env_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--> Replace version data, subregion to generate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ChronixVersion = notebook_config['agent_rel_version'] #the version of the iteration we are doing for generating our environment\n",
    "subgrid_region = notebook_config['region']  #choose subgrid region betwen 1,2,3 for IEEE 118 subgrids\n",
    "\n",
    "#######\n",
    "ModeTest = notebook_config['mode_test'] #if Test notebook, this should be true, and everything will be run on 2 chronics over 2 months only to also test for multiprocess\n",
    "\n",
    "#######\n",
    "ModeRunnerWithSeeds = notebook_config['withseeds'] # Will generate Chronix with specific seed according the path specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**--> specify paths** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Specify Chronix2grid paths'''\n",
    "Chronix2Grid_folder=Chronix2Grid_directory#os.path.join(Chronix2Grid_directory, \"ChroniX2Grid\")\n",
    "Input_folder=os.path.join(Chronix2Grid_folder, \"input_data\") #chronix2grid input folder with necesaary patterns and grid case\n",
    "Ouput_folder=os.path.join(Chronix2Grid_folder, \"tests/data/output\") #output folder for chronics\n",
    "\n",
    "'''Specify Grid2Op_EnvironmentDesign path'''\n",
    "RunnerScriptFolder=os.path.join(Chronix2Grid_directory, \"getting_started\",\"scripts\")\n",
    "\n",
    "'''Specify full_ieee_118_grid and subgrid NAMES'''\n",
    "case_runner_grid = notebook_config['full_case_name']\n",
    "case_subgrid = notebook_config['subgrid_case_name']\n",
    "\n",
    "'''Specify output folder'''\n",
    "Ouput_folder_do_nothing=os.path.join(Chronix2Grid_folder, \"agent_results\" + \"_\" + ChronixVersion) #output folder when running the runner on chronics\n",
    "\n",
    "'''Specify path to read seeds'''\n",
    "seed_read_path = notebook_config['path_read_seeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridPath=os.path.join(Input_folder, 'generation', case_runner_grid)\n",
    "if not os.path.exists(gridPath):\n",
    "    print('WARNING: the grid folder '+gridPath+' does not exist, create it')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "venv_chronix2grid_path=os.path.join(Chronix2Grid_folder, venv_chronix2grid_name)\n",
    "if not os.path.exists(venv_chronix2grid_path):\n",
    "    print('WARNING: the chronix2grid virtual env folder '+venv_chronix2grid_path+' does not exist, create it')\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subgridPath=os.path.join(RunnerScriptFolder,case_subgrid)\n",
    "# if not os.path.exists(subgridPath):\n",
    "#     print('WARNING: the subgrid folder '+subgridPath+' does not exist, be sure to locate your subgrid folder there.' \\\n",
    "#           'If you have not yet created it, run the subgrid_design.ipynb first')\n",
    "#     raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Process is:\n",
    "    \n",
    "    Preliminaries: make sure you have the subgrid case created + create a modified case for the slack to run chroniX2Grid \n",
    "\n",
    "    1) Chronics Generation For Full IEEE 118\n",
    "        - move all chronics in a same folder \n",
    "        - duplicate the chronics folder to keep one origal and one that we will modify then\n",
    "    2) Run the runner with the do nothing agent\n",
    "        - we want to assess the residual losses that we did not account for in the chronix generation process\n",
    "    3) Correct the slack bus chronic with it\n",
    "        - so that no more compensation exists when we will run the chronix again, to avoid compensation making losse management negligeable to the amount of compensation\n",
    "    4) Create the subgrid chronics\n",
    "    5) Run the runner with the do nothing agent\n",
    "        - so that we are all set to analyze the environement and calibrate the thermal limits\n",
    "        \n",
    "    6) Last check to see that the slack does not need to compensate and be corrected anymore\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Preliminary - create a grid case with lower Pmax and Ramps if needed\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "This section may allow you to modify any input file that helps to create an environment in Grid2op and consequentently will affect the Economic Dispatch in the next process.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> \"This can directly be done now in params_opf.json\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the case that will be used for Chronix2Grid generation.\n",
    "\n",
    "This will allow for slack correction later on the real case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input_folder_case=os.path.join(Input_folder,\"generation\",case_runner_grid)\n",
    "case_chronix2grid_folder=os.path.join(Input_folder,\"generation\",case_runner_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod_caract_df=pd.read_csv(os.path.join(case_chronix2grid_folder,'prods_charac.csv'))\n",
    "prod_caract_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> Make sure that params_opf.json has those parameters: 'loss_grid2op_simulation': True, 'idxSlack': .., 'nameSlack': ..,   \"hydro_ramp_reduction_factor\":.., \"slack_p_max_reduction\":.., \"slack_ramp_max_reduction\":..,\n",
    "    \n",
    "    loss_grid2op_simulation will be used to adjust for the losses aposteriori\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "change slack and hydro ramps and pmax artificially within dedicated json parameters for better thermal dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json \n",
    "  \n",
    "# Opening JSON file \n",
    "filePath=os.path.join(case_chronix2grid_folder,'params_opf.json')\n",
    "f = open(filePath,) \n",
    "  \n",
    "# returns JSON object as  \n",
    "# a dictionary \n",
    "params_json = json.load(f) \n",
    "print(params_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change losses compensation (this should be below the minimal ratio of losses we will \n",
    "#see after running Grid2op on the chronics) \n",
    "#Otherwise it will lead to negative slack production\n",
    "#params_json['reactive_comp'] = 0.5\n",
    "#params_json['losses_pct'] = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#possible changes\n",
    "#for full grid\n",
    "#idxSlack=37\n",
    "#nameSlack='gen_68_37'\n",
    "\n",
    "#for subgrid\n",
    "#idxSlack_subgrid=21\n",
    "#nameSlack_subgrid='gen_35_21'#it has changed name in the subgrid\n",
    "\n",
    "#PmaxReduction=150\n",
    "#RampReduction=6\n",
    "#RampHydroReductionFactor=2\n",
    "\n",
    "with open(filePath, 'w') as f:\n",
    "    json.dump(params_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Chronics Generation For Full IEEE 118\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "Run Economic dispatch using Chronix2Grid.\n",
    "</div>\n",
    "\n",
    "It will create two folders:\n",
    "\n",
    "```\n",
    "|---main_root\n",
    "    |---Chronix2grid\n",
    "        |---{#scenarios}_years_chronics_{version} (1)\n",
    "        |---{#scenarios}_years_chronics_{version}_SlackCorrection (2)\n",
    "```\n",
    "\n",
    "Dir (1) will contain the results of the Economic Dispatch <br>\n",
    "Dir (2) will be created temporarily with the same result as dir (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code style=\"background:yellow;color:black\">\n",
    "Copy the full grid case in the output folder to create a full working environment in the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "orginalGridFolder=os.path.join(Input_folder,'generation',case_runner_grid)\n",
    "runnerCaseFolder=os.path.join(Ouput_folder,'generation')\n",
    "#workingGridFolder=os.path.join(RunnerScriptFolder,case_runner_grid)\n",
    "\n",
    "if os.path.exists(runnerCaseFolder):\n",
    "    print('delete folder before creating case in:'+runnerCaseFolder)\n",
    "    !rm -rf $workingGridFolder\n",
    "!cp -r $orginalGridFolder $runnerCaseFolder #to copy the content of a into b do \"cp -r a/. b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months=[\"january\",\"february\",\"march\",\"april\",\"may\",\"june\",\n",
    "        \"july\", \"august\", \"september\", \"october\", \"november\", \"december\"]\n",
    "#months=[\"november\",\"december\"]\n",
    "\n",
    "start_dates=[\"2012-01-01\", \"2012-02-01\", \"2012-03-01\", \"2012-04-01\", \"2012-05-01\", \"2012-06-01\",\n",
    "             \"2012-07-01\", \"2012-08-01\", \"2012-09-01\", \"2012-10-01\", \"2012-11-01\", \"2012-12-01\"]\n",
    "#start_dates=[\"2012-11-01\",\"2012-12-01\"]\n",
    "\n",
    "#os.chdir(\"ChroniX2Grid/chronix2grid\")\n",
    "os.chdir(Chronix2Grid_folder)\n",
    "#!source venv_chronix2grid/bin/activate "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read seed form path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = {}\n",
    "if ModeRunnerWithSeeds:  \n",
    "    with open(seed_read_path) as f:\n",
    "        seed = json.load(f)\n",
    "#if ModeRunnerWithSeeds and os.path.exists(seed_read_path):  \n",
    "#    for file in glob(os.path.join(seed_read_path, '*.json')):\n",
    "#        with open(file) as f:\n",
    "#            seed_file = json.load(f)\n",
    "#            month = os.path.basename(file).split('_')[0]\n",
    "#            # Fill seed\n",
    "#            seed[month] = {'loads': seed_file['loads'],\n",
    "#                           'renewables': seed_file['renewables'],\n",
    "#                           'dispatch': seed_file['dispatch'],\n",
    "#                          }\n",
    "#        \n",
    "#pprint(seed, width=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that loss asjustement with grid2Op is activated and check that lightsim2grid is installed for fast computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not params_json['loss_grid2op_simulation']:\n",
    "    print('activate loss adjustement in params_opf.json to generate proper chronics to be used with grid2op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lightsim2grid\n",
    "except ImportError as e:\n",
    "    print('lightsim2grid is not installed. You should install it for faster loss adjustement computation')  # module doesn't exist, deal with it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Execute command line to run economic dispatch\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> Chronix2grid virtualenv will be activated\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 4 weeks chronics for every month in the Chronix2grid virtual env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ModeTest:\n",
    "    print('we are in testing mode for the process of this notebook')\n",
    "    months=months[0:2]\n",
    "    start_dates=start_dates[0:2]\n",
    "    n_scenarios=2 #number of scenarios to generate for each month\n",
    "    if(nb_core>4):\n",
    "        nb_core=4\n",
    "    \n",
    "else:\n",
    "    print('we are in production mode for the process of this notebook, generating lots of chronics')\n",
    "    \n",
    "for i in range(len(months)):\n",
    "    month=months[i]\n",
    "    print(month)\n",
    "    start_date=start_dates[i]\n",
    "\n",
    "    #define your chronix2grid command line with your arguments\n",
    "    cli_activateVirtualEnv='. '+venv_chronix2grid_path+'/bin/activate'\n",
    "    \n",
    "    if ModeRunnerWithSeeds:\n",
    "        cli_chronix2grid=\"chronix2grid \\\n",
    "                         --mode LRT --output-folder {} --input-folder {} --ignore-warnings \\\n",
    "                         --weeks 4 --case {} --n_scenarios {} --nb_core {} --scenario_name {} --start-date {} \\\n",
    "                         --seed-for-loads {} --seed-for-res {} --seed-for-dispatch {}\".format(\n",
    "                         Ouput_folder, Input_folder, case_runner_grid, n_scenarios, nb_core, month, start_date, \\\n",
    "                         seed[month]['loads'], seed[month]['renewables'], seed[month]['dispatch'])\n",
    "        generate_mp_core(case_runner_grid, start_date, 4, 4, n_scenarios, 'LRT',\n",
    "                     Input_folder, Ouput_folder, str(month),\n",
    "                     seed[month]['loads'], seed[month]['renewables'], seed[month]['dispatch'], nb_core, ignore_warnings = True)\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        cli_chronix2grid=\"chronix2grid \\\n",
    "                         --mode LRT --output-folder {} --input-folder {} --ignore-warnings \\\n",
    "                         --weeks 4 --case {} --n_scenarios {} --nb_core {} --scenario_name {} --start-date {}\".format(\n",
    "                         Ouput_folder, Input_folder, case_runner_grid, n_scenarios, nb_core, month, start_date)\n",
    "        generate_mp_core(case_runner_grid, start_date, 4, 4, n_scenarios, 'LRT',\n",
    "                     Input_folder, Ouput_folder, str(month),\n",
    "                     None, None, None, nb_core, ignore_warnings = True)\n",
    "        \n",
    "    #call a subprocess to load your virtual env and excute your cli with it\n",
    "#     subprocess.call('. venv_chronix2grid/bin/activate;'+cli_chronix2grid, shell=True)\n",
    "    #output=subprocess.call(cli_activateVirtualEnv+';' + cli_chronix2grid, shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_chronix2grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First move grid2op runner agent results over chronics (used to do loss adjustement): \n",
    "will be reused in case of subgrid chronics generation below\n",
    "\n",
    "we move it in OutputFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_output_case_folder=os.path.join(Ouput_folder, 'generation', case_runner_grid)\n",
    "agent_result_folder_name='agent_results'\n",
    "agent_result_folder_path=os.path.join(existing_output_case_folder,agent_result_folder_name)\n",
    "\n",
    "new_agent_result_folder_path=os.path.join(Ouput_folder,agent_result_folder_name)\n",
    "\n",
    "if(os.path.exists(agent_result_folder_path)):\n",
    "    if(os.path.exists(new_agent_result_folder_path)):\n",
    "        print('delete folder before creating:'+new_agent_result_folder_path)\n",
    "        !rm -rf $new_agent_result_folder_path\n",
    "    shutil.move(agent_result_folder_path, Ouput_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now move monthly folder chronic files into a single chronics folder expected to build a grid2op environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouput_chronics_folder=os.path.join(existing_output_case_folder,'chronics')\n",
    "if os.path.exists(ouput_chronics_folder):\n",
    "    print('delete folder before creating:'+ouput_chronics_folder)\n",
    "    !rm -rf $ouput_chronics_folder\n",
    "\n",
    "#get monthly chronics folder\n",
    "existing_subfolderChronics=next(os.walk(existing_output_case_folder))[1]\n",
    "existing_subfolderChronics=[os.path.join(existing_output_case_folder,subF) for subF in existing_subfolderChronics]\n",
    "\n",
    "\n",
    "#create chronics folder to move all scenarios in one folder\n",
    "os.makedirs(ouput_chronics_folder, exist_ok=True)\n",
    "\n",
    "for d in existing_subfolderChronics:\n",
    "    #!ls $d/*\n",
    "    #!mv $d/* $folderChronics\n",
    "    for sub_d in next(os.walk(d))[1]:\n",
    "        print(os.path.join(d,sub_d))\n",
    "        shutil.move(os.path.join(d,sub_d),ouput_chronics_folder)\n",
    "    \n",
    "    file_names = os.listdir(d)\n",
    "    \n",
    "    for file_name in file_names:\n",
    "        if(file_name.endswith('.json')):\n",
    "            print(os.path.join(d, file_name))\n",
    "            shutil.move(os.path.join(d, file_name), ouput_chronics_folder)\n",
    "            \n",
    "    shutil.rmtree(d)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFolders=n_scenarios*len(months)\n",
    "\n",
    "if(len(next(os.walk(ouput_chronics_folder))[1])!=nFolders):\n",
    "    print(\"we have a problem in the chronics generation - maybe chronics to grid did not run properly\")\n",
    "    print(\"do it in the shell to check\")\n",
    "    print(\"do 1)  . venv_chronix2grid/bin/activate\")\n",
    "    print(\"this will source chronix2grid\")\n",
    "    print(\"do 2) \")\n",
    "    print(cli_chronix2grid)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks on generated chronics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check that losses have been adjusted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check adjusted_loss.csv.bz2 files exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_svcenarios=next(os.walk(ouput_chronics_folder))[1]\n",
    "\n",
    "for scenario in existing_svcenarios:\n",
    "    loss_adjustement_file_path=os.path.join(ouput_chronics_folder,scenario,'adjusted_loss.csv.bz2')\n",
    "   \n",
    "    if(os.path.exists(loss_adjustement_file_path)):\n",
    "        loss_adjusted_df=pd.read_csv(loss_adjustement_file_path)\n",
    "    else:\n",
    "        print(\"WARNING: losses have not been adjusted aposteriori with grid2op in scenario: \"+scenario)\n",
    "        print(\"Maybe dispatch did not converge or grid2op did not run for loss adjustement \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that we don't need to ajdust for losses anymore by rerunning once again grid2op and seeing almost no corrections in productions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path=os.path.join(Chronix2Grid_directory,'getting_started/scripts/check_loss_adjustement.py')\n",
    "%run $script_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen_id=1\n",
    "existing_svcenarios.sort()\n",
    "scenario=existing_svcenarios[scen_id]\n",
    "print(scenario)\n",
    "max_iter=1000\n",
    "\n",
    "check_loss_adjustement(existing_output_case_folder,scenario,scen_id,max_iter,Ouput_folder,params_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check that slack production is between Pmin and Pmax have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_slack=params_json['nameSlack']\n",
    "Pmin_slack=0\n",
    "Pmax_slack=prod_caract_df[prod_caract_df.name==name_slack].Pmax.values[0]\n",
    "Pmax_slack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for scenario in existing_svcenarios:\n",
    "    prod_p_file_path=os.path.join(ouput_chronics_folder,scenario,'prod_p.csv.bz2')\n",
    "    #print(scenario)\n",
    "    if(os.path.exists(prod_p_file_path)):\n",
    "        prod_p=pd.read_csv(prod_p_file_path,sep=';')\n",
    "        if(name_slack in prod_p.columns):\n",
    "            min_prod_slack=prod_p[[name_slack]].min()[0]\n",
    "            max_prod_slack=prod_p[[name_slack]].max()[0]\n",
    "            if(min_prod_slack<Pmin_slack):\n",
    "                print(\"WARNING: for scenario \"+scenario+\" the min slack production has negative value \"+str(min_prod_slack))\n",
    "            if(max_prod_slack>Pmax_slack):\n",
    "                print(\"WARNING: for scenario \"+scenario+\" the max slack production has high value \"+str(max_prod_slack))\n",
    "        else:\n",
    "            print(\"dispatch did not converge for this scenario: \"+ scenario)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO BE UPDATED\n",
    "# Path scenarios to compare with different environments\n",
    "#path_env1 = ouput_chronics_folder\n",
    "#path_env2 = notebook_config['ref_chronix']\n",
    "#\n",
    "#if ModeRunnerWithSeeds:\n",
    "#    # Select random scenarios\n",
    "#    rand_month = np.random.choice(months)\n",
    "#    rand_n_scenario = np.random.choice(range(n_scenarios))\n",
    "#    if rand_n_scenario < 10:\n",
    "#        n_scenario = f'0{rand_n_scenario}'\n",
    "#    else:\n",
    "#        n_scenario = str(rand_n_scenario)\n",
    "#\n",
    "#    # Create proper scenario name\n",
    "#    rand_scenario_name = f'Scenario_{rand_month}_{rand_n_scenario}'\n",
    "#\n",
    "#    factor_renew = 3\n",
    "#    for var in ['load', 'wind', 'solar']:\n",
    "#        chrnx_2 = os.path.join(path_env2, 'chronics')\n",
    "#        df_env1 = pd.read_csv(os.path.join(path_env1, rand_scenario_name, f'{var}_p.csv.bz2'), sep=';')\n",
    "#        df_env2 = pd.read_csv(os.path.join(chrnx_2, rand_scenario_name, f'{var}_p.csv.bz2'), sep=';')\n",
    "#        if var not in ['wind', 'solar']:\n",
    "#            if (df_env1.values[:, 1:] == df_env2.values[:, 1:]).all():\n",
    "#                print(f'{var}_p are the same in both envs')\n",
    "#        else:\n",
    "#            tolr = 1e-01\n",
    "#            arry1 = factor_renew * df_env1.values[:, 1:].astype(float)\n",
    "#            arry2 = df_env2.values[:, 1:].astype(float)\n",
    "#            if np.allclose(arry1, arry2, tolr):\n",
    "#                print(f'{var}_p are the same in both envs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3) Create the subgrid chronics - Create_chronics_subnet.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move subgrid to dir (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FromSubgridPath=os.path.join(Input_folder, 'generation', case_subgrid)\n",
    "ToSubgridPath=os.path.join(RunnerScriptFolder)\n",
    "ToSubgridPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FromSubgridPath=os.path.join(Input_folder, 'generation', case_subgrid)\n",
    "ToSubgridPath=os.path.join(RunnerScriptFolder)\n",
    "\n",
    "!cp -r $FromSubgridPath $ToSubgridPath #to copy the content of a into b do \"cp -r a/. b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that the subgrid folder exists - or otherwise run the 'subgrid_design' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgridPath = os.path.join(RunnerScriptFolder, case_subgrid)\n",
    "folderChronicsSubgrid=os.path.join(subgridPath, 'chronics')\n",
    "if os.path.exists(folderChronicsSubgrid):\n",
    "    print('delete folder before creating')\n",
    "    !rm -rf $folderChronicsSubgrid\n",
    "\n",
    "os.makedirs(folderChronicsSubgrid, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lsastr $folderChronicsSubgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lsastr $ouput_chronics_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that do-nothing agent results exist from fullgrid grid2op running computation (when doing loss adjustements) as we will reuse those results to set the values of subgrid interconnections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.exists(new_agent_result_folder_path)):\n",
    "    print(\"WARNING: you need to have run grid2op over your chronics for the full grid before creating subgrid chronics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Execute command line to get chronix for subgrid.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_create_subgrid_chronics=\"python \"+os.path.join(RunnerScriptFolder,'Create_chronics_subnet.py')+' --subnet_path {} --disptach_dir {} --agent_dir {} --ouput_dir {} --region {} --cores {}'.format(\n",
    "subgridPath,ouput_chronics_folder,new_agent_result_folder_path,folderChronicsSubgrid,subgrid_region,nb_core) \n",
    "cli_create_subgrid_chronics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$cli_create_subgrid_chronics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Move new subgrid folder in output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouput_folder_subgrid_path=os.path.join(Ouput_folder,'generation')\n",
    "new_folder_subgrid_path=os.path.join(ouput_folder_subgrid_path,case_subgrid)\n",
    "\n",
    "if(os.path.exists(new_folder_subgrid_path)):\n",
    "    print('delete folder before creating:'+new_folder_subgrid_path)\n",
    "    !rm -rf $new_folder_subgrid_path\n",
    "\n",
    "shutil.move(subgridPath,ouput_folder_subgrid_path)\n",
    "print(\"you can find your new subgrid environement \"+str(case_subgrid)+\" in folder: \"+ouput_folder_subgrid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgridPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output=subprocess.check_output(cli_create_subgrid_chronics,shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checks on generated chronics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scen_id=1\n",
    "existing_svcenarios.sort()\n",
    "scenario=existing_svcenarios[scen_id]\n",
    "print(scenario)\n",
    "max_iter=1000\n",
    "\n",
    "#change slack info for subgrid in params.json\n",
    "params_json_subgrid=params_json\n",
    "params_json_subgrid['idxSlack']=21\n",
    "params_json_subgrid['nameSlack']='gen_35_21'\n",
    "\n",
    "\n",
    "check_loss_adjustement(os.path.join(ouput_folder_subgrid_path,case_subgrid),scenario,scen_id,\n",
    "                       max_iter,Ouput_folder,case_subgrid,params_json_subgrid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
