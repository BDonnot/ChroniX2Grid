{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are trying to modify the power plants of this grid to obtain this energy mix:\n",
    "<img src=\"images/target_em.png\" width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import grid2op\n",
    "from grid2op.Chronics import ChangeNothing\n",
    "from chronix2grid.kpi.Generator_parameter_checker import EnergyMix_AprioriChecker\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from grid2op.PlotGrid import NUKE_COLOR, THERMAL_COLOR, WIND_COLOR, SOLAR_COLOR, HYDRO_COLOR\n",
    "\n",
    "# for pandas interactive plots\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We load the original prods_charac.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"case118_l2rpn_wcci_benjamin\"\n",
    "path_ref = os.path.join(\"..\", \"example\", \"input\", \"generation\")\n",
    "path_tmp = os.path.join(\"..\", \"example\", \"custom\", \"input\", \"generation\")\n",
    "input_path = os.path.join(path_ref, env_name)\n",
    "df = pd.read_csv(os.path.join(input_path, \"prods_charac.csv\"))\n",
    "\n",
    "avg_pmaxs = df.groupby([\"type\"])[\"Pmax\"].mean()\n",
    "types = avg_pmaxs.index.to_numpy()\n",
    "avg_pmaxs = avg_pmaxs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_by_type(info):\n",
    "  res = []\n",
    "  for t in types:\n",
    "    res.append(df[df[\"type\"] == t].iloc[0][info])\n",
    "  return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We recover some informations about each power plant type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(input_path, \"prods_charac.csv\"))\n",
    "\n",
    "\n",
    "n = df.shape[0]\n",
    "pmaxs = [250.0, 400.0, 74.7, 200.0, 67.2]\n",
    "max_ramp_up = get_info_by_type(\"max_ramp_up\")\n",
    "max_ramp_down = get_info_by_type(\"max_ramp_down\")\n",
    "min_up_time = get_info_by_type(\"min_up_time\")\n",
    "min_down_time = get_info_by_type(\"min_down_time\")\n",
    "marginal_cost = get_info_by_type(\"marginal_cost\")\n",
    "shut_down_cost = get_info_by_type(\"shut_down_cost\")\n",
    "start_cost = get_info_by_type(\"start_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We load the solution returned by the solver and modify the original csv according to the solution\n",
    "\n",
    "YOUR \"SOLVER\" DO NOT WORK AT ALL !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"optimization/solver/build/result.txt\")\n",
    "# for i in range(n):\n",
    "#   idx = int(file.readline())\n",
    "#   df.at[i, \"type\"] = types[idx]\n",
    "#   df.at[i, \"Pmax\"] = pmaxs[idx]\n",
    "#   df.at[i, \"max_ramp_up\"] = max_ramp_up[idx]\n",
    "#   df.at[i, \"max_ramp_down\"] = max_ramp_down[idx]\n",
    "#   df.at[i, \"min_up_time\"] = min_up_time[idx]\n",
    "#   df.at[i, \"min_down_time\"] = min_down_time[idx]\n",
    "#   df.at[i, \"marginal_cost\"] = marginal_cost[idx]\n",
    "#   df.at[i, \"shut_down_cost\"] = shut_down_cost[idx]\n",
    "#   df.at[i, \"start_cost\"] = start_cost[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is much more wind power plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(path_tmp, env_name)\n",
    "df.to_csv(os.path.join(output_path, \"prods_charac.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_factor = np.array([30, 95, 15, np.nan, 25])\n",
    "average_load = 2800\n",
    "capacity_factor_df = pd.DataFrame(data=capacity_factor, columns=['capacity_factor'], index=types)\n",
    "\n",
    "grid_path = os.path.join(output_path, \"grid.json\")\n",
    "env118_withoutchron = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    ")\n",
    "\n",
    "Target_EM_percentage=pd.DataFrame(data=[9, 36, 17, 2, 36], columns=['target_energy_mix'], index=types)\n",
    "\n",
    "#Variable used to anticipate the energy mix a priori. Update them after chronics generation if too different\n",
    "PeakLoad = 4200 #expected peak load\n",
    "\n",
    "EnergyMix_AprioriChecker(env118_withoutchron, Target_EM_percentage, PeakLoad, average_load, capacity_factor_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can see that the difference between the target energy mix and the apriori energy mix is 45%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) We now try to generate the loads / renewable to make sure the generated data are compatible with the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "notebook_folder=%pwd\n",
    "\n",
    "# define your input folder\n",
    "INPUT_FOLDER = os.path.join(notebook_folder, '..', 'example', 'custom', 'input')\n",
    "\n",
    "OUTPUT_FOLDER = os.path.join(notebook_folder, '..', 'example', 'custom', 'output')\n",
    "\n",
    "# Detailed configuration to be set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "weeks = 4\n",
    "n_scenarios = 1\n",
    "by_n_weeks = 4\n",
    "\n",
    "mode = 'RLTK'\n",
    "mode = 'RL'\n",
    "\n",
    "\n",
    "CASE = env_name\n",
    "\n",
    "load_seed = 7\n",
    "renewable_seed = 12\n",
    "\n",
    "li_months = [\"2012-01-01\", \"2012-02-01\", \"2012-03-01\", \"2012-04-01\", \"2012-05-01\", \"2012-06-01\",\n",
    "             \"2012-07-01\", \"2012-08-01\", \"2012-09-01\", \"2012-10-01\", \"2012-11-01\", \"2012-12-01\",\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_date in li_months:\n",
    "    cli_chronix2grid = \"chronix2grid \\\n",
    "                        --mode {} --output-folder {} --input-folder {} --ignore-warnings \\\n",
    "                        --weeks {} --case {} --n_scenarios {} --start-date {} --by-n-weeks {} \\\n",
    "                        --seed-for-loads {}  --seed-for-res {}\".format(\n",
    "                        mode, OUTPUT_FOLDER, INPUT_FOLDER, weeks, CASE, n_scenarios, start_date,by_n_weeks,\n",
    "                        load_seed, renewable_seed)\n",
    "    cli_chronix2grid\n",
    "    !$cli_chronix2grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_p = []\n",
    "prods_p_renewable = []\n",
    "for start_date in li_months:\n",
    "    path_data_generated = os.path.join(OUTPUT_FOLDER, \"generation\", CASE, start_date, \"Scenario_0\")\n",
    "    loads_p.append(pd.read_csv(os.path.join(path_data_generated, \"load_p.csv.bz2\"), sep=\";\"))\n",
    "    prods_p_renewable.append(pd.read_csv(os.path.join(path_data_generated, \"prod_p.csv.bz2\"), sep=\";\"))\n",
    "loads_p = pd.concat(loads_p, ignore_index=True)\n",
    "prods_p_renewable = pd.concat(prods_p_renewable, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gen_solar = env118_withoutchron.gen_type == \"solar\"\n",
    "is_gen_wind = env118_withoutchron.gen_type == \"wind\"\n",
    "gen_solar_name = env118_withoutchron.name_gen[is_gen_solar]\n",
    "gen_wind_name = env118_withoutchron.name_gen[is_gen_wind]\n",
    "list_gen_renwable = gen_solar_name.tolist()+gen_wind_name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_load = loads_p.sum(axis=1) - prods_p_renewable[list_gen_renwable].sum(axis=1)\n",
    "proportion_solar_wind = pd.DataFrame({\"total_load\": loads_p.sum(axis=1),\n",
    "                                      \"total_solar\": prods_p_renewable[gen_solar_name].sum(axis=1),\n",
    "                                      \"total_wind\": prods_p_renewable[gen_wind_name].sum(axis=1),\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gen_possible = np.sum(env118_withoutchron.gen_pmin[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_possible = np.sum(env118_withoutchron.gen_pmax[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_up_possible = np.sum(env118_withoutchron.gen_max_ramp_up[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_down_possible = np.sum(env118_withoutchron.gen_max_ramp_down[env118_withoutchron.gen_redispatchable])\n",
    "loss_ratio = 0.95  # takes into account some loss (conservative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some plot to have a look at the generation, might be handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods_p_renewable[gen_wind_name[1]].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods_p_renewable[gen_solar_name[1]].iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can compare above with previous validated grid2op environment (uncomment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import grid2op\n",
    "# env_test = grid2op.make(\"l2rpn_neurips_2020_track2_small\")\n",
    "# this_env_wind = [i for i in range(env_test.n_gen) if env_test.gen_type[i] == \"wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(env_test.chronics_handler.real_data.data.prod_p[:, this_env_wind[3]]).iplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected share of renewables\n",
    "\n",
    "If everything goes well and there is not much \"curtailment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['solar','wind','unknown']\n",
    "values = [proportion_solar_wind[\"total_solar\"].sum(),\n",
    "          proportion_solar_wind[\"total_wind\"].sum(),\n",
    "          proportion_solar_wind[\"total_load\"].sum() - proportion_solar_wind[\"total_solar\"].sum() - proportion_solar_wind[\"total_wind\"].sum()\n",
    "         ]\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels,\n",
    "                             values=values,\n",
    "                             marker_colors=[SOLAR_COLOR, WIND_COLOR, 'rgba(0,0,0, 0.05)'],\n",
    "                             text=[f\"{round(el / 12., -3):,.0f} MWh\" for el in values])\n",
    "                     ]\n",
    "               )\n",
    "fig.update_layout(\n",
    "    title=f\"This has only run on {weeks} weeks, the target is for a whole year !!!\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic infeasibilities\n",
    "\n",
    "The section bellow check that the market dispatch has a chance to converge. If something is violated here, \n",
    "then there is now way the market dispatch can work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "due_pmin = residual_load < min_gen_possible\n",
    "due_pmax = residual_load > loss_ratio * max_gen_possible\n",
    "delta_gen = residual_load.diff()  # diff(t) = residual_load(t) - residual_load(t-1)\n",
    "due_rampmax = delta_gen > max_gen_up_possible\n",
    "due_rampmin = delta_gen < -max_gen_up_possible\n",
    "due_rampmax[::(weeks * 7 * 288)] = False  # remove the \"interface\" at 4 weeks, 8 weeks etc.\n",
    "due_rampmin[::(weeks * 7 * 288)] = False  # remove the \"interface\" at 4 weeks, 8 weeks etc.\n",
    "print(f\"There are (at least) {due_pmin.sum()} infeasibilities due to pmin ({100. * due_pmin.sum() / due_pmin.shape[0]:.0f}%) that will require curtailment\")\n",
    "print(f\"There are (at least) {due_pmax.sum()} infeasibilities due to pmax ({100. * due_pmax.sum() / due_pmax.shape[0]:.0f}%) that will require curtailment\")\n",
    "print(f\"There are (at least) {due_rampmax.sum()} infeasibilities due to ramp up ({100. * due_rampmax.sum() / due_rampmax.shape[0]:.0f}%) that will require curtailment\")\n",
    "print(f\"There are (at least) {due_rampmin.sum()} infeasibilities due to ramp down ({100. * due_rampmin.sum() / due_rampmin.shape[0]:.0f}%) that will require curtailment\")\n",
    "# assert np.all(~due_pmin) and np.all(~due_pmax) and np.all(~due_rampmax) and np.all(~due_rampmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_gen.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_gen_up_possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some basic check to make sure the data are consistent with what we asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_solar_above_pmax = prods_p_renewable[gen_solar_name] > env118_withoutchron.gen_pmax[is_gen_solar]\n",
    "all_solar_below_pmin = prods_p_renewable[gen_solar_name] < env118_withoutchron.gen_pmin[is_gen_solar]\n",
    "\n",
    "all_wind_above_pmax = prods_p_renewable[gen_wind_name] > env118_withoutchron.gen_pmax[is_gen_wind]\n",
    "all_wind_below_pmin = prods_p_renewable[gen_wind_name] < env118_withoutchron.gen_pmin[is_gen_wind]\n",
    "\n",
    "assert np.all(all_solar_above_pmax.sum() == 0), f\"some solar are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "assert np.all(all_solar_below_pmin.sum() == 0), f\"some solar are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "assert np.all(all_wind_above_pmax.sum() == 0), f\"some wind are above pmax:\\n{all_wind_above_pmax.sum()})\"\n",
    "assert np.all(all_wind_below_pmin.sum() == 0), f\"some wind are below pmin:\\n{all_wind_below_pmin.sum()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Now start the redispatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_DISPATCH2 = \"RLDT\"\n",
    "seed_dispatch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for start_date in li_months:\n",
    "    cli_chronix2grid2 = \"chronix2grid \\\n",
    "                         --mode {} --output-folder {} --input-folder {} --ignore-warnings \\\n",
    "                         --weeks {} --case {} --n_scenarios {} --start-date {} --by-n-weeks {} \\\n",
    "                         --seed-for-loads {}  --seed-for-res {} --seed-for-dispatch {}\".format(\n",
    "                         MODE_DISPATCH2, OUTPUT_FOLDER, INPUT_FOLDER, weeks, CASE, n_scenarios, start_date,by_n_weeks,\n",
    "                         load_seed, renewable_seed, seed_dispatch)\n",
    "    cli_chronix2grid2\n",
    "    !$cli_chronix2grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_p2 = []\n",
    "prods_p_total = []\n",
    "prods_p_total_gen = []\n",
    "for start_date in li_months:\n",
    "    path_data_generated = os.path.join(OUTPUT_FOLDER, \"generation\", CASE, start_date, \"Scenario_0\")\n",
    "    loads_p2.append(pd.read_csv(os.path.join(path_data_generated, \"load_p.csv.bz2\"), sep=\";\"))\n",
    "    prods_p_total.append(pd.read_csv(os.path.join(path_data_generated, \"prod_p.csv.bz2\"), sep=\";\"))\n",
    "    prods_p_total_gen.append(pd.read_csv(os.path.join(path_data_generated, \"prod_p_renew_orig.csv.bz2\"), sep=\";\"))\n",
    "    \n",
    "loads_p2 = pd.concat(loads_p2, ignore_index=True)\n",
    "prods_p_total = pd.concat(prods_p_total, ignore_index=True)\n",
    "prods_p_total_gen = pd.concat(prods_p_total_gen, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_solar_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"solar\"]\n",
    "gen_wind_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"wind\"]\n",
    "gen_hydro_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"hydro\"]\n",
    "gen_nuclear_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"nuclear\"]\n",
    "gen_thermal_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"thermal\"]\n",
    "residual_load = loads_p2.sum(axis=1) - prods_p_total.sum(axis=1)\n",
    "proportion_solar_wind2 = pd.DataFrame({\"total_load\": loads_p2.sum(axis=1),\n",
    "                                      \"total_solar\": prods_p_total[gen_solar_name2].sum(axis=1),\n",
    "                                      \"total_wind\": prods_p_total[gen_wind_name2].sum(axis=1),\n",
    "                                      \"total_hydro\": prods_p_total[gen_hydro_name2].sum(axis=1),\n",
    "                                      \"total_nuclear\": prods_p_total[gen_nuclear_name2].sum(axis=1),\n",
    "                                      \"total_thermal\": prods_p_total[gen_thermal_name2].sum(axis=1),\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = ['solar','wind','hydro', \"nuclear\", \"thermal\"]\n",
    "values2 = [proportion_solar_wind2[\"total_solar\"].sum(),\n",
    "           proportion_solar_wind2[\"total_wind\"].sum(),\n",
    "           proportion_solar_wind2[\"total_hydro\"].sum(),\n",
    "           proportion_solar_wind2[\"total_nuclear\"].sum(),\n",
    "           proportion_solar_wind2[\"total_thermal\"].sum(),\n",
    "          ]\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels2,\n",
    "                             values=values2,\n",
    "                             marker_colors=[SOLAR_COLOR, WIND_COLOR, HYDRO_COLOR, NUKE_COLOR, THERMAL_COLOR],\n",
    "                            text=[f\"{round(el / 12., -3):,.0f} MWh\" for el in values2]\n",
    "                            )]\n",
    "                             \n",
    "                )\n",
    "fig.update_layout(\n",
    "    title=f\"This has only run on {weeks} weeks, the target is for a whole year !!!\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the \"OPF\" did not curtail too much\n",
    "\n",
    "Be carefull, there are \"noise\" in the generation now ! This is why the \"prod_p_renew_orig\" has been loaded and is used here !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to rounding\n",
    "assert np.all((prods_p_total[gen_wind_name] - prods_p_total_gen[gen_wind_name2]).max() <= 0.100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max amount \"curtailed\" by the optimiser, we should get close to 0.\n",
    "(prods_p_total[gen_wind_name] - prods_p_total_gen[gen_wind_name2]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of that should be really, really close to 0., it's the amount\n",
    "# of energy \"lost\" because of constraints on the controlable generators\n",
    "total_curtailed_generation_pct = 100. * (prods_p_total[gen_wind_name] - prods_p_total_gen[gen_wind_name2]).abs().sum() / prods_p_total_gen[gen_wind_name].sum()\n",
    "total_curtailed_generation_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prods_p_total_gen[gen_wind_name2[0]].iplot()\n",
    "nm_gen = gen_wind_name[0]\n",
    "fig = go.Figure(data=[go.Scatter(y=prods_p_total[nm_gen], name=\"actual generation\"),\n",
    "                      go.Scatter(y=prods_p_total_gen[nm_gen], name=\"possible generation\"),\n",
    "                     ]\n",
    "               )\n",
    "fig.update_layout(\n",
    "    title=f\"Comparison of generation for wind generator {nm_gen}\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to rounding\n",
    "assert np.all((prods_p_total[gen_solar_name] - prods_p_total_gen[gen_solar_name2]).max() <= 0.100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max amount \"curtailed\" by the optimiser, we should get close to 0.\n",
    "(prods_p_total[gen_solar_name] - prods_p_total_gen[gen_solar_name2]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of that should be really, really close to 0., it's the amount\n",
    "# of energy \"lost\" because of constraints on the controlable generators\n",
    "total_curtailed_generation_pct = 100. * (prods_p_total[gen_solar_name] - prods_p_total_gen[gen_solar_name2]).abs().sum() / prods_p_total_gen[gen_solar_name].sum()\n",
    "total_curtailed_generation_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_gen = gen_solar_name[0]\n",
    "fig = go.Figure(data=[go.Scatter(y=prods_p_total[nm_gen], name=\"actual generation\"),\n",
    "                      go.Scatter(y=prods_p_total_gen[nm_gen], name=\"possible generation\"),\n",
    "                     ]\n",
    "               )\n",
    "fig.update_layout(\n",
    "    title=f\"Comparison of generation for solar generator {nm_gen}\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check possible bugs\n",
    "\n",
    "#### check loads meet demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_loss = prods_p_total.sum(axis=1) / loads_p.sum(axis=1)\n",
    "assert (ratio_loss.max() - ratio_loss.min()) <= 3e-3  # with rounding this can vary a little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for renewable generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_solar_above_pmax = prods_p_total[gen_solar_name] > env118_withoutchron.gen_pmax[is_gen_solar]\n",
    "all_solar_below_pmin = prods_p_total[gen_solar_name] < env118_withoutchron.gen_pmin[is_gen_solar]\n",
    "\n",
    "all_wind_above_pmax = prods_p_total[gen_wind_name] > env118_withoutchron.gen_pmax[is_gen_wind]\n",
    "all_wind_below_pmin = prods_p_total[gen_wind_name] < env118_withoutchron.gen_pmin[is_gen_wind]\n",
    "\n",
    "assert np.all(all_solar_above_pmax.sum() == 0), f\"some solar are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "assert np.all(all_solar_below_pmin.sum() == 0), f\"some solar are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "assert np.all(all_wind_above_pmax.sum() == 0), f\"some wind are above pmax:\\n{all_wind_above_pmax.sum()})\"\n",
    "assert np.all(all_wind_below_pmin.sum() == 0), f\"some wind are below pmin:\\n{all_wind_below_pmin.sum()}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_controlable_gens(gen_name, env, prods_p_total):\n",
    "    pmax_ = np.array([env.gen_pmax[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    pmax_ = pmax_.ravel()\n",
    "    check_pmax = prods_p_total[gen_name] > pmax_\n",
    "\n",
    "    pmin_ = np.array([env.gen_pmin[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    pmin_ = pmin_.ravel()\n",
    "    check_pmin = prods_p_total[gen_name] < pmin_\n",
    "\n",
    "    max_up_ = np.array([env.gen_max_ramp_up[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    max_up_ = max_up_.ravel()\n",
    "    max_down_ = np.array([env.gen_max_ramp_down[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    max_down_ = max_down_.ravel()\n",
    "    delta_gen_ = prods_p_total[gen_name].diff()  # prods_p_total.diff(t) = prods_p_total(t) - prods_p_total(t-1)\n",
    "    check_max_up = delta_gen_ > max_up_\n",
    "    check_max_down = delta_gen_ < -max_down_\n",
    "    # remove the \"interface\" between the months\n",
    "    check_max_up[::(weeks * 7 * 288 - 1)] = False\n",
    "    check_max_down[::(weeks * 7 * 288 - 1)] = False\n",
    "    check_max_up[::(weeks * 7 * 288 )] = False\n",
    "    check_max_down[::(weeks * 7 * 288)] = False\n",
    "    return check_pmax, check_pmin, check_max_up, check_max_down\n",
    "\n",
    "def check_all_controlable_gens(prods_p_total, gen_hydro_name2, gen_nuclear_name2, gen_thermal_name2, env118_withoutchron):\n",
    "    check_pmax_hydro, check_pmin_hydro, check_max_up_hydro, check_max_down_hydro = check_controlable_gens(\n",
    "        gen_hydro_name2, env118_withoutchron, prods_p_total)\n",
    "    check_pmax_nuclear, check_pmin_nuclear, check_max_up_nuclear, check_max_down_nuclear = check_controlable_gens(\n",
    "        gen_nuclear_name2, env118_withoutchron, prods_p_total)\n",
    "    check_pmax_thermal, check_pmin_thermal, check_max_up_thermal, check_max_down_thermal = check_controlable_gens(\n",
    "        gen_thermal_name2, env118_withoutchron, prods_p_total)\n",
    "\n",
    "    assert np.all(check_pmax_hydro.sum() == 0), f\"some hydro are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "    assert np.all(check_pmin_hydro.sum() == 0), f\"some hydro are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "    assert np.all(check_max_up_hydro.sum() == 0), f\"some hydro are above max_up:\\n{check_max_up_hydro.sum()}\"\n",
    "    assert np.all(check_max_down_hydro.sum() == 0), f\"some hydro are below max_down:\\n{check_max_down_hydro.sum()}\"\n",
    "\n",
    "    assert np.all(check_pmax_nuclear.sum() == 0), f\"some nuclear are above pmax:\\n{check_pmax_nuclear.sum()}\"\n",
    "    assert np.all(check_pmin_nuclear.sum() == 0), f\"some nuclear are below pmin:\\n{check_pmin_nuclear.sum()}\"\n",
    "    assert np.all(check_max_up_nuclear.sum() == 0), f\"some nuclear are above max_up:\\n{check_max_up_nuclear.sum()}\"\n",
    "    assert np.all(check_max_down_nuclear.sum() == 0), f\"some nuclear are below max_down:\\n{check_max_down_nuclear.sum()}\"\n",
    "\n",
    "    assert np.all(check_pmax_thermal.sum() == 0), f\"some thermal are above pmax:\\n{check_pmax_thermal.sum()}\"\n",
    "    assert np.all(check_pmin_thermal.sum() == 0), f\"some thermal are below pmin:\\n{check_pmin_thermal.sum()}\"\n",
    "    assert np.all(check_max_up_thermal.sum() == 0), f\"some thermal are above max_up:\\n{check_max_up_thermal.sum()}\"\n",
    "    assert np.all(check_max_down_thermal.sum() == 0), f\"some thermal are below max_down:\\n{check_max_down_thermal.sum()}\"\n",
    "\n",
    "    print(\"All checks passed !\\n\")\n",
    "\n",
    "check_all_controlable_gens(prods_p_total, gen_hydro_name2, gen_nuclear_name2, gen_thermal_name2, env118_withoutchron)\n",
    "print(f\"It's now time to look at the 'KPI' and the productions / loads generated at :\\n\\t{path_data_generated}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Check the loss of the grid\n",
    "\n",
    "Make sure the data generated can be loaded with grid2op framework\n",
    "\n",
    "This part might not work on microsoft windows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Parameters import Parameters\n",
    "from lightsim2grid import LightSimBackend  # might need \"pip install lightsim2grid\"\n",
    "import shutil\n",
    "from grid2op.Chronics import FromNPY\n",
    "# TODO TQDM !\n",
    "\n",
    "path_chronics_outputopf = os.path.join(OUTPUT_FOLDER, \"all_scenarios\")\n",
    "shutil.rmtree(path_chronics_outputopf)\n",
    "if not os.path.exists(path_chronics_outputopf):\n",
    "    os.mkdir(path_chronics_outputopf)\n",
    "    \n",
    "path_chronics_fixed = os.path.join(OUTPUT_FOLDER, \"fixed_chronics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_date in li_months:\n",
    "    path_data_generated = os.path.join(OUTPUT_FOLDER, \"generation\", CASE, start_date, \"Scenario_0\")\n",
    "    path_ = os.path.abspath(os.path.join(path_chronics_outputopf, start_date))\n",
    "    os.symlink(path_data_generated, path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = env118_withoutchron.parameters\n",
    "param.NO_OVERFLOW_DISCONNECTION = True\n",
    "env_for_loss = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    chronics_path=path_chronics_outputopf,\n",
    "    param=param,\n",
    "    backend=LightSimBackend()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_real_gen(target, row_id, obs, env):\n",
    "    target[row_id, env.gen_renewable] = obs.gen_p[env.gen_renewable]\n",
    "    loss = np.sum(obs.gen_p) - np.sum(obs.load_p)  # actual loss of the grid\n",
    "    \n",
    "    # split what the slack absorbed in the controlable generators\n",
    "    gen_p_setpoint = env.chronics_handler.real_data.data.prod_p[row_id]\n",
    "    to_split = np.sum(obs.gen_p) - np.sum(gen_p_setpoint)\n",
    "    redisp_ = 1.0 * gen_p_setpoint[~env.gen_renewable]\n",
    "    redisp_ *= 1.0 + to_split / np.sum(redisp_)\n",
    "    target[row_id, ~env.gen_renewable] = redisp_\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gen_p = np.full((weeks * 7 * 288 - 1, env_for_loss.n_gen), fill_value=np.NaN, dtype=np.float32)\n",
    "final_gen_v = np.full((weeks * 7 * 288 - 1, env_for_loss.n_gen), fill_value=np.NaN, dtype=np.float32)\n",
    "final_load_p = np.full((weeks * 7 * 288 - 1, env_for_loss.n_load), fill_value=np.NaN, dtype=np.float32)\n",
    "final_load_q = np.full((weeks * 7 * 288 - 1, env_for_loss.n_load), fill_value=np.NaN, dtype=np.float32)\n",
    "all_loss = np.zeros(weeks * 7 * 288 - 1)\n",
    "\n",
    "obs = env_for_loss.reset()\n",
    "i = 0\n",
    "all_loss[i] = fill_real_gen(final_gen_p, i, obs, env_for_loss)\n",
    "final_gen_v[i] = obs.gen_v\n",
    "final_load_p[i] = obs.load_p\n",
    "final_load_q[i] = obs.load_q\n",
    "chron_name = env_for_loss.chronics_handler.get_id()\n",
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, info = env_for_loss.step(env_for_loss.action_space())\n",
    "    i += 1\n",
    "    all_loss[i] = fill_real_gen(final_gen_p, i, obs, env_for_loss)\n",
    "    final_gen_v[i] = obs.gen_v\n",
    "    final_load_p[i] = obs.load_p\n",
    "    final_load_q[i] = obs.load_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these numbers should be between 1-2-3% (more than 5 indicates an issue !)\n",
    "losses_pct = 100. * all_loss / np.sum(final_gen_p, axis=1)\n",
    "print(f\"max loss: {losses_pct.max():.2f} %\")\n",
    "print(f\"min loss: {losses_pct.min():.2f} %\")\n",
    "print(f\"avg loss: {losses_pct.mean():.2f} %\")\n",
    "assert losses_pct.max() <= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test that it's working (and continue looping until it does not move)\n",
    "env_fixed = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    param=param,\n",
    "    backend=LightSimBackend(),\n",
    "    chronics_class=FromNPY,\n",
    "    chronics_path=path_chronics_outputopf,\n",
    "    data_feeding_kwargs={\"load_p\": final_load_p,\n",
    "                         \"load_q\": final_load_q,\n",
    "                         \"prod_p\": final_gen_p,\n",
    "                         \"prod_v\": final_gen_v}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be as close to 0. as possible...\n",
    "# we might do a second \"repartition loop\" to make sure it's ok :-)\n",
    "i = 0\n",
    "final_gen_p2 = final_gen_p * np.NaN\n",
    "diff_ = np.full((weeks * 7 * 288 - 1, env_fixed.n_gen), fill_value=np.NaN)\n",
    "obs = env_fixed.reset()\n",
    "diff_[i] = obs.gen_p - final_gen_p[i]\n",
    "fill_real_gen(final_gen_p2, i, obs, env_for_loss)\n",
    "while True:\n",
    "    obs, reward, done, info = env_fixed.step(env_for_loss.action_space())\n",
    "    if done:\n",
    "        break\n",
    "    i += 1\n",
    "    fill_real_gen(final_gen_p2, i, obs, env_for_loss)\n",
    "    diff_[i] = obs.gen_p - final_gen_p[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(diff_).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use the time serie module from lightsim2grid for that !!!\n",
    "env_fixed2 = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    param=param,\n",
    "    backend=LightSimBackend(),\n",
    "    chronics_class=FromNPY,\n",
    "    chronics_path=path_chronics_outputopf,\n",
    "    data_feeding_kwargs={\"load_p\": final_load_p,\n",
    "                         \"load_q\": final_load_q,\n",
    "                         \"prod_p\": final_gen_p2,\n",
    "                         \"prod_v\": final_gen_v}\n",
    "    )\n",
    "i = 0\n",
    "final_gen_p3 = final_gen_p * np.NaN\n",
    "diff_2 = np.full((weeks * 7 * 288 - 1, env_fixed.n_gen), fill_value=np.NaN)\n",
    "obs = env_fixed2.reset()\n",
    "diff_2[i] = obs.gen_p - final_gen_p2[i]\n",
    "fill_real_gen(final_gen_p3, i, obs, env_for_loss)\n",
    "while True:\n",
    "    obs, reward, done, info = env_fixed2.step(env_for_loss.action_space())\n",
    "    if done:\n",
    "        break\n",
    "    i += 1\n",
    "    fill_real_gen(final_gen_p3, i, obs, env_for_loss)\n",
    "    diff_2[i] = obs.gen_p - final_gen_p2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(diff_2).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_fixed3 = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    param=param,\n",
    "    backend=LightSimBackend(),\n",
    "    chronics_class=FromNPY,\n",
    "    chronics_path=path_chronics_outputopf,\n",
    "    data_feeding_kwargs={\"load_p\": final_load_p,\n",
    "                         \"load_q\": final_load_q,\n",
    "                         \"prod_p\": final_gen_p3,\n",
    "                         \"prod_v\": final_gen_v}\n",
    "    )\n",
    "i = 0\n",
    "final_gen_p4 = final_gen_p * np.NaN\n",
    "diff_3 = np.full((weeks * 7 * 288 - 1, env_fixed.n_gen), fill_value=np.NaN)\n",
    "obs = env_fixed3.reset()\n",
    "diff_3[i] = obs.gen_p - final_gen_p3[i]\n",
    "fill_real_gen(final_gen_p4, i, obs, env_for_loss)\n",
    "while True:\n",
    "    obs, reward, done, info = env_fixed3.step(env_for_loss.action_space())\n",
    "    if done:\n",
    "        break\n",
    "    i += 1\n",
    "    fill_real_gen(final_gen_p4, i, obs, env_for_loss)\n",
    "    diff_3[i] = obs.gen_p - final_gen_p3[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(diff_3).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that the generation \"does not move\", we check that it meets the physical constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gen_df = pd.DataFrame(final_gen_p3, columns=env_for_loss.name_gen)\n",
    "check_all_controlable_gens(final_gen_df, gen_hydro_name2, gen_nuclear_name2, gen_thermal_name2, env118_withoutchron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(final_gen_df[\"gen_25_13\"].diff()).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we save the data in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(final_load_p, columns=env_for_loss.name_load).to_csv(...)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
