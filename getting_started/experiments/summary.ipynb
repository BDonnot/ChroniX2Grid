{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are trying to modify the power plants of this grid to obtain this energy mix:\n",
    "<img src=\"images/target_em.png\" width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import grid2op\n",
    "from grid2op.Chronics import ChangeNothing\n",
    "from chronix2grid.kpi.Generator_parameter_checker import EnergyMix_AprioriChecker\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from grid2op.PlotGrid import NUKE_COLOR, THERMAL_COLOR, WIND_COLOR, SOLAR_COLOR, HYDRO_COLOR\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# for pandas interactive plots\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We load the original prods_charac.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"case118_l2rpn_wcci_benjamin\"\n",
    "path_ref = os.path.join(\"..\", \"example\", \"input\", \"generation\")\n",
    "path_tmp = os.path.join(\"..\", \"example\", \"custom\", \"input\", \"generation\")\n",
    "input_path = os.path.join(path_ref, env_name)\n",
    "df = pd.read_csv(os.path.join(input_path, \"prods_charac.csv\"))\n",
    "\n",
    "avg_pmaxs = df.groupby([\"type\"])[\"Pmax\"].mean()\n",
    "types = avg_pmaxs.index.to_numpy()\n",
    "avg_pmaxs = avg_pmaxs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_by_type(info):\n",
    "  res = []\n",
    "  for t in types:\n",
    "    res.append(df[df[\"type\"] == t].iloc[0][info])\n",
    "  return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We recover some informations about each power plant type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(input_path, \"prods_charac.csv\"))\n",
    "\n",
    "\n",
    "n = df.shape[0]\n",
    "pmaxs = [250.0, 400.0, 74.7, 200.0, 67.2]\n",
    "max_ramp_up = get_info_by_type(\"max_ramp_up\")\n",
    "max_ramp_down = get_info_by_type(\"max_ramp_down\")\n",
    "min_up_time = get_info_by_type(\"min_up_time\")\n",
    "min_down_time = get_info_by_type(\"min_down_time\")\n",
    "marginal_cost = get_info_by_type(\"marginal_cost\")\n",
    "shut_down_cost = get_info_by_type(\"shut_down_cost\")\n",
    "start_cost = get_info_by_type(\"start_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coppy the prods_charac to the right place\n",
    "output_path = os.path.join(path_tmp, env_name)\n",
    "df.to_csv(os.path.join(output_path, \"prods_charac.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the parameters to the right place\n",
    "for el in [\"params.json\", \"params_load.json\", \"params_loss.json\", \"params_opf.json\", \"params_res.json\"]:\n",
    "    with open(os.path.join(input_path, el), \"r\") as f:\n",
    "        dict_ = json.load(f)\n",
    "    with open(os.path.join(output_path, el), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(fp=f, obj=dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_factor = np.array([30, 95, 15, np.nan, 25])\n",
    "average_load = 2800\n",
    "capacity_factor_df = pd.DataFrame(data=capacity_factor, columns=['capacity_factor'], index=types)\n",
    "\n",
    "grid_path = os.path.join(output_path, \"grid.json\")\n",
    "env118_withoutchron = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    ")\n",
    "\n",
    "# some data usefull later\n",
    "is_gen_solar = env118_withoutchron.gen_type == \"solar\"\n",
    "is_gen_wind = env118_withoutchron.gen_type == \"wind\"\n",
    "gen_solar_name = env118_withoutchron.name_gen[is_gen_solar]\n",
    "gen_wind_name = env118_withoutchron.name_gen[is_gen_wind]\n",
    "list_gen_renwable = gen_solar_name.tolist()+gen_wind_name.tolist()\n",
    "\n",
    "min_gen_possible = np.sum(env118_withoutchron.gen_pmin[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_possible = np.sum(env118_withoutchron.gen_pmax[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_up_possible = np.sum(env118_withoutchron.gen_max_ramp_up[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_down_possible = np.sum(env118_withoutchron.gen_max_ramp_down[env118_withoutchron.gen_redispatchable])\n",
    "loss_ratio = 0.95  # takes into account some loss (conservative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the grid, to know where are the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.PlotGrid import PlotMatplot\n",
    "plot_helper = PlotMatplot(env118_withoutchron)\n",
    "_ = plot_helper.plot_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information, you can check the \"bus\" (blue circle) in the \"bus\" column of the prods_charac.csv\n",
    "\n",
    "On the graph above, generators are green pentagons.\n",
    "\n",
    "You can also know if from their name.  For example \"gen_68_37\" is the generator **37** (gen_68_**37**) connected to substation **68** (gen_**68**_37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_helper.plot_gen_type()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the figure above you have also the generator types (colored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can see that the difference between the target energy mix and the apriori energy mix is 45%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A) We now try to generate the loads / renewable to make sure the generated data are compatible with the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrate_res = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "notebook_folder=%pwd\n",
    "\n",
    "# define your input folder\n",
    "INPUT_FOLDER = os.path.join(notebook_folder, '..', 'example', 'custom', 'input')\n",
    "\n",
    "OUTPUT_FOLDER = os.path.join(notebook_folder, '..', 'example', 'custom', 'output')\n",
    "\n",
    "# Detailed configuration to be set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "weeks = 1\n",
    "n_scenarios = 1\n",
    "# by_n_weeks = 4  # not used\n",
    "\n",
    "mode = 'RLTK'\n",
    "mode = 'RL'\n",
    "\n",
    "\n",
    "CASE = env_name\n",
    "# change line 19 of consumptions_utils.py\n",
    "# day_lag = 6  # this is only TRUE if you simulate 2050 !!!\n",
    "# if you change the year !!!\n",
    "li_months = [\"2050-01-03\", \n",
    "             \"2050-01-10\",\n",
    "             \"2050-01-17\",\n",
    "             \"2050-01-24\",\n",
    "             \"2050-01-31\",\n",
    "             \"2050-02-07\",\n",
    "             \"2050-02-14\",\n",
    "             \"2050-02-21\",\n",
    "             \"2050-02-28\",\n",
    "             \"2050-03-07\",\n",
    "             \"2050-03-14\",\n",
    "             \"2050-03-21\",\n",
    "             \"2050-03-28\",\n",
    "             \"2050-04-04\",\n",
    "             \"2050-04-11\",\n",
    "             \"2050-04-18\",\n",
    "             \"2050-04-25\",\n",
    "             \"2050-05-02\", \n",
    "             \"2050-05-09\", \n",
    "             \"2050-05-16\", \n",
    "             \"2050-05-23\", \n",
    "             \"2050-05-30\",\n",
    "             \"2050-06-06\",\n",
    "             \"2050-06-13\",\n",
    "             \"2050-06-20\",\n",
    "             \"2050-06-27\",\n",
    "             \"2050-07-04\", \n",
    "             \"2050-07-11\", \n",
    "             \"2050-07-18\", \n",
    "             \"2050-07-25\", \n",
    "             \"2050-08-01\", \n",
    "             \"2050-08-08\", \n",
    "             \"2050-08-15\", \n",
    "             \"2050-08-22\", \n",
    "             \"2050-08-29\", \n",
    "             \"2050-09-05\", \n",
    "             \"2050-09-12\", \n",
    "             \"2050-09-19\", \n",
    "             \"2050-09-26\", \n",
    "             \"2050-10-03\", \n",
    "             \"2050-10-10\", \n",
    "             \"2050-10-17\", \n",
    "             \"2050-10-24\", \n",
    "             \"2050-10-31\", \n",
    "             \"2050-11-07\", \n",
    "             \"2050-11-14\", \n",
    "             \"2050-11-21\", \n",
    "             \"2050-11-28\", \n",
    "             \"2050-12-05\",\n",
    "             \"2050-12-12\",\n",
    "             \"2050-12-19\",\n",
    "             \"2050-12-26\",\n",
    "            ]\n",
    "np.random.seed(1)\n",
    "load_seeds = [np.random.randint(0, np.iinfo(np.int32).max) for _ in range(len(li_months))]\n",
    "renewable_seeds = [np.random.randint(0, np.iinfo(np.int32).max) for _ in range(len(li_months))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 0\n",
    "max_ = 1\n",
    "calibrate_res = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if calibrate_res:\n",
    "    for i, start_date in enumerate(li_months[min_:max_]):\n",
    "        cli_chronix2grid = \"chronix2grid \" \\\n",
    "                            \"--mode {} --output-folder {} --input-folder {} --ignore-warnings \"\\\n",
    "                            \"--weeks {} --case {} --n_scenarios {} --start-date {} \"\\\n",
    "                            \"--seed-for-loads {}  --seed-for-res {}\".format(\n",
    "                            mode, OUTPUT_FOLDER, INPUT_FOLDER, weeks, CASE, n_scenarios, start_date,\n",
    "                            load_seeds[i], renewable_seeds[i])\n",
    "        print(cli_chronix2grid)\n",
    "        !$cli_chronix2grid\n",
    "    \n",
    "# --by-n-weeks {} \n",
    "# by_n_weeks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    loads_p = []\n",
    "    prods_p_renewable = []\n",
    "    for start_date in li_months[min_:max_]:\n",
    "        for scen_id in range(n_scenarios):\n",
    "            path_data_generated = os.path.join(OUTPUT_FOLDER, \"generation\", CASE, start_date, f\"Scenario_{scen_id}\")\n",
    "            loads_p.append(pd.read_csv(os.path.join(path_data_generated, \"load_p.csv.bz2\"), sep=\";\"))\n",
    "            prods_p_renewable.append(pd.read_csv(os.path.join(path_data_generated, \"prod_p.csv.bz2\"), sep=\";\"))\n",
    "    loads_p = pd.concat(loads_p, ignore_index=True)\n",
    "    prods_p_renewable = pd.concat(prods_p_renewable, ignore_index=True)\n",
    "    # assert loads_p.shape[0] == len(li_months) * n_scenarios * (weeks * 288 * 7  - 1) \n",
    "    # assert prods_p_renewable.shape[0] == len(li_months) * n_scenarios * (weeks * 288 * 7  - 1) \n",
    "    total_load = loads_p.sum(axis=1)\n",
    "    wind_plus_solar = prods_p_renewable[list_gen_renwable].sum(axis=1)\n",
    "    total_solar = prods_p_renewable[gen_solar_name].sum(axis=1)\n",
    "    total_wind = prods_p_renewable[gen_wind_name].sum(axis=1)\n",
    "    residual_load = total_load - wind_plus_solar\n",
    "    proportion_solar_wind = pd.DataFrame({\"total_load\": loads_p.sum(axis=1),\n",
    "                                          \"total_solar\": prods_p_renewable[gen_solar_name].sum(axis=1),\n",
    "                                          \"total_wind\": prods_p_renewable[gen_wind_name].sum(axis=1),\n",
    "                                         })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some plot to have a look at the generation, might be handy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    prods_p_renewable[gen_wind_name[:3]].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    prods_p_renewable[gen_solar_name[1]].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    loads_p.iloc[:,1].iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    fig = go.Figure(data=[go.Scatter(y=total_load, name=\"total load\")])\n",
    "    fig.add_trace(go.Scatter(y=residual_load, name=\"residual load\"))\n",
    "    fig.add_trace(go.Scatter(y=wind_plus_solar, name=\"wind + solar\"))\n",
    "    fig.add_trace(go.Scatter(y=total_solar, name=\"solar\"))\n",
    "    fig.add_trace(go.Scatter(y=total_wind, name=\"wind\"))\n",
    "    for el_id, el in enumerate(li_months[min_:max_]):\n",
    "        fig.add_vline(x=el_id * n_scenarios * (weeks * 288 * 7  - 1),\n",
    "                      line_dash='dash',\n",
    "                      line_color=\"red\" if el_id % 4 == 0 else \"gray\")\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can compare above with previous validated grid2op environment (uncomment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "if calibrate_res:\n",
    "    env_name = \"l2rpn_neurips_2020_track2_small\"\n",
    "    env_name = \"l2rpn_case14_sandbox\"\n",
    "    env_name = \"l2rpn_icaps_2021_small\"\n",
    "    env_test = grid2op.make(env_name)\n",
    "    this_env_wind = [i for i in range(env_test.n_gen) if env_test.gen_type[i] == \"wind\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    df = pd.DataFrame(env_test.chronics_handler.real_data.data.prod_p[::12, this_env_wind]).sum(axis=1)\n",
    "    df.iplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    french_ref_data = \"ref_french_data\"\n",
    "    all_year_ref = list(range(2012, 2021))\n",
    "    french_dfs = []\n",
    "    for year_ in all_year_ref:\n",
    "        temp_df = pd.read_csv(os.path.join(french_ref_data,\n",
    "                                           f\"eCO2mix_RTE_Annuel-Definitif_{year_}.zip\"),\n",
    "                              sep=\"\\t\",\n",
    "                              encoding=\"ISO-8859-1\",\n",
    "                              index_col=False)\n",
    "        french_dfs.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    fig = go.Figure()\n",
    "    for i, year_ in enumerate(all_year_ref):\n",
    "        tmp_ = french_dfs[i][\"Eolien\"].dropna().values\n",
    "        tmp_ /= tmp_.max()\n",
    "        fig.add_trace(go.Scatter(y=tmp_, name=f'{year_}'))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    fig = go.Figure()\n",
    "    for i, year_ in enumerate(all_year_ref[-2:]):\n",
    "        tmp_ = french_dfs[i][\"Eolien\"].dropna().values\n",
    "        tmp_ /= tmp_.max()\n",
    "        fig.add_trace(go.Histogram(x=tmp_, name=f'{year_}'))\n",
    "    # tmp_ = 1.0 * total_wind[::6]  # real data are sampled every 30 mins, I need to do this too here\n",
    "    # tmp_ /= tmp_.max()\n",
    "    # fig.add_trace(go.Histogram(x=tmp_, name=\"generated (sum)\"))\n",
    "    # tmp_ = 1.0 * prods_p_renewable[gen_wind_name[0]].values[::6]  # real data are sampled every 30 mins, I need to do this too here\n",
    "    # tmp_ /= tmp_.max()\n",
    "    fig.add_trace(go.Histogram(x=tmp_, name=\"generated (one)\"))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected share of renewables\n",
    "\n",
    "If everything goes well and there is not much \"curtailment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    labels = ['solar','wind','unknown']\n",
    "    values = [proportion_solar_wind[\"total_solar\"].sum(),\n",
    "              proportion_solar_wind[\"total_wind\"].sum(),\n",
    "              proportion_solar_wind[\"total_load\"].sum() - proportion_solar_wind[\"total_solar\"].sum() - proportion_solar_wind[\"total_wind\"].sum()\n",
    "             ]\n",
    "\n",
    "    fig = go.Figure(data=[go.Pie(labels=labels,\n",
    "                                 values=values,\n",
    "                                 marker_colors=[SOLAR_COLOR, WIND_COLOR, 'rgba(0,0,0, 0.05)'],\n",
    "                                 text=[f\"{round(el / 12., -3):,.0f} MWh\" for el in values])\n",
    "                         ]\n",
    "                   )\n",
    "    fig.update_layout(\n",
    "        title=f\"Repartition of renewable energy sources (upper bound)\"\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic infeasibilities\n",
    "\n",
    "The section bellow check that the market dispatch has a chance to converge. If something is violated here, \n",
    "then there is now way the market dispatch can work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    due_pmin = residual_load < min_gen_possible\n",
    "    due_pmax = residual_load > loss_ratio * max_gen_possible\n",
    "    delta_gen = residual_load.diff()  # diff(t) = residual_load(t) - residual_load(t-1)\n",
    "    due_rampmax = delta_gen > max_gen_up_possible\n",
    "    due_rampmin = delta_gen < -max_gen_up_possible\n",
    "    due_rampmax[::(7 * 288)] = False  # remove the \"interface\" at 1 week, 2 weeks etc.\n",
    "    due_rampmin[::(7 * 288)] = False  # remove the \"interface\" at 1 weeks, 2 weeks etc.\n",
    "    print(f\"There are (at least) {due_pmin.sum()} infeasibilities due to pmin ({100. * due_pmin.sum() / due_pmin.shape[0]:.0f}%) that will require curtailment\")\n",
    "    print(f\"There are (at least) {due_pmax.sum()} infeasibilities due to pmax ({100. * due_pmax.sum() / due_pmax.shape[0]:.0f}%) that will require curtailment\")\n",
    "    print(f\"There are (at least) {due_rampmax.sum()} infeasibilities due to ramp up ({100. * due_rampmax.sum() / due_rampmax.shape[0]:.0f}%) that will require curtailment\")\n",
    "    print(f\"There are (at least) {due_rampmin.sum()} infeasibilities due to ramp down ({100. * due_rampmin.sum() / due_rampmin.shape[0]:.0f}%) that will require curtailment\")\n",
    "    # assert np.all(~due_pmin) and np.all(~due_pmax) and np.all(~due_rampmax) and np.all(~due_rampmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    delta_gen.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    max_gen_up_possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    total_load[-2016:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_ratio * max_gen_possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### some basic check to make sure the data are consistent with what we asked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    all_solar_above_pmax = prods_p_renewable[gen_solar_name] > env118_withoutchron.gen_pmax[is_gen_solar]\n",
    "    all_solar_below_pmin = prods_p_renewable[gen_solar_name] < env118_withoutchron.gen_pmin[is_gen_solar]\n",
    "\n",
    "    all_wind_above_pmax = prods_p_renewable[gen_wind_name] > env118_withoutchron.gen_pmax[is_gen_wind]\n",
    "    all_wind_below_pmin = prods_p_renewable[gen_wind_name] < env118_withoutchron.gen_pmin[is_gen_wind]\n",
    "\n",
    "    assert np.all(all_solar_above_pmax.sum() == 0), f\"some solar are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "    assert np.all(all_solar_below_pmin.sum() == 0), f\"some solar are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "    assert np.all(all_wind_above_pmax.sum() == 0), f\"some wind are above pmax:\\n{all_wind_above_pmax.sum()})\"\n",
    "    assert np.all(all_wind_below_pmin.sum() == 0), f\"some wind are below pmin:\\n{all_wind_below_pmin.sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    prods_p_renewable[gen_wind_name].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if calibrate_res:\n",
    "    env118_withoutchron.gen_pmax[is_gen_wind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B) Now start the redispatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_DISPATCH2 = \"RLT\"  # do not put the \"D\" here !\n",
    "seed_dispatch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ = 0\n",
    "max_ = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# --> OPF formulation by => week - Analyzing week # 45\n",
    "# --> OPF formulation by => week - Analyzing week # 52\n",
    "for i, start_date in enumerate(li_months[min_:max_]):\n",
    "    cli_chronix2grid2 = \"chronix2grid \" \\\n",
    "                         \"--mode {} --output-folder {} --input-folder {} --ignore-warnings \" \\\n",
    "                         \"--weeks {} --case {} --n_scenarios {} --start-date {} \" \\\n",
    "                         \"--seed-for-loads {}  --seed-for-res {} --seed-for-dispatch {}\".format(\n",
    "                         MODE_DISPATCH2, OUTPUT_FOLDER, INPUT_FOLDER, weeks, CASE, n_scenarios, start_date,\n",
    "                         load_seeds[i], renewable_seeds[i], seed_dispatch)\n",
    "    print(cli_chronix2grid2)\n",
    "    !$cli_chronix2grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loads_p2 = []\n",
    "prods_p_total = []\n",
    "prods_p_total_gen = []\n",
    "failed = False\n",
    "for start_date in li_months[min_:max_]:\n",
    "    for scen_id in range(n_scenarios):\n",
    "        path_data_generated = os.path.join(OUTPUT_FOLDER, \"generation\", CASE, start_date, f\"Scenario_{scen_id}\")\n",
    "        if os.path.exists(os.path.join(path_data_generated, \"DISPATCH_FAILED\")):\n",
    "            # dispatched has failed for this one\n",
    "            print(f\"Dispatch failed for {start_date} (scenario {scen_id})\")\n",
    "            failed = True\n",
    "            continue\n",
    "        loads_p2.append(pd.read_csv(os.path.join(path_data_generated, \"load_p.csv.bz2\"), sep=\";\"))\n",
    "        prods_p_total.append(pd.read_csv(os.path.join(path_data_generated, \"prod_p.csv.bz2\"), sep=\";\"))\n",
    "        prods_p_total_gen.append(pd.read_csv(os.path.join(path_data_generated, \"prod_p_renew_orig.csv.bz2\"),\n",
    "                                             sep=\";\"))\n",
    "    \n",
    "loads_p2 = pd.concat(loads_p2, ignore_index=True)\n",
    "prods_p_total = pd.concat(prods_p_total, ignore_index=True)\n",
    "prods_p_total_gen = pd.concat(prods_p_total_gen, ignore_index=True)\n",
    "\n",
    "assert not failed, \"some weeks did not converge\"\n",
    "assert loads_p2.shape[0] == len(li_months) * n_scenarios * (weeks * 288 * 7  - 1) \n",
    "assert prods_p_total.shape[0] == len(li_months) * n_scenarios * (weeks * 288 * 7  - 1) \n",
    "assert prods_p_total_gen.shape[0] == len(li_months) * n_scenarios * (weeks * 288 * 7  - 1) \n",
    "\n",
    "assert loads_p2.isna().sum().sum() == 0, \"there are nans in the loads\"\n",
    "assert prods_p_total.isna().sum().sum() == 0, f\"there are {prods_p_total.isna().sum().sum()} nans in the generators\"\n",
    "assert prods_p_total_gen.isna().sum().sum() == 0, f\"there are {prods_p_total_gen.isna().sum().sum()} nans in the generators (max values)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_solar_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"solar\"]\n",
    "gen_wind_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"wind\"]\n",
    "gen_hydro_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"hydro\"]\n",
    "gen_nuclear_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"nuclear\"]\n",
    "gen_thermal_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"thermal\"]\n",
    "residual_load = loads_p2.sum(axis=1) - prods_p_total.sum(axis=1)\n",
    "proportion_solar_wind2 = pd.DataFrame({\"total_load\": loads_p2.sum(axis=1),\n",
    "                                      \"total_solar\": prods_p_total[gen_solar_name2].sum(axis=1),\n",
    "                                      \"total_wind\": prods_p_total[gen_wind_name2].sum(axis=1),\n",
    "                                      \"total_hydro\": prods_p_total[gen_hydro_name2].sum(axis=1),\n",
    "                                      \"total_nuclear\": prods_p_total[gen_nuclear_name2].sum(axis=1),\n",
    "                                      \"total_thermal\": prods_p_total[gen_thermal_name2].sum(axis=1),\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = ['solar','wind','hydro', \"nuclear\", \"thermal\"]\n",
    "values2 = [proportion_solar_wind2[\"total_solar\"].sum(),\n",
    "           proportion_solar_wind2[\"total_wind\"].sum(),\n",
    "           proportion_solar_wind2[\"total_hydro\"].sum(),\n",
    "           proportion_solar_wind2[\"total_nuclear\"].sum(),\n",
    "           proportion_solar_wind2[\"total_thermal\"].sum(),\n",
    "          ]\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels2,\n",
    "                             values=values2,\n",
    "                             marker_colors=[SOLAR_COLOR, WIND_COLOR, HYDRO_COLOR, NUKE_COLOR, THERMAL_COLOR],\n",
    "                            text=[f\"{round(el / 12., -3):,.0f} MWh\" for el in values2]\n",
    "                            )]\n",
    "                             \n",
    "                )\n",
    "fig.update_layout(\n",
    "    title=f\"Share of energy produced depending on energy type\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the \"OPF\" did not curtail too much\n",
    "\n",
    "Be carefull, there are \"noise\" in the generation now ! This is why the \"prod_p_renew_orig\" has been loaded and is used here !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to rounding\n",
    "assert np.all((prods_p_total[gen_wind_name] - prods_p_total_gen[gen_wind_name2]).max() <= 0.100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max amount \"curtailed\" by the optimiser, we should get close to 0.\n",
    "(prods_p_total[gen_wind_name] - prods_p_total_gen[gen_wind_name2]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of that should be really, really close to 0., it's the amount\n",
    "# of energy \"lost\" because of constraints on the controlable generators\n",
    "total_curtailed_generation_pct = 100. * (prods_p_total[gen_wind_name] - prods_p_total_gen[gen_wind_name2]).abs().sum() / prods_p_total_gen[gen_wind_name].sum()\n",
    "print(total_curtailed_generation_pct)\n",
    "assert np.all(total_curtailed_generation_pct <= 0.6) # below 0.5% is ok, 0.6-0.7 is a maximum\n",
    "# TODO check this by month !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prods_p_total_gen[gen_wind_name2[0]].iplot()\n",
    "nm_gen = gen_wind_name[0]\n",
    "fig = go.Figure(data=[go.Scatter(y=prods_p_total[nm_gen][::12], name=\"actual generation\"),\n",
    "                      go.Scatter(y=prods_p_total_gen[nm_gen][::12], name=\"possible generation\"),\n",
    "                     ]\n",
    "               )\n",
    "fig.update_layout(\n",
    "    title=f\"Comparison of generation for wind generator {nm_gen}\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# due to rounding\n",
    "assert np.all((prods_p_total[gen_solar_name] - prods_p_total_gen[gen_solar_name2]).max() <= 0.100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max amount \"curtailed\" by the optimiser, we should get close to 0.\n",
    "(prods_p_total[gen_solar_name] - prods_p_total_gen[gen_solar_name2]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all of that should be really, really close to 0., it's the amount\n",
    "# of energy \"lost\" because of constraints on the controlable generators\n",
    "total_curtailed_generation_pct = 100. * (prods_p_total[gen_solar_name] - prods_p_total_gen[gen_solar_name2]).abs().sum() / prods_p_total_gen[gen_solar_name].sum()\n",
    "print(total_curtailed_generation_pct)\n",
    "assert np.all(total_curtailed_generation_pct <= 0.1)  # below 0.1% is ok !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nm_gen = gen_solar_name[0]\n",
    "fig = go.Figure(data=[go.Scatter(y=prods_p_total[nm_gen], name=\"actual generation\"),\n",
    "                      go.Scatter(y=prods_p_total_gen[nm_gen], name=\"possible generation\"),\n",
    "                     ]\n",
    "               )\n",
    "fig.update_layout(\n",
    "    title=f\"Comparison of generation for solar generator {nm_gen}\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check possible bugs\n",
    "\n",
    "#### check loads meet demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_loss = prods_p_total.sum(axis=1) / loads_p.sum(axis=1)\n",
    "print(ratio_loss.max() - ratio_loss.min())\n",
    "assert (ratio_loss.max() - ratio_loss.min()) <= 3e-3  # with rounding this can vary a little"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for renewable generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_solar_above_pmax = prods_p_total[gen_solar_name] > env118_withoutchron.gen_pmax[is_gen_solar]\n",
    "all_solar_below_pmin = prods_p_total[gen_solar_name] < env118_withoutchron.gen_pmin[is_gen_solar]\n",
    "\n",
    "all_wind_above_pmax = prods_p_total[gen_wind_name] > env118_withoutchron.gen_pmax[is_gen_wind]\n",
    "all_wind_below_pmin = prods_p_total[gen_wind_name] < env118_withoutchron.gen_pmin[is_gen_wind]\n",
    "\n",
    "assert np.all(all_solar_above_pmax.sum() == 0), f\"some solar are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "assert np.all(all_solar_below_pmin.sum() == 0), f\"some solar are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "assert np.all(all_wind_above_pmax.sum() == 0), f\"some wind are above pmax:\\n{all_wind_above_pmax.sum()})\"\n",
    "assert np.all(all_wind_below_pmin.sum() == 0), f\"some wind are below pmin:\\n{all_wind_below_pmin.sum()}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_controlable_gens(gen_name, env, prods_p_total):\n",
    "    pmax_ = np.array([env.gen_pmax[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    pmax_ = pmax_.ravel()\n",
    "    check_pmax = prods_p_total[gen_name] > pmax_\n",
    "\n",
    "    pmin_ = np.array([env.gen_pmin[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    pmin_ = pmin_.ravel()\n",
    "    check_pmin = prods_p_total[gen_name] < pmin_\n",
    "\n",
    "    max_up_ = np.array([env.gen_max_ramp_up[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    max_up_ = max_up_.ravel()\n",
    "    max_down_ = np.array([env.gen_max_ramp_down[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    max_down_ = max_down_.ravel()\n",
    "    delta_gen_ = prods_p_total[gen_name].diff()  # prods_p_total.diff(t) = prods_p_total(t) - prods_p_total(t-1)\n",
    "    check_max_up = delta_gen_ > max_up_\n",
    "    check_max_down = delta_gen_ < -max_down_\n",
    "    # remove the \"interface\" between the months\n",
    "    check_max_up[::(weeks * 7 * 288 - 1)] = False\n",
    "    check_max_down[::(weeks * 7 * 288 - 1)] = False\n",
    "    check_max_up[::(weeks * 7 * 288 )] = False\n",
    "    check_max_down[::(weeks * 7 * 288)] = False\n",
    "    return check_pmax, check_pmin, check_max_up, check_max_down\n",
    "\n",
    "def check_all_controlable_gens(prods_p_total, gen_hydro_name2, gen_nuclear_name2, gen_thermal_name2, env118_withoutchron):\n",
    "    check_pmax_hydro, check_pmin_hydro, check_max_up_hydro, check_max_down_hydro = check_controlable_gens(\n",
    "        gen_hydro_name2, env118_withoutchron, prods_p_total)\n",
    "    check_pmax_nuclear, check_pmin_nuclear, check_max_up_nuclear, check_max_down_nuclear = check_controlable_gens(\n",
    "        gen_nuclear_name2, env118_withoutchron, prods_p_total)\n",
    "    check_pmax_thermal, check_pmin_thermal, check_max_up_thermal, check_max_down_thermal = check_controlable_gens(\n",
    "        gen_thermal_name2, env118_withoutchron, prods_p_total)\n",
    "\n",
    "    errors = []\n",
    "    if not np.all(check_pmax_hydro.sum() == 0):\n",
    "        errors.append(f\"some hydro are above pmax:\\n{check_pmax_hydro.sum()}\")\n",
    "    if not np.all(check_pmin_hydro.sum() == 0):\n",
    "        errors.append(f\"some hydro are below pmin:\\n{check_pmin_hydro.sum()}\")\n",
    "    if not np.all(check_max_up_hydro.sum() == 0):\n",
    "        errors.append(f\"some hydro are above max_up:\\n{check_max_up_hydro.sum()}\")\n",
    "    if not np.all(check_max_down_hydro.sum() == 0):\n",
    "        errors.append(f\"some hydro are below max_down:\\n{check_max_down_hydro.sum()}\")\n",
    "\n",
    "    if not np.all(check_pmax_nuclear.sum() == 0):\n",
    "        errors.append(f\"some nuclear are above pmax:\\n{check_pmax_nuclear.sum()}\")\n",
    "    if not np.all(check_pmin_nuclear.sum() == 0):\n",
    "        errors.append(f\"some nuclear are below pmin:\\n{check_pmin_nuclear.sum()}\")\n",
    "    if not np.all(check_max_up_nuclear.sum() == 0):\n",
    "        errors.append(f\"some nuclear are above max_up:\\n{check_max_up_nuclear.sum()}\")\n",
    "    if not np.all(check_max_down_nuclear.sum() == 0):\n",
    "        errors.append(f\"some nuclear are below max_down:\\n{check_max_down_nuclear.sum()}\")\n",
    "\n",
    "    if not np.all(check_pmax_thermal.sum() == 0):\n",
    "        errors.append(f\"some thermal are above pmax:\\n{check_pmax_thermal.sum()}\")\n",
    "    if not np.all(check_pmin_thermal.sum() == 0):\n",
    "        errors.append(f\"some thermal are below pmin:\\n{check_pmin_thermal.sum()}\")\n",
    "    if not np.all(check_max_up_thermal.sum() == 0):\n",
    "        errors.append(f\"some thermal are above max_up:\\n{check_max_up_thermal.sum()}\")\n",
    "    if not np.all(check_max_down_thermal.sum() == 0):\n",
    "        errors.append(f\"some thermal are below max_down:\\n{check_max_down_thermal.sum()}\")\n",
    "\n",
    "    return errors\n",
    "\n",
    "errors = check_all_controlable_gens(prods_p_total, gen_hydro_name2, gen_nuclear_name2, gen_thermal_name2, env118_withoutchron)\n",
    "if len(errors) != 0:\n",
    "    for el in errors:\n",
    "        print(el)\n",
    "print(f\"It's now time to look at the 'KPI' and the productions / loads generated at :\\n\\t{path_data_generated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C) Fix the loss of the grid\n",
    "\n",
    "Make sure the data generated can be loaded with grid2op framework\n",
    "\n",
    "This part might not work on microsoft windows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Parameters import Parameters\n",
    "from lightsim2grid import LightSimBackend  # might need \"pip install lightsim2grid\"\n",
    "import shutil\n",
    "from grid2op.Chronics import FromNPY\n",
    "# TODO TQDM !\n",
    "\n",
    "path_chronics_outputopf = os.path.join(OUTPUT_FOLDER, \"all_scenarios\")\n",
    "shutil.rmtree(path_chronics_outputopf)\n",
    "if not os.path.exists(path_chronics_outputopf):\n",
    "    os.mkdir(path_chronics_outputopf)\n",
    "    \n",
    "path_chronics_fixed = os.path.join(OUTPUT_FOLDER, \"fixed_chronics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_date in li_months:\n",
    "    for scen_id in range(n_scenarios):\n",
    "        path_data_generated = os.path.join(OUTPUT_FOLDER, \"generation\", CASE, start_date, f\"Scenario_{scen_id}\")\n",
    "        path_ = os.path.abspath(os.path.join(path_chronics_outputopf, f\"{start_date}_{scen_id}\"))\n",
    "        if os.path.exists(os.path.join(path_data_generated, \"DISPATCH_FAILED\")):\n",
    "            # dispatched has failed for this one\n",
    "            continue\n",
    "        os.symlink(path_data_generated, path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = env118_withoutchron.parameters\n",
    "param.NO_OVERFLOW_DISCONNECTION = True\n",
    "env_for_loss = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    chronics_path=path_chronics_outputopf,\n",
    "    param=param,\n",
    "    backend=LightSimBackend()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slack_id = 37\n",
    "np.where(env_for_loss.backend.init_pp_backend._grid.gen[\"slack\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_real_gen(target, row_id, obs, env, prev=None, slack_id=None, rounding_margin=0.2):\n",
    "    target[row_id, env.gen_renewable] = obs.gen_p[env.gen_renewable]\n",
    "    loss = np.sum(obs.gen_p) - np.sum(obs.load_p)  # actual loss of the grid\n",
    "    # if False:\n",
    "\n",
    "    # split what the slack absorbed in the controlable generators\n",
    "    gen_p_setpoint = env.chronics_handler.real_data.data.prod_p[row_id]\n",
    "    to_split = np.sum(obs.gen_p) - np.sum(gen_p_setpoint)\n",
    "    total_margin = None\n",
    "    delta_previous = 0.\n",
    "\n",
    "    can_adjust = copy.deepcopy(~env.gen_renewable)\n",
    "    can_adjust[slack_id] = False\n",
    "    slack_abs = gen_p_setpoint[slack_id]  # obs.gen_p[slack_id]  # gen_p_setpoint[slack_id]\n",
    "    \n",
    "    slack_id_controlable = np.where(np.arange(obs.n_gen)[can_adjust] == slack_id)[0]\n",
    "    \n",
    "    if to_split > 0.:\n",
    "        total_margin = np.minimum(obs.gen_max_ramp_up[can_adjust] - delta_previous, \n",
    "                                  obs.gen_pmax[can_adjust] - obs.gen_p[can_adjust])\n",
    "    else:\n",
    "        total_margin = np.minimum(obs.gen_max_ramp_down[can_adjust] + delta_previous, \n",
    "                                  obs.gen_p[can_adjust] - obs.gen_pmin[can_adjust])\n",
    "            \n",
    "    if prev is not None:\n",
    "        delta_previous = gen_p_setpoint[can_adjust] - prev[can_adjust]\n",
    "        gen_up = delta_previous > 0.\n",
    "        gen_down = delta_previous < 0.\n",
    "        \n",
    "        # there is 4 cases:\n",
    "        if to_split > 0.:\n",
    "            # generators up: less margin (because the should \"get up more\")\n",
    "            total_margin[gen_up] = np.minimum(obs.gen_pmax[can_adjust][gen_up] - gen_p_setpoint[can_adjust][gen_up],\n",
    "                                              obs.gen_max_ramp_up[can_adjust][gen_up] + delta_previous[gen_up]\n",
    "                                              )\n",
    "            \n",
    "            # generators down: more margin (because the should get down, but the split is up)\n",
    "            total_margin[gen_down] = np.minimum(obs.gen_pmax[can_adjust][gen_down] - gen_p_setpoint[can_adjust][gen_down],\n",
    "                                                obs.gen_max_ramp_up[can_adjust][gen_down] + delta_previous[gen_down]\n",
    "                                                )\n",
    "            total_margin[gen_down] = np.minimum(rounding_margin + 0.01, total_margin[gen_down])\n",
    "        else:\n",
    "            # generators up: more margin (because the should \"get up more\")\n",
    "            total_margin[gen_up] = np.minimum(gen_p_setpoint[can_adjust][gen_up] - obs.gen_pmin[can_adjust][gen_up],\n",
    "                                              obs.gen_max_ramp_down[can_adjust][gen_up] + delta_previous[gen_up]\n",
    "                                              )\n",
    "            \n",
    "            # generators down: less margin (because the should get down, but the split is up)\n",
    "            total_margin[gen_down] = np.minimum(gen_p_setpoint[can_adjust][gen_down] - obs.gen_pmin[can_adjust][gen_down],\n",
    "                                                obs.gen_max_ramp_down[can_adjust][gen_down] + delta_previous[gen_down]\n",
    "                                                )\n",
    "            \n",
    "    total_margin[total_margin < rounding_margin] = 0.\n",
    "    total_margin[total_margin >= rounding_margin] -= rounding_margin\n",
    "    \n",
    "    turned_on = obs.gen_p[can_adjust] > 0.\n",
    "    if abs(to_split) <= abs(np.sum(total_margin[turned_on])) - rounding_margin:\n",
    "        # do not turn on turned off generators, because I can\n",
    "        total_margin[~turned_on] = 0.\n",
    "    else:\n",
    "        # print(\"\\t forced to turn on...\")\n",
    "        # total_margin_this = abs(np.sum(total_margin[~turned_off]))\n",
    "        # needed_margin = abs(to_split) - total_margin_this\n",
    "        # total_margin[turned_off] /=  total_margin_this\n",
    "        # total_margin[turned_off] *=  needed_margin\n",
    "        total_margin[~turned_on] = 0.\n",
    "        before = 1.0 * to_split\n",
    "        to_split = np.sign(to_split) * (abs(np.sum(total_margin[turned_on])) - rounding_margin)\n",
    "    # slack_abs -= to_split\n",
    "    \n",
    "    sum_margin = np.sum(total_margin)\n",
    "    redisp_ = 1.0 * gen_p_setpoint[can_adjust]\n",
    "    # redisp_ += np.sign(to_split) * total_margin\n",
    "    if sum_margin == 0.:\n",
    "        print(\"no margin for your system !\")\n",
    "    else:\n",
    "        redisp_ += to_split * total_margin / sum_margin\n",
    "    target[row_id, can_adjust] = redisp_\n",
    "    target[row_id, slack_id] = slack_abs\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_debug_id = 53\n",
    "\n",
    "final_gen_p = np.full((weeks * 7 * 288 - 1, env_for_loss.n_gen), fill_value=np.NaN, dtype=np.float32)\n",
    "final_gen_v = np.full((weeks * 7 * 288 - 1, env_for_loss.n_gen), fill_value=np.NaN, dtype=np.float32)\n",
    "final_load_p = np.full((weeks * 7 * 288 - 1, env_for_loss.n_load), fill_value=np.NaN, dtype=np.float32)\n",
    "final_load_q = np.full((weeks * 7 * 288 - 1, env_for_loss.n_load), fill_value=np.NaN, dtype=np.float32)\n",
    "all_loss_orig = np.zeros(weeks * 7 * 288 - 1)\n",
    "\n",
    "obs = env_for_loss.reset()\n",
    "i = 0\n",
    "all_loss_orig[i] = fill_real_gen(final_gen_p, i, obs, env_for_loss, slack_id=slack_id)\n",
    "final_gen_v[i] = obs.gen_v\n",
    "final_load_p[i] = obs.load_p\n",
    "final_load_q[i] = obs.load_q\n",
    "chron_name = env_for_loss.chronics_handler.get_id()\n",
    "done = False\n",
    "prev_ = obs.gen_p\n",
    "while not done:\n",
    "    obs, reward, done, info = env_for_loss.step(env_for_loss.action_space())\n",
    "    i += 1\n",
    "    all_loss_orig[i] = fill_real_gen(final_gen_p, i, obs, env_for_loss, prev=final_gen_p[i-1], slack_id=slack_id)\n",
    "    final_gen_v[i] = obs.gen_v\n",
    "    final_load_p[i] = obs.load_p\n",
    "    final_load_q[i] = obs.load_q\n",
    "    # if (final_gen_p[i][gen_debug_id] - final_gen_p[i-1][gen_debug_id]) < -obs.gen_max_ramp_down[gen_debug_id]:\n",
    "    #     import pdb\n",
    "    #     pdb.set_trace()\n",
    "    prev_ = 1.0 * obs.gen_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gen_df = pd.DataFrame(final_gen_p, columns=env_for_loss.name_gen)\n",
    "errors = check_all_controlable_gens(final_gen_df, gen_hydro_name2, gen_nuclear_name2, gen_thermal_name2, env118_withoutchron)\n",
    "if errors:\n",
    "    for el in errors:\n",
    "        print(el)\n",
    "        print()\n",
    "    raise RuntimeError(\"some constraints are not met\")\n",
    "print(\"No errors !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these numbers should be between 1-2-3% (more than 5 indicates an issue !)\n",
    "losses_pct_orig = 100. * all_loss_orig / np.sum(final_gen_p, axis=1)\n",
    "print(f\"max loss (origin grid): {losses_pct_orig.max():.2f} %\")\n",
    "print(f\"min loss (origin grid): {losses_pct_orig.min():.2f} %\")\n",
    "print(f\"avg loss (origin grid): {losses_pct_orig.mean():.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now adjust the generators schedule so that they do not move\n",
    "cond_ = True\n",
    "all_loss = 1.0 * all_loss_orig\n",
    "prev_max_diff = 100000.\n",
    "while cond_:\n",
    "    env_fixed = grid2op.make(\n",
    "        output_path,\n",
    "        test=True,\n",
    "        grid_path=grid_path, # assign it the 118 grid\n",
    "        param=param,\n",
    "        backend=LightSimBackend(),\n",
    "        chronics_class=FromNPY,\n",
    "        chronics_path=path_chronics_outputopf,\n",
    "        data_feeding_kwargs={\"load_p\": final_load_p,\n",
    "                             \"load_q\": final_load_q,\n",
    "                             \"prod_p\": final_gen_p,\n",
    "                             \"prod_v\": final_gen_v}\n",
    "        )\n",
    "    # this should be as close to 0. as possible...\n",
    "    # we might do a second \"repartition loop\" to make sure it's ok :-)\n",
    "    i = 0\n",
    "    final_gen_p_tmp = final_gen_p * np.NaN\n",
    "    diff_ = np.full((weeks * 7 * 288 - 1, env_fixed.n_gen), fill_value=np.NaN)\n",
    "    all_loss = np.zeros(weeks * 7 * 288 - 1)\n",
    "    obs = env_fixed.reset()\n",
    "    diff_[i] = obs.gen_p - final_gen_p[i]\n",
    "    all_loss[i] = fill_real_gen(final_gen_p_tmp, i, obs, env_for_loss, slack_id=slack_id)\n",
    "    prev_ = obs.gen_p\n",
    "    while True:\n",
    "        obs, reward, done, info = env_fixed.step(env_for_loss.action_space())\n",
    "        if done:\n",
    "            break\n",
    "        i += 1\n",
    "        all_loss[i] = fill_real_gen(final_gen_p_tmp, i, obs, env_for_loss, prev=final_gen_p_tmp[i-1], slack_id=slack_id)\n",
    "        diff_[i] = obs.gen_p - final_gen_p_tmp[i]\n",
    "        prev_ = 1.0 * obs.gen_p\n",
    "    max_diff = np.abs(diff_).max()\n",
    "    final_gen_p = 1.0 * final_gen_p_tmp\n",
    "    print(f\"max diff is {max_diff:.2f}\")\n",
    "    if max_diff >= prev_max_diff:\n",
    "        print(\"seems to mess something up... stopping here...\")\n",
    "        cond_ = False\n",
    "        break\n",
    "    print(prev_max_diff, max_diff)\n",
    "    prev_max_diff = copy.deepcopy(max_diff)\n",
    "    cond_ = max_diff > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these numbers should be between 1-2-3% (more than 5 indicates an issue !)\n",
    "losses_pct = 100. * all_loss / np.sum(final_gen_p, axis=1)\n",
    "print(f\"max loss: {losses_pct.max():.2f} %\")\n",
    "print(f\"min loss: {losses_pct.min():.2f} %\")\n",
    "print(f\"avg loss: {losses_pct.mean():.2f} %\")\n",
    "assert losses_pct.max() <= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ = np.mean(losses_pct)\n",
    "fig = go.Figure(data=[go.Histogram(x=losses_pct)])\n",
    "# fig.add_trace(go.Scatter(x=[avg_, avg_], y =[0, 100], mode=\"lines\", name=\"average\"))\n",
    "fig.add_vline(x = avg_, line_dash='dash', line_color=\"red\")\n",
    "fig.update_layout(title=\"Loss on the grid (%) [should be around 2-3% on average]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now that the generation \"does not move\", we check that it meets the physical constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gen_df = pd.DataFrame(final_gen_p, columns=env_for_loss.name_gen)\n",
    "errors = check_all_controlable_gens(final_gen_df, gen_hydro_name2, gen_nuclear_name2, gen_thermal_name2, env118_withoutchron)\n",
    "if errors:\n",
    "    for el in errors:\n",
    "        print(el)\n",
    "        print()\n",
    "    raise RuntimeError(\"some constraints are not met\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(final_gen_df[\"gen_41_19\"].diff()).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we save the data in the right format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(final_load_p, columns=env_for_loss.name_load).to_csv(...)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
