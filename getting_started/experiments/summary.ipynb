{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are trying to modify the power plants of this grid to obtain this energy mix:\n",
    "<img src=\"images/target_em.png\" width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import grid2op\n",
    "from grid2op.Chronics import ChangeNothing\n",
    "from chronix2grid.kpi.Generator_parameter_checker import EnergyMix_AprioriChecker\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "from grid2op.PlotGrid import NUKE_COLOR, THERMAL_COLOR, WIND_COLOR, SOLAR_COLOR, HYDRO_COLOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We load the original prods_charac.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"case118_l2rpn_wcci_benjamin\"\n",
    "path_ref = os.path.join(\"..\", \"example\", \"input\", \"generation\")\n",
    "path_tmp = os.path.join(\"..\", \"example\", \"custom\", \"input\", \"generation\")\n",
    "input_path = os.path.join(path_ref, env_name)\n",
    "df = pd.read_csv(os.path.join(input_path, \"prods_charac.csv\"))\n",
    "\n",
    "avg_pmaxs = df.groupby([\"type\"])[\"Pmax\"].mean()\n",
    "types = avg_pmaxs.index.to_numpy()\n",
    "avg_pmaxs = avg_pmaxs.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_by_type(info):\n",
    "  res = []\n",
    "  for t in types:\n",
    "    res.append(df[df[\"type\"] == t].iloc[0][info])\n",
    "  return np.array(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We recover some informations about each power plant type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(input_path, \"prods_charac.csv\"))\n",
    "\n",
    "\n",
    "n = df.shape[0]\n",
    "pmaxs = [250.0, 400.0, 74.7, 200.0, 67.2]\n",
    "max_ramp_up = get_info_by_type(\"max_ramp_up\")\n",
    "max_ramp_down = get_info_by_type(\"max_ramp_down\")\n",
    "min_up_time = get_info_by_type(\"min_up_time\")\n",
    "min_down_time = get_info_by_type(\"min_down_time\")\n",
    "marginal_cost = get_info_by_type(\"marginal_cost\")\n",
    "shut_down_cost = get_info_by_type(\"shut_down_cost\")\n",
    "start_cost = get_info_by_type(\"start_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We load the solution returned by the solver and modify the original csv according to the solution\n",
    "\n",
    "YOUR \"SOLVER\" DO NOT WORK AT ALL !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\"optimization/solver/build/result.txt\")\n",
    "# for i in range(n):\n",
    "#   idx = int(file.readline())\n",
    "#   df.at[i, \"type\"] = types[idx]\n",
    "#   df.at[i, \"Pmax\"] = pmaxs[idx]\n",
    "#   df.at[i, \"max_ramp_up\"] = max_ramp_up[idx]\n",
    "#   df.at[i, \"max_ramp_down\"] = max_ramp_down[idx]\n",
    "#   df.at[i, \"min_up_time\"] = min_up_time[idx]\n",
    "#   df.at[i, \"min_down_time\"] = min_down_time[idx]\n",
    "#   df.at[i, \"marginal_cost\"] = marginal_cost[idx]\n",
    "#   df.at[i, \"shut_down_cost\"] = shut_down_cost[idx]\n",
    "#   df.at[i, \"start_cost\"] = start_cost[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There is much more wind power plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(path_tmp, env_name)\n",
    "df.to_csv(os.path.join(output_path, \"prods_charac.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_factor = np.array([30, 95, 15, np.nan, 25])\n",
    "average_load = 2800\n",
    "capacity_factor_df = pd.DataFrame(data=capacity_factor, columns=['capacity_factor'], index=types)\n",
    "\n",
    "grid_path = os.path.join(output_path, \"grid.json\")\n",
    "env118_withoutchron = grid2op.make(\n",
    "    output_path,\n",
    "    test=True,\n",
    "    grid_path=grid_path, # assign it the 118 grid\n",
    "    chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    ")\n",
    "\n",
    "Target_EM_percentage=pd.DataFrame(data=[9, 36, 17, 2, 36], columns=['target_energy_mix'], index=types)\n",
    "\n",
    "#Variable used to anticipate the energy mix a priori. Update them after chronics generation if too different\n",
    "PeakLoad = 4200 #expected peak load\n",
    "\n",
    "EnergyMix_AprioriChecker(env118_withoutchron, Target_EM_percentage, PeakLoad, average_load, capacity_factor_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can see that the difference between the target energy mix and the apriori energy mix is 45%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now try to generate the loads / renewable to make sure the generated data are compatible with the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "notebook_folder=%pwd\n",
    "\n",
    "# define your input folder\n",
    "INPUT_FOLDER = os.path.join(notebook_folder, '..', 'example', 'custom', 'input')\n",
    "\n",
    "OUTPUT_FOLDER = os.path.join(notebook_folder, '..', 'example', 'custom', 'output')\n",
    "\n",
    "# Detailed configuration to be set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "start_date = \"2012-01-01\"\n",
    "weeks = 4\n",
    "n_scenarios = 1\n",
    "by_n_weeks = 4\n",
    "\n",
    "mode = 'RLTK'\n",
    "mode = 'RL'\n",
    "\n",
    "\n",
    "CASE = env_name\n",
    "\n",
    "load_seed = 7\n",
    "renewable_seed = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cli_chronix2grid=\"chronix2grid \\\n",
    "                         --mode {} --output-folder {} --input-folder {} --ignore-warnings \\\n",
    "                         --weeks {} --case {} --n_scenarios {} --start-date {} --by-n-weeks {} \\\n",
    "                          --seed-for-loads {}  --seed-for-res {}\".format(\n",
    "                         mode, OUTPUT_FOLDER, INPUT_FOLDER, weeks, CASE, n_scenarios, start_date,by_n_weeks,\n",
    "                         load_seed, renewable_seed)\n",
    "cli_chronix2grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But it doesn't converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$cli_chronix2grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data_generated = os.path.join(OUTPUT_FOLDER, \"generation\", CASE, start_date, \"Scenario_0\")\n",
    "loads_p = pd.read_csv(os.path.join(path_data_generated, \"load_p.csv.bz2\"), sep=\";\")\n",
    "prods_p_renewable = pd.read_csv(os.path.join(path_data_generated, \"prod_p.csv.bz2\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gen_solar = env118_withoutchron.gen_type == \"solar\"\n",
    "is_gen_wind = env118_withoutchron.gen_type == \"wind\"\n",
    "gen_solar_name = env118_withoutchron.name_gen[is_gen_solar]\n",
    "gen_wind_name = env118_withoutchron.name_gen[is_gen_wind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_load = loads_p.sum(axis=1) - prods_p_renewable.sum(axis=1)\n",
    "proportion_solar_wind = pd.DataFrame({\"total_load\": loads_p.sum(axis=1),\n",
    "                                      \"total_solar\": prods_p_renewable[gen_solar_name].sum(axis=1),\n",
    "                                      \"total_wind\": prods_p_renewable[gen_wind_name].sum(axis=1),\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gen_possible = np.sum(env118_withoutchron.gen_pmin[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_possible = np.sum(env118_withoutchron.gen_pmax[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_up_possible = np.sum(env118_withoutchron.gen_max_ramp_up[env118_withoutchron.gen_redispatchable])\n",
    "max_gen_down_possible = np.sum(env118_withoutchron.gen_max_ramp_down[env118_withoutchron.gen_redispatchable])\n",
    "loss_ratio = 0.95  # takes into account some loss (conservative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Share of renewables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['solar','wind','unknown']\n",
    "values = [proportion_solar_wind[\"total_solar\"].sum(),\n",
    "          proportion_solar_wind[\"total_wind\"].sum(),\n",
    "          proportion_solar_wind[\"total_load\"].sum() - proportion_solar_wind[\"total_solar\"].sum() - proportion_solar_wind[\"total_wind\"].sum()\n",
    "         ]\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels,\n",
    "                             values=values,\n",
    "                             marker_colors=[SOLAR_COLOR, WIND_COLOR, 'rgba(0,0,0, 0.05)'],\n",
    "                             text=[f\"{round(el / 12., -3):,.0f} MWh\" for el in values])\n",
    "                     ]\n",
    "               )\n",
    "fig.update_layout(\n",
    "    title=f\"This has only run on {weeks} weeks, the target is for a whole year !!!\"\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic infeasibilities\n",
    "\n",
    "The section bellow check that the market dispatch has a chance to converge. If something is violated here, \n",
    "then there is now way the market dispatch can work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "due_pmin = residual_load < min_gen_possible\n",
    "due_pmax = residual_load > loss_ratio * max_gen_possible\n",
    "delta_gen = residual_load.diff()  # diff(t) = residual_load(t) - residual_load(t-1)\n",
    "due_rampmax = delta_gen > max_gen_up_possible\n",
    "due_rampmin = delta_gen < -max_gen_up_possible\n",
    "print(f\"There are (at least) {due_pmin.sum()} infeasibilities due to pmin ({100. * due_pmin.sum() / due_pmin.shape[0]:.0f}%)\")\n",
    "print(f\"There are (at least) {due_pmax.sum()} infeasibilities due to pmax ({100. * due_pmax.sum() / due_pmax.shape[0]:.0f}%)\")\n",
    "print(f\"There are (at least) {due_rampmax.sum()} infeasibilities due to ramp up ({100. * due_rampmax.sum() / due_rampmax.shape[0]:.0f}%)\")\n",
    "print(f\"There are (at least) {due_rampmin.sum()} infeasibilities due to ramp down ({100. * due_rampmin.sum() / due_rampmin.shape[0]:.0f}%)\")\n",
    "assert np.all(~due_pmin) and np.all(~due_pmax) and np.all(~due_rampmax) and np.all(~due_rampmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check config working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_solar_above_pmax = prods_p_renewable[gen_solar_name] > env118_withoutchron.gen_pmax[is_gen_solar]\n",
    "all_solar_below_pmin = prods_p_renewable[gen_solar_name] < env118_withoutchron.gen_pmin[is_gen_solar]\n",
    "\n",
    "all_wind_above_pmax = prods_p_renewable[gen_wind_name] > env118_withoutchron.gen_pmax[is_gen_wind]\n",
    "all_wind_below_pmin = prods_p_renewable[gen_wind_name] < env118_withoutchron.gen_pmin[is_gen_wind]\n",
    "\n",
    "assert np.all(all_solar_above_pmax.sum() == 0), f\"some solar are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "assert np.all(all_solar_below_pmin.sum() == 0), f\"some solar are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "assert np.all(all_wind_above_pmax.sum() == 0), f\"some wind are above pmax:\\n{all_wind_above_pmax.sum()})\"\n",
    "assert np.all(all_wind_below_pmin.sum() == 0), f\"some wind are below pmin:\\n{all_wind_below_pmin.sum()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now start the redispatching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE_DISPATCH = \"RLDT\"\n",
    "seed_dispatch = 0\n",
    "cli_chronix2grid2=\"chronix2grid \\\n",
    "                         --mode {} --output-folder {} --input-folder {} --ignore-warnings \\\n",
    "                         --weeks {} --case {} --n_scenarios {} --start-date {} --by-n-weeks {} \\\n",
    "                          --seed-for-loads {}  --seed-for-res {} --seed-for-dispatch {}\".format(\n",
    "                         MODE_DISPATCH, OUTPUT_FOLDER, INPUT_FOLDER, weeks, CASE, n_scenarios, start_date,by_n_weeks,\n",
    "                         load_seed, renewable_seed, seed_dispatch)\n",
    "cli_chronix2grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$cli_chronix2grid2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prods_p_total = pd.read_csv(os.path.join(path_data_generated, \"prod_p.csv.bz2\"), sep=\";\")\n",
    "assert prods_p_total.shape[1] == env118_withoutchron.n_gen\n",
    "loads_p2 = pd.read_csv(os.path.join(path_data_generated, \"load_p.csv.bz2\"), sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_solar_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"solar\"]\n",
    "gen_wind_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"wind\"]\n",
    "gen_hydro_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"hydro\"]\n",
    "gen_nuclear_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"nuclear\"]\n",
    "gen_thermal_name2 = env118_withoutchron.name_gen[env118_withoutchron.gen_type == \"thermal\"]\n",
    "residual_load = loads_p2.sum(axis=1) - prods_p_total.sum(axis=1)\n",
    "proportion_solar_wind2 = pd.DataFrame({\"total_load\": loads_p2.sum(axis=1),\n",
    "                                      \"total_solar\": prods_p_total[gen_solar_name2].sum(axis=1),\n",
    "                                      \"total_wind\": prods_p_total[gen_wind_name2].sum(axis=1),\n",
    "                                      \"total_hydro\": prods_p_total[gen_hydro_name2].sum(axis=1),\n",
    "                                      \"total_nuclear\": prods_p_total[gen_nuclear_name2].sum(axis=1),\n",
    "                                      \"total_thermal\": prods_p_total[gen_thermal_name2].sum(axis=1),\n",
    "                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = ['solar','wind','hydro', \"nuclear\", \"thermal\"]\n",
    "values2 = [proportion_solar_wind2[\"total_solar\"].sum(),\n",
    "           proportion_solar_wind2[\"total_wind\"].sum(),\n",
    "           proportion_solar_wind2[\"total_hydro\"].sum(),\n",
    "           proportion_solar_wind2[\"total_nuclear\"].sum(),\n",
    "           proportion_solar_wind2[\"total_thermal\"].sum(),\n",
    "          ]\n",
    "\n",
    "fig = go.Figure(data=[go.Pie(labels=labels2,\n",
    "                             values=values2,\n",
    "                             marker_colors=[SOLAR_COLOR, WIND_COLOR, HYDRO_COLOR, NUKE_COLOR, THERMAL_COLOR],\n",
    "                            text=[f\"{round(el / 12., -3):,.0f} MWh\" for el in values2]\n",
    "                            )]\n",
    "                             \n",
    "                )\n",
    "fig.update_layout(\n",
    "    title=f\"This has only run on {weeks} weeks, the target is for a whole year !!!\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check possible bugs\n",
    "\n",
    "#### for renewable generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_solar_above_pmax = prods_p_total[gen_solar_name] > env118_withoutchron.gen_pmax[is_gen_solar]\n",
    "all_solar_below_pmin = prods_p_total[gen_solar_name] < env118_withoutchron.gen_pmin[is_gen_solar]\n",
    "\n",
    "all_wind_above_pmax = prods_p_total[gen_wind_name] > env118_withoutchron.gen_pmax[is_gen_wind]\n",
    "all_wind_below_pmin = prods_p_total[gen_wind_name] < env118_withoutchron.gen_pmin[is_gen_wind]\n",
    "\n",
    "assert np.all(all_solar_above_pmax.sum() == 0), f\"some solar are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "assert np.all(all_solar_below_pmin.sum() == 0), f\"some solar are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "assert np.all(all_wind_above_pmax.sum() == 0), f\"some wind are above pmax:\\n{all_wind_above_pmax.sum()})\"\n",
    "assert np.all(all_wind_below_pmin.sum() == 0), f\"some wind are below pmin:\\n{all_wind_below_pmin.sum()}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_name = gen_hydro_name2\n",
    "\n",
    "def check_controlable_gens(gen_name, env, prods_p_total):\n",
    "    pmax_ = np.array([env.gen_pmax[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    pmax_ = pmax_.ravel()\n",
    "    check_pmax = prods_p_total[gen_name] > pmax_\n",
    "\n",
    "    pmin_ = np.array([env.gen_pmin[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    pmin_ = pmin_.ravel()\n",
    "    check_pmin = prods_p_total[gen_name] < pmin_\n",
    "\n",
    "    max_up_ = np.array([env.gen_max_ramp_up[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    max_up_ = max_up_.ravel()\n",
    "    max_down_ = np.array([env.gen_max_ramp_down[np.where(env.name_gen == nm_)[0]] for nm_ in gen_name])\n",
    "    max_down_ = max_down_.ravel()\n",
    "    delta_gen_ = prods_p_total[gen_name].diff()  # prods_p_total.diff(t) = prods_p_total(t) - prods_p_total(t-1)\n",
    "    check_max_up = delta_gen_ > max_up_\n",
    "    check_max_down = delta_gen_ < -max_down_\n",
    "    return check_pmax, check_pmin, check_max_up, check_max_down\n",
    "\n",
    "check_pmax_hydro, check_pmin_hydro, check_max_up_hydro, check_max_down_hydro = check_controlable_gens(\n",
    "    gen_hydro_name2, env118_withoutchron, prods_p_total)\n",
    "check_pmax_nuclear, check_pmin_nuclear, check_max_up_nuclear, check_max_down_nuclear = check_controlable_gens(\n",
    "    gen_nuclear_name2, env118_withoutchron, prods_p_total)\n",
    "check_pmax_thermal, check_pmin_thermal, check_max_up_thermal, check_max_down_thermal = check_controlable_gens(\n",
    "    gen_thermal_name2, env118_withoutchron, prods_p_total)\n",
    "\n",
    "assert np.all(check_pmax_hydro.sum() == 0), f\"some hydro are above pmax:\\n{all_solar_above_pmax.sum()}\"\n",
    "assert np.all(check_pmin_hydro.sum() == 0), f\"some hydro are below pmin:\\n{all_solar_below_pmin.sum()}\"\n",
    "assert np.all(check_max_up_hydro.sum() == 0), f\"some hydro are above max_up:\\n{check_max_up_hydro.sum()}\"\n",
    "assert np.all(check_max_down_hydro.sum() == 0), f\"some hydro are below max_down:\\n{check_max_down_hydro.sum()}\"\n",
    "\n",
    "assert np.all(check_pmax_nuclear.sum() == 0), f\"some nuclear are above pmax:\\n{check_pmax_nuclear.sum()}\"\n",
    "assert np.all(check_pmin_nuclear.sum() == 0), f\"some nuclear are below pmin:\\n{check_pmin_nuclear.sum()}\"\n",
    "assert np.all(check_max_up_nuclear.sum() == 0), f\"some nuclear are above max_up:\\n{check_max_up_nuclear.sum()}\"\n",
    "assert np.all(check_max_down_nuclear.sum() == 0), f\"some nuclear are below max_down:\\n{check_max_down_nuclear.sum()}\"\n",
    "\n",
    "assert np.all(check_pmax_thermal.sum() == 0), f\"some thermal are above pmax:\\n{check_pmax_thermal.sum()}\"\n",
    "assert np.all(check_pmin_thermal.sum() == 0), f\"some thermal are below pmin:\\n{check_pmin_thermal.sum()}\"\n",
    "assert np.all(check_max_up_thermal.sum() == 0), f\"some thermal are above max_up:\\n{check_max_up_thermal.sum()}\"\n",
    "assert np.all(check_max_down_thermal.sum() == 0), f\"some thermal are below max_down:\\n{check_max_down_thermal.sum()}\"\n",
    "\n",
    "print(\"All checks passed !\\n\")\n",
    "\n",
    "print(f\"It's now time to look at the 'KPI' and the productions / loads generated at :\\n\\t{path_data_generated}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
