{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how to get a first grid2op environment, then use the data it needs to generate some loads and renewables (and a shitty market design) and load this second environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import grid2op\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid2op.ChronicsHandler import ChangeNothing\n",
    "from grid2op.PlotMatplotlib import GetLayout\n",
    "print(\"This notebook uses the last dev version of grid2op. You can install it with:\\n\"\\\n",
    "      \"\\t{} -m pip install git+https://github.com/bdonnot/grid2op.git@betternotebooks --user\".format(sys.executable))\n",
    "\n",
    "#path_grid = os.path.join(\"data\", \"case118_l2rpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronix2grid modules\n",
    "sys.path.insert(0, '..')\n",
    "import generation.generate_chronics as gen\n",
    "import generation.dispatch.EconomicDispatch as ec\n",
    "import generation.thermal.EDispatch_L2RPN2020.run_economic_dispatch as run_economic_dispatch\n",
    "import kpi.main as kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "## Generation step of chronix2grid\n",
    "INPUT_FOLDER = 'generation/input'\n",
    "OUTPUT_FOLDER = 'generation/output'\n",
    "CASE = 'case118_l2rpn'\n",
    "    # Detailed configuration to set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "\n",
    "\n",
    "## KPI computation phase\n",
    "KPI_INPUT_FOLDER = 'kpi/input'\n",
    "IMAGES_FOLDER = 'kpi/images'\n",
    "    # Detailed configuration to set in <KPI_INPUT_FOLDER>/params.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_grid = os.path.join(INPUT_FOLDER, CASE)\n",
    "\n",
    "env118_withoutchron = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                      grid_path=os.path.join(path_grid, \"L2RPN_2020_case118_redesigned.json\"), # assign it the 118 grid\n",
    "                      chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    "                  )\n",
    "grid_layout =  [(-403, -311), (-355, -311), (-380, -275), (-355, -245), (-369, -191), (-330, -193), (-299, -190), \n",
    "                (-366, -88),\n",
    "         (-364, -44), (-366, -7), (-320, -247), (-266, -266), (-241, -198), (-203, -231), (-188, -201), (-282, -153),\n",
    "         (-221, -123), (-161, -123), (-131, -156), (-139, -142), (-131, -27), (-123, -3), (-131, 29), (-18, -46),\n",
    "         (-162, 67), (-203, 39), (-324, 21), (-332, -15), (-331, -52), (-212, -88), (-292, -52), (-259, -29),\n",
    "         (-4, -254), (32, -203), (-34, -148), (51, -155), (74, -221), (88, -127), (59, -265), (86, -296), (129, -296),\n",
    "         (161, -296), (124, -198), (140, -226), (147, -163), (133, -138), (162, -134), (187, -173), (221, -125),\n",
    "         (268, -215), (287, -225), (199, -258), (202, -296), (237, -295), (329, -296), (283, -297), (268, -248),\n",
    "         (287, -248), (372, -277), (372, -197), (372, -153), (340, -74), (348, -254), (342, -168), (298, -29),\n",
    "         (283, -74), (297, -92), (213, -62), (184, -50), (61, -45), (40, -73), (25, -52), (61, -84), (43, 53), (61, 73),\n",
    "         (151, 73), (176, 99), (195, 53), (221, 33), (227, 73), (230, 56), (149, 131), (57, 154), (46, 171), (43, 205),\n",
    "         (43, 229), (57, 245), (78, 205), (119, 207), (122, 241), (191, 243), (196, 207), (219, 186), (245, 154),\n",
    "         (212, 154), (221, 132), (220, 110), (262, 94), (294, 74), (288, 154), (273, 230), (226, 229), (326, 230),\n",
    "         (330, 152), (365, 154), (364, 91), (404, 154), (370, 191), (373, 212), (361, 253), (330, 260), (403, 253),\n",
    "(-256, -102), (-270, 0), (-236, 1), (229, -32), (-211, -266), (99, 74)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Energy Mix apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Target_EM_percentage=pd.DataFrame(data=[4,6,35,15,40],columns=['target_energy_mix'],\n",
    "                                  index=['solar','wind','nuclear','hydro','thermal'])\n",
    "PeakLoad=4200\n",
    "AverageLoad=2800\n",
    "CapacityFactor=pd.DataFrame(data=[15,25,95,30,np.nan],columns=['capacity_factor'],\n",
    "                            index=['solar','wind','nuclear','hydro','thermal'])\n",
    "Capacity_df=EnergyMix_AprioriChecker(env118_withoutchron,Target_EM_percentage, PeakLoad, AverageLoad, CapacityFactor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Capacity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Generate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can set generation configuration such as number of scenarios, start date, number of weeks, noise intensities, timestep... in INPUT_FOLDER/CASE/params.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II A) Generate loads and renewables\n",
    "\n",
    "Chronix2grid generation process which implements Balthazar method. CSV writting takes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading parameters\n",
    "year, n_scenarios, params, loads_charac, prods_charac, load_weekly_pattern, solar_pattern, lines = gen.read_configuration(INPUT_FOLDER, CASE)\n",
    "print(year)\n",
    "gen.main(year, n_scenarios, params, INPUT_FOLDER, OUTPUT_FOLDER, prods_charac, loads_charac, lines, solar_pattern, load_weekly_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(solar_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has been generated in this folder\n",
    "chronics_path_gen = os.path.join(INPUT_FOLDER, \"dispatch\", str(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Ramps and Pmin/Pmax Generator parameters A priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the scenario you want to check first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "\n",
    "losses_pct = 3.0  # losses as pct of load\n",
    "[isThermalInTrouble,isNuclearInTrouble,IsRampUpInTrouble,IsRampDownInTrouble]=Ramps_Pmax_Pmin_APrioriCheckers(\n",
    "    env118_withoutchron,Capacity_df,chronics_path_gen,losses_pct,PeakLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(isThermalInTrouble)\n",
    "print(isNuclearInTrouble)\n",
    "print(IsRampUpInTrouble)\n",
    "print(IsRampDownInTrouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Aposteriori_renewableCapacityFactor_Checkers(env118_withoutchron,Capacity_df, chronics_path_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute some KPIs for solar, wind and load\n",
    "\n",
    "#### Good comparison can be obtained by setting \"renewable_ninja\" as comparison in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "Images are saved in IMAGES_FOLDER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_solar_only = True\n",
    "if not os.path.exists(KPI_INPUT_FOLDER):\n",
    "    os.mkdir(KPI_INPUT_FOLDER)\n",
    "kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, IMAGES_FOLDER, year, CASE, n_scenarios, wind_solar_only, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The EconomicDispatch instance : a high level wrapper around a Pypsa net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install PyPSA correctly <br>\n",
    "`pip3 install -U git+http://github.com/PyPSA/PyPSA.git@8d527e25fa9876cac66957448f449a1c901901d2`\n",
    "\n",
    "You also need to install the solver that pypsa is calling. For instance cbc solver. On Fedora do `dnf install coin-or-Cbc.x86_64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch = ec.Dispatch.from_gri2op_env(env118_withoutchron)\n",
    "dispatch.modify_marginal_costs({'hydro': 8, 'nuclear': 3})\n",
    "dispatch.read_hydro_guide_curves(os.path.join(INPUT_FOLDER, 'patterns', 'hydro.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch.plot_ramps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II B) Run a unit commitment model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use pypsa. To avoid messing with the names, and make sure to have data in the proper shape, it is better, I think, to create the pypsa network directly from the grid2op environment.\n",
    "\n",
    "For more information on unit commitment see https://pypsa.org/examples/unit-commitment.html for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run opf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'snapshots': [],\n",
    "          'step_opf_min': 5,\n",
    "          'mode_opf': 'day',\n",
    "          'reactive_comp': 1.025,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses_pct = 3.0\n",
    "\n",
    "# Rigth now if you want to rerun this you'll probably have to re-instanciate the Dispatch class\n",
    "\n",
    "# The run is by scenario\n",
    "for subpath in os.listdir(chronics_path_gen):\n",
    "    \n",
    "    this_path = os.path.join(chronics_path_gen, subpath)\n",
    "    dispatch.read_load_and_res_scenario(os.path.join(this_path, 'load_p.csv.bz2'),\n",
    "                                        os.path.join(this_path, 'prod_p.csv.bz2'))\n",
    "    dispatch.make_hydro_constraints_from_res_load_scenario()\n",
    "    agg_load_without_renew = dispatch.net_load(losses_pct, name=dispatch.loads.index[0])\n",
    "\n",
    "    # Prepare gen constraints for EDispatch module\n",
    "    hydro_constraints = {'p_max_pu': dispatch._max_hydro_pu.copy(), 'p_min_pu': dispatch._min_hydro_pu.copy()}\n",
    "    \n",
    "    # Run Economic Disptach using submodule EDisptach_L2RPN_2020\n",
    "    # **  **  **  **  **  **  **  **  **  **  **  **  **  **\n",
    "    opf_dispatch, term_conditions = dispatch.run(\n",
    "                                        agg_load_without_renew,\n",
    "                                        params=params,\n",
    "                                        gen_constraints=hydro_constraints,\n",
    "                                        ramp_mode=run_economic_dispatch.RampMode.easy,\n",
    "                                        by_carrier=False  # True to run the dispatch only aggregated generators by carrier\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate renewable dispatch\n",
    "full_opf_dispatch = pd.concat([opf_dispatch, dispatch.wind_p, dispatch.solar_p], axis=1)\n",
    "\n",
    "# Keep same order as grid2op\n",
    "full_opf_dispatch = full_opf_dispatch[env118_withoutchron.name_gen].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclear_names = dispatch.generators[dispatch.generators.carrier == 'nuclear'].index\n",
    "hydro_names = dispatch.generators[dispatch.generators.carrier == 'hydro'].index\n",
    "thermal_names = dispatch.generators[dispatch.generators.carrier == 'thermal'].index\n",
    "\n",
    "dispatch_by_fleet = full_opf_dispatch[nuclear_names].sum(axis=1).to_frame('Nuclear')\n",
    "dispatch_by_fleet['Hyrdro'] = full_opf_dispatch[hydro_names].sum(axis=1)\n",
    "dispatch_by_fleet['Thermal'] = full_opf_dispatch[thermal_names].sum(axis=1)\n",
    "\n",
    "dispatch_by_fleet.loc[dispatch_by_fleet['Thermal'] < 0, 'Thermal'] = 0\n",
    "\n",
    "# grid2op env starts in 2007 but read loads are in 2012...\n",
    "dispatch_by_fleet = dispatch_by_fleet.loc[dispatch_by_fleet.index.year == 2007,:]\n",
    "\n",
    "dispatch_by_fleet.plot(figsize=(20, 8), title='Dispatch over 1 year', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet.iloc[(288*140):(288*147), :].plot(figsize=(20, 8), title='Dispatch over 1 week', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite values into chronics\n",
    "scenario = 'Scenario_0' # Careful: this cell was previously coded so that the last computed scenario is written. Better would be to move it in the for loop above\n",
    "outputPath = os.path.join(OUTPUT_FOLDER, str(year), scenario)\n",
    "full_opf_dispatch[env118_withoutchron.name_gen].to_csv(os.path.join(outputPath, \"prod_p.csv.bz2\"), sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate whether they have same order\n",
    "np.all(full_opf_dispatch.columns == env118_withoutchron.name_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute some KPIs for dispatch\n",
    "As I never had a dispatch output file, I didn't have a precise output format for the dispatch to be taken into account by the KPI module.So I chose to take the format of the only example i had: chronics exported by a previous script of Camilo with month by month dispatch chronics. \n",
    "- Download these files to have a format example on Nextcloud: https://nextcloud.artelys.com/nextcloud/s/tFirA3TRXrHeFwC\n",
    "- Careful, this example is for year 2007\n",
    "- We should agree on an output format from dispatch. Maybe you could put it on Nextcloud as an example for me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have to set \"eco2mix\" as comparison in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "**Images were not designed to be plot on a notebook but to be saved as png or zoomable in IMAGES_FOLDER**. In particular, yearly productions and energy mix are better to watch in their written files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "wind_solar_only = False\n",
    "if not os.path.exists(KPI_INPUT_FOLDER):\n",
    "    os.mkdir(KPI_INPUT_FOLDER)\n",
    "kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, IMAGES_FOLDER, year, CASE, n_scenarios, wind_solar_only, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Create an environment with the chronics this time\n",
    "\n",
    "This is to test the environment can be used by grid2op. This is what the \"case118_l2rpn\" will look like for the competitions.\n",
    "\n",
    "**NB** The \"Balthazar code\" is fully compatible with the \"GridStateFromFileWithForecasts\". So it is useful to use this class to load back the data. If the data generation process does not provide the same utilities, it is not a problem to write another class, like \"GridStateFromFileWithForecasts\" that can read its format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the bug in element 7_4_173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose generated scenario\n",
    "scenario = 'Scenario_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = pd.DataFrame(columns=env118_withoutchron.name_line.tolist())\n",
    "# line.to_csv('/Users/camiloromero/Rte/EDispatch_L2RPN2020/lines_names.txt', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_path = os.path.join(OUTPUT_FOLDER, str(year), scenario)\n",
    "hazard = pd.read_csv(os.path.join(scenario_path, 'hazards.csv.bz2'), sep=';')\n",
    "chronics_line_names = hazard.columns.tolist()\n",
    "\n",
    "lines_names = {}\n",
    "for g, c in zip(env118_withoutchron.name_line, chronics_line_names):\n",
    "    lines_names[c] = g\n",
    "    \n",
    "names_chronics_to_backend = {}\n",
    "names_chronics_to_backend['lines'] = lines_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I can't run from the following cell: can't make the dispatch run on my machine and don't data in the right format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.ChronicsHandler import Multifolder, GridStateFromFileWithForecasts\n",
    "from grid2op.Parameters import Parameters\n",
    "# don't disconnect powerline on overflow, the thermal limit are not set for now, it would not make sens\n",
    "param = Parameters()\n",
    "param.init_from_dict({\"NO_OVERFLOW_DISCONNECTION\": True})\n",
    "\n",
    "#chronics_path_gen = os.path.join(chronics_path, \"chronics\")\n",
    "chronics_path_gen = None\n",
    "\n",
    "env = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                   grid_path=os.path.join(path_grid, \"L2RPN_2020_case118_redesigned.json\"), # assign it the 118 grid\n",
    "                   chronics_class=Multifolder, # tell it to change nothing (not the most usable environment...)\n",
    "                   data_feeding_kwargs= {\"path\": chronics_path_gen, \"gridvalueClass\": GridStateFromFileWithForecasts},\n",
    "                   param=param,\n",
    "                   names_chronics_to_backend = names_chronics_to_backend,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can test that we can use a Runner, store the results, and plot the flows on the powerline for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Validate the generation process\n",
    "\n",
    "For that we use a runner, that will compute the powerflows with a \"do nothing\" agent, and we prevent it to disconnect any power line, even if they are on overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Runner import Runner\n",
    "path_data_saved = chronics_path+\"_computed\"\n",
    "runner = Runner(**env.get_params_for_runner())\n",
    "\n",
    "# here you might need to change \"nb_episode\" if you generated more than one scenario\n",
    "# this might really take some times... 4 mins per scenario per week [on one core]\n",
    "res = runner.run(nb_episode=nb_episode, path_save=path_data_saved, pbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can study the results, for example by loading the chronics, extracting prod p, load p etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Utils import ActionSpace, ObservationSpace\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path_data_saved_ep0 = os.path.join(path_data_saved, \"0\")\n",
    "action_space = ActionSpace.from_dict(os.path.join(path_data_saved, \"dict_action_space.json\"))\n",
    "env_modif_space = ActionSpace.from_dict(os.path.join(path_data_saved, \"dict_env_modification_space.json\"))\n",
    "observation_space = ObservationSpace.from_dict(os.path.join(path_data_saved, \"dict_observation_space.json\"))\n",
    "observations_npy = np.load(os.path.join(path_data_saved_ep0, \"observations.npy\"))\n",
    "li_observations = []\n",
    "for i in range(observations_npy.shape[0]):\n",
    "    tmp = observation_space.from_vect(observations_npy[i,:])\n",
    "    li_observations.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_a = np.array([obs.a_or for obs in li_observations])\n",
    "loads_p = np.array([obs.load_p for obs in li_observations])\n",
    "prods_p = np.array([obs.prod_p for obs in li_observations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display distribution of flows over scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "flow_a_vector=np.concatenate(flows_a, axis=None)\n",
    "plt.hist(flow_a_vector,bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the KPI you want with that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to **II)** if results are not satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V Export the final results\n",
    "\n",
    "First, regenerate a lot more data, then save then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO generate more data with the same distribution as the one that has been validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO export them to be usable in a friendly manner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
