{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how to get a first grid2op environment, then use the data it needs to generate some loads and renewables (and a shitty market design) and load this second environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/camiloromero/Rte/env_for_pypsa/lib/python3.7/site-packages/pandapower/io_utils.py:8: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  from pandas.util.testing import assert_series_equal, assert_frame_equal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook uses the last dev version of grid2op. You can install it with:\n",
      "\t/Users/camiloromero/Rte/env_for_pypsa/bin/python3 -m pip install git+https://github.com/bdonnot/grid2op.git@betternotebooks --user\n"
     ]
    }
   ],
   "source": [
    "import grid2op\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid2op.ChronicsHandler import ChangeNothing\n",
    "from grid2op.PlotMatplotlib import GetLayout\n",
    "print(\"This notebook uses the last dev version of grid2op. You can install it with:\\n\"\\\n",
    "      \"\\t{} -m pip install git+https://github.com/bdonnot/grid2op.git@betternotebooks --user\".format(sys.executable))\n",
    "\n",
    "#path_grid = os.path.join(\"data\", \"case118_l2rpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-86faf9d33ae4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_chronics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgeneration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthermal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEDispatch_L2RPN2020\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_economic_dispatch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrun_economic_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkpis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Rte/ChroniX2Grid/chronix2grid/kpi/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot_KPI\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpivot_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkpis\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEconomicDispatchValidator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Rte/ChroniX2Grid/chronix2grid/kpi/deterministic/kpis.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "# Chronix2grid modules\n",
    "import generation.generate_chronics as gen\n",
    "import generation.thermal.EDispatch_L2RPN2020.run_economic_dispatch as run_economic_dispatch\n",
    "import kpi.main as kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "## Generation step of chronix2grid\n",
    "INPUT_FOLDER = 'generation/input'\n",
    "OUTPUT_FOLDER = 'generation/output'\n",
    "CASE = 'case118_l2rpn'\n",
    "    # Detailed configuration to set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "\n",
    "\n",
    "## KPI computation phase\n",
    "KPI_INPUT_FOLDER = 'kpi/input'\n",
    "IMAGES_FOLDER = 'kpi/images'\n",
    "    # Detailed configuration to set in <KPI_INPUT_FOLDER>/params.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_grid = os.path.join(INPUT_FOLDER, CASE)\n",
    "\n",
    "env118_withoutchron = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                      grid_path=os.path.join(path_grid, \"L2RPN_2020_case118_redesigned.json\"), # assign it the 118 grid\n",
    "                      chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    "                  )\n",
    "grid_layout =  [(-403, -311), (-355, -311), (-380, -275), (-355, -245), (-369, -191), (-330, -193), (-299, -190), \n",
    "                (-366, -88),\n",
    "         (-364, -44), (-366, -7), (-320, -247), (-266, -266), (-241, -198), (-203, -231), (-188, -201), (-282, -153),\n",
    "         (-221, -123), (-161, -123), (-131, -156), (-139, -142), (-131, -27), (-123, -3), (-131, 29), (-18, -46),\n",
    "         (-162, 67), (-203, 39), (-324, 21), (-332, -15), (-331, -52), (-212, -88), (-292, -52), (-259, -29),\n",
    "         (-4, -254), (32, -203), (-34, -148), (51, -155), (74, -221), (88, -127), (59, -265), (86, -296), (129, -296),\n",
    "         (161, -296), (124, -198), (140, -226), (147, -163), (133, -138), (162, -134), (187, -173), (221, -125),\n",
    "         (268, -215), (287, -225), (199, -258), (202, -296), (237, -295), (329, -296), (283, -297), (268, -248),\n",
    "         (287, -248), (372, -277), (372, -197), (372, -153), (340, -74), (348, -254), (342, -168), (298, -29),\n",
    "         (283, -74), (297, -92), (213, -62), (184, -50), (61, -45), (40, -73), (25, -52), (61, -84), (43, 53), (61, 73),\n",
    "         (151, 73), (176, 99), (195, 53), (221, 33), (227, 73), (230, 56), (149, 131), (57, 154), (46, 171), (43, 205),\n",
    "         (43, 229), (57, 245), (78, 205), (119, 207), (122, 241), (191, 243), (196, 207), (219, 186), (245, 154),\n",
    "         (212, 154), (221, 132), (220, 110), (262, 94), (294, 74), (288, 154), (273, 230), (226, 229), (326, 230),\n",
    "         (330, 152), (365, 154), (364, 91), (404, 154), (370, 191), (373, 212), (361, 253), (330, 260), (403, 253),\n",
    "(-256, -102), (-270, 0), (-236, 1), (229, -32), (-211, -266), (99, 74)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Energy Mix apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Target_EM_percentage=pd.DataFrame(data=[4,6,35,15,40],columns=['target_energy_mix'],\n",
    "                                  index=['solar','wind','nuclear','hydro','thermal'])\n",
    "PeakLoad=4200\n",
    "AverageLoad=2800\n",
    "CapacityFactor=pd.DataFrame(data=[15,25,95,30,np.nan],columns=['capacity_factor'],\n",
    "                            index=['solar','wind','nuclear','hydro','thermal'])\n",
    "Capacity_df=EnergyMix_AprioriChecker(env118_withoutchron,Target_EM_percentage, PeakLoad, AverageLoad, CapacityFactor )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Capacity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Generate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can set generation configuration such as number of scenarios, start date, number of weeks, noise intensities, timestep... in INPUT_FOLDER/CASE/params.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II A) Generate loads and renewables\n",
    "\n",
    "Chronix2grid generation process which implements Balthazar method. CSV writting takes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading parameters\n",
    "year, n_scenarios, params, loads_charac, prods_charac, load_weekly_pattern, solar_pattern, lines = gen.read_configuration(INPUT_FOLDER, CASE)\n",
    "print(year)\n",
    "gen.main(year, n_scenarios, params, INPUT_FOLDER, OUTPUT_FOLDER, prods_charac, loads_charac, lines, solar_pattern, load_weekly_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(solar_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It has been generated in this folder\n",
    "chronics_path_gen = os.path.join(INPUT_FOLDER, \"dispatch\", str(year))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Ramps and Pmin/Pmax Generator parameters A priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the scenario you want to check first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "\n",
    "losses_pct = 3.0  # losses as pct of load\n",
    "[isThermalInTrouble,isNuclearInTrouble,IsRampUpInTrouble,IsRampDownInTrouble]=Ramps_Pmax_Pmin_APrioriCheckers(\n",
    "    env118_withoutchron,Capacity_df,chronics_path_gen,losses_pct,PeakLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(isThermalInTrouble)\n",
    "print(isNuclearInTrouble)\n",
    "print(IsRampUpInTrouble)\n",
    "print(IsRampDownInTrouble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Aposteriori_renewableCapacityFactor_Checkers(env118_withoutchron,Capacity_df, chronics_path_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute some KPIs for solar, wind and load\n",
    "\n",
    "#### Good comparison can be obtained by setting \"renewable_ninja\" as comparison in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "Images are saved in IMAGES_FOLDER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_solar_only = True\n",
    "if not os.path.exists(KPI_INPUT_FOLDER):\n",
    "    os.mkdir(KPI_INPUT_FOLDER)\n",
    "kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, IMAGES_FOLDER, year, CASE, n_scenarios, wind_solar_only, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pypsa net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install PyPSA correctly <br>\n",
    "`pip3 install -U git+http://github.com/PyPSA/PyPSA.git@8d527e25fa9876cac66957448f449a1c901901d2`\n",
    "\n",
    "You also need to install the solver that pypsa is calling. For instance cbc solver. On Fedora do `dnf install coin-or-Cbc.x86_64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pypsa\n",
    "\n",
    "net = pypsa.Network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one bus\n",
    "net.add('Bus', 'node')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(env118_withoutchron.name_gen)):\n",
    "    net.add(class_name = 'Generator',\n",
    "             name = env118_withoutchron.name_gen[i],\n",
    "             bus = 'node',\n",
    "             p_nom = env118_withoutchron.gen_pmax[i],\n",
    "             p_nom_extendable = False,\n",
    "             p_nom_min = 0,\n",
    "             p_nom_max = 1,\n",
    "             carrier = env118_withoutchron.gen_type[i],\n",
    "             marginal_cost = env118_withoutchron.gen_cost_per_MW[i],\n",
    "             committable = env118_withoutchron.gen_redispatchable[i],\n",
    "             ramp_limit_up = 0.6 * env118_withoutchron.gen_max_ramp_up[i] / env118_withoutchron.gen_pmax[i],\n",
    "             ramp_limit_down = 0.6 * env118_withoutchron.gen_max_ramp_down[i] / env118_withoutchron.gen_pmax[i],  \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep copy of original grid\n",
    "original_gen_pypsa = net.generators.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generators.carrier.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove wind and solar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renew_fltr = net.generators.carrier.isin(['wind', 'solar'])\n",
    "net.generators.drop(net.generators.loc[renew_fltr].index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.generators.carrier.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify marginal costs (hydro > nuclear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check marginal costs\n",
    "net.generators.groupby('carrier').min()['marginal_cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange marginal costs\n",
    "hydro_fltr = net.generators.carrier.isin(['hydro'])\n",
    "nuclear_fltr = net.generators.carrier.isin(['nuclear'])\n",
    "\n",
    "net.generators.loc[hydro_fltr, 'marginal_cost'] = 8\n",
    "net.generators.loc[nuclear_fltr, 'marginal_cost'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check marginal costs\n",
    "net.generators.groupby('carrier').min()['marginal_cost']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add('Load',\n",
    "        name = 'agg_load',\n",
    "        bus = 'node',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renew_fltr = net.generators.carrier.isin(['wind', 'solar'])\n",
    "# net.generators.loc[renew_fltr, 'ramp_limit_up'] = np.nan\n",
    "# net.generators.loc[renew_fltr, 'ramp_limit_down'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II B) Run a unit commitment model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use pypsa. To avoid messing with the names, and make sure to have data in the proper shape, it is better, I think, to create the pypsa network directly from the grid2op environment.\n",
    "\n",
    "For more information on unit commitment see https://pypsa.org/examples/unit-commitment.html for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create hydro limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateparse = lambda x: pd.datetime.strptime(x, '%d/%m/%Y %H:%M')\n",
    "hydro_pattern_path = os.path.join(INPUT_FOLDER, 'patterns', 'hydro.csv')\n",
    "hydro_pattern = pd.read_csv(hydro_pattern_path, usecols=[0, 2, 3], parse_dates=[0], date_parser=dateparse)\n",
    "hydro_pattern.set_index(hydro_pattern.columns[0], inplace=True)\n",
    "hydro_pattern.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hydro_names = net.generators[net.generators.carrier == 'hydro'].index.tolist()\n",
    "hydro_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_hydro_pu = hydro_pattern[['p_max_u'] * len(hydro_names)]\n",
    "max_hydro_pu.columns = hydro_names\n",
    "max_hydro_pu.reset_index(drop=True, inplace=True)\n",
    "max_hydro_pu.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_hydro_pu = hydro_pattern[['p_min_u'] * len(hydro_names)]\n",
    "min_hydro_pu.columns = hydro_names\n",
    "min_hydro_pu.reset_index(drop=True, inplace=True)\n",
    "min_hydro_pu.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run opf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'snapshots': [],\n",
    "          'step_opf_min': 5,\n",
    "          'mode_opf': 'day',\n",
    "          'reactive_comp': 1.025,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generation.thermal.EDispatch_L2RPN2020.run_economic_dispatch import main_run_disptach\n",
    "\n",
    "\n",
    "losses_pct = 3.0\n",
    "\n",
    "# The run is by scenario\n",
    "for subpath in os.listdir(chronics_path_gen):\n",
    "    # Load consumption and prod\n",
    "    this_path = os.path.join(chronics_path_gen, subpath)\n",
    "    load_p = pd.read_csv(os.path.join(this_path, 'load_p.csv.bz2'), sep = ';', index_col = 0)\n",
    "    prod_p = pd.read_csv(os.path.join(this_path, 'prod_p.csv.bz2'), sep = ';', index_col = 0)\n",
    "    \n",
    "    # Match hydro indices with load_p (same lenght of dataframes)\n",
    "    max_hydro_pu = max_hydro_pu.loc[:load_p.shape[0]-1]\n",
    "    min_hydro_pu = min_hydro_pu.loc[:load_p.shape[0]-1]\n",
    "\n",
    "    \n",
    "    # Prepare gen constraints for EDispatch module\n",
    "    hydro_constraints = {'p_max_pu': max_hydro_pu, 'p_min_pu': min_hydro_pu}\n",
    "    \n",
    "    # Retrieve wind and solar from prod_p (Balthazar's generator)\n",
    "    prod_p_wind = prod_p[[el for i, el in enumerate(env118_withoutchron.name_gen) if env118_withoutchron.gen_type[i] in [\"wind\"]]]\n",
    "    prod_p_solar = prod_p[[el for i, el in enumerate(env118_withoutchron.name_gen) if env118_withoutchron.gen_type[i] in [\"solar\"]]]\n",
    "    \n",
    "    total_renew = pd.concat([prod_p_wind, prod_p_solar], axis=1).sum(axis=1)\n",
    "    \n",
    "    # Compensate the reactive part in loads\n",
    "    load_ = load_p.copy() * (1 + losses_pct/100)\n",
    "    load_ = load_.sum(axis=1)\n",
    "    \n",
    "    # Demand for OPF (total - renewable)\n",
    "    agg_load_without_renew = (load_ - total_renew).to_frame()\n",
    "    agg_load_without_renew.columns = ['agg_load']\n",
    "    \n",
    "    # Run Economic Disptach using submodule EDisptach_L2RPN_2020\n",
    "    # **  **  **  **  **  **  **  **  **  **  **  **  **  **\n",
    "    opf_dispatch = main_run_disptach(net, \n",
    "                                     agg_load_without_renew,\n",
    "                                     params=params,\n",
    "                                     gen_constraints=hydro_constraints,\n",
    "                                     ramp_mode=run_economic_dispatch.RampMode.easy\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate renewable dispatch\n",
    "full_opf_dispatch = pd.concat([opf_dispatch, prod_p_wind, prod_p_solar], axis=1)\n",
    "\n",
    "# Keep same order as grid2op\n",
    "full_opf_dispatch = full_opf_dispatch[env118_withoutchron.name_gen].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_opf_dispatch[hydro_names].plot(figsize=(10,4), title='Hydro Dispatch for 1 week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite values into chronics\n",
    "scenario = 'Scenario_0' # Careful: this cell was previously coded so that the last computed scenario is written. Better would be to move it in the for loop above\n",
    "outputPath = os.path.join(OUTPUT_FOLDER, str(year), scenario)\n",
    "full_opf_dispatch[env118_withoutchron.name_gen].to_csv(os.path.join(outputPath, \"prod_p.csv.bz2\"), sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate whether they have same order\n",
    "np.all(full_opf_dispatch.columns == env118_withoutchron.name_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute some KPIs for dispatch\n",
    "As I never had a dispatch output file, I didn't have a precise output format for the dispatch to be taken into account by the KPI module.So I chose to take the format of the only example i had: chronics exported by a previous script of Camilo with month by month dispatch chronics. \n",
    "- Download these files to have a format example on Nextcloud: https://nextcloud.artelys.com/nextcloud/s/tFirA3TRXrHeFwC\n",
    "- Careful, this example is for year 2007\n",
    "- We should agree on an output format from dispatch. Maybe you could put it on Nextcloud as an example for me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have to set \"eco2mix\" as comparison in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "**Images were not designed to be plot on a notebook but to be saved as png or zoomable in IMAGES_FOLDER**. In particular, yearly productions and energy mix are better to watch in their written files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "wind_solar_only = False\n",
    "if not os.path.exists(KPI_INPUT_FOLDER):\n",
    "    os.mkdir(KPI_INPUT_FOLDER)\n",
    "kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, IMAGES_FOLDER, year, CASE, n_scenarios, wind_solar_only, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Create an environment with the chronics this time\n",
    "\n",
    "This is to test the environment can be used by grid2op. This is what the \"case118_l2rpn\" will look like for the competitions.\n",
    "\n",
    "**NB** The \"Balthazar code\" is fully compatible with the \"GridStateFromFileWithForecasts\". So it is useful to use this class to load back the data. If the data generation process does not provide the same utilities, it is not a problem to write another class, like \"GridStateFromFileWithForecasts\" that can read its format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the bug in element 7_4_173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chose generated scenario\n",
    "scenario = 'Scenario_0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line = pd.DataFrame(columns=env118_withoutchron.name_line.tolist())\n",
    "# line.to_csv('/Users/camiloromero/Rte/EDispatch_L2RPN2020/lines_names.txt', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_path = os.path.join(OUTPUT_FOLDER, str(year), scenario)\n",
    "hazard = pd.read_csv(os.path.join(scenario_path, 'hazards.csv.bz2'), sep=';')\n",
    "chronics_line_names = hazard.columns.tolist()\n",
    "\n",
    "lines_names = {}\n",
    "for g, c in zip(env118_withoutchron.name_line, chronics_line_names):\n",
    "    lines_names[c] = g\n",
    "    \n",
    "names_chronics_to_backend = {}\n",
    "names_chronics_to_backend['lines'] = lines_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I can't run from the following cell: can't make the dispatch run on my machine and don't data in the right format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.ChronicsHandler import Multifolder, GridStateFromFileWithForecasts\n",
    "from grid2op.Parameters import Parameters\n",
    "# don't disconnect powerline on overflow, the thermal limit are not set for now, it would not make sens\n",
    "param = Parameters()\n",
    "param.init_from_dict({\"NO_OVERFLOW_DISCONNECTION\": True})\n",
    "\n",
    "#chronics_path_gen = os.path.join(chronics_path, \"chronics\")\n",
    "chronics_path_gen = None\n",
    "\n",
    "env = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                   grid_path=os.path.join(path_grid, \"L2RPN_2020_case118_redesigned.json\"), # assign it the 118 grid\n",
    "                   chronics_class=Multifolder, # tell it to change nothing (not the most usable environment...)\n",
    "                   data_feeding_kwargs= {\"path\": chronics_path_gen, \"gridvalueClass\": GridStateFromFileWithForecasts},\n",
    "                   param=param,\n",
    "                   names_chronics_to_backend = names_chronics_to_backend,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can test that we can use a Runner, store the results, and plot the flows on the powerline for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Validate the generation process\n",
    "\n",
    "For that we use a runner, that will compute the powerflows with a \"do nothing\" agent, and we prevent it to disconnect any power line, even if they are on overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Runner import Runner\n",
    "path_data_saved = chronics_path+\"_computed\"\n",
    "runner = Runner(**env.get_params_for_runner())\n",
    "\n",
    "# here you might need to change \"nb_episode\" if you generated more than one scenario\n",
    "# this might really take some times... 4 mins per scenario per week [on one core]\n",
    "res = runner.run(nb_episode=nb_episode, path_save=path_data_saved, pbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can study the results, for example by loading the chronics, extracting prod p, load p etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Utils import ActionSpace, ObservationSpace\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path_data_saved_ep0 = os.path.join(path_data_saved, \"0\")\n",
    "action_space = ActionSpace.from_dict(os.path.join(path_data_saved, \"dict_action_space.json\"))\n",
    "env_modif_space = ActionSpace.from_dict(os.path.join(path_data_saved, \"dict_env_modification_space.json\"))\n",
    "observation_space = ObservationSpace.from_dict(os.path.join(path_data_saved, \"dict_observation_space.json\"))\n",
    "observations_npy = np.load(os.path.join(path_data_saved_ep0, \"observations.npy\"))\n",
    "li_observations = []\n",
    "for i in range(observations_npy.shape[0]):\n",
    "    tmp = observation_space.from_vect(observations_npy[i,:])\n",
    "    li_observations.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_a = np.array([obs.a_or for obs in li_observations])\n",
    "loads_p = np.array([obs.load_p for obs in li_observations])\n",
    "prods_p = np.array([obs.prod_p for obs in li_observations])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display distribution of flows over scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "flow_a_vector=np.concatenate(flows_a, axis=None)\n",
    "plt.hist(flow_a_vector,bins=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the KPI you want with that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to **II)** if results are not satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V Export the final results\n",
    "\n",
    "First, regenerate a lot more data, then save then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO generate more data with the same distribution as the one that has been validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO export them to be usable in a friendly manner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_for_pypsa",
   "language": "python",
   "name": "env_for_pypsa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
