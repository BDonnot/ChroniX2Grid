{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explains how to get a first grid2op environment, then use the data it needs to generate some loads and renewables (and a shitty market design) and load this second environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"This notebook uses the last version of grid2op. You can install it with:\\n\"\\\n",
    "      \"\\t{} -m pip install grid2op\".format(sys.executable))\n",
    "import grid2op\n",
    "if grid2op.__version__ < \"0.6.0\":\n",
    "    raise RuntimeError(\"Impossible to run this notebook without grid2op version 0.6.0 installed.\")\n",
    "from grid2op.Chronics import ChangeNothing\n",
    "from grid2op.Plot import PlotMatplotlib\n",
    "\n",
    "#path_grid = os.path.join(\"data\", \"case118_l2rpn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cufflinks as cf\n",
    "import plotly.offline\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chronix2grid modules\n",
    "sys.path.insert(0, '..')\n",
    "import chronix2grid.generation.generate_chronics as gen\n",
    "import chronix2grid.generation.generation_utils as gu\n",
    "import chronix2grid.generation.consumption.generate_load as gen_loads\n",
    "import chronix2grid.generation.renewable.generate_solar_wind as gen_enr\n",
    "import chronix2grid.generation.thermal.generate_dispatch as gen_dispatch\n",
    "import chronix2grid.generation.dispatch.utils as du\n",
    "\n",
    "import chronix2grid.generation.dispatch.EconomicDispatch as ec\n",
    "import chronix2grid.generation.thermal.EDispatch_L2RPN2020.run_economic_dispatch as run_economic_dispatch\n",
    "import chronix2grid.kpi.main as kpis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isRunCase118=True\n",
    "isRunCase14=False\n",
    "isSkipKpi=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANT\n",
    "\n",
    "root_dir = %pwd\n",
    "\n",
    "INPUT_FOLDER = 'generation/input'\n",
    "# Detailed configuration to set in <INPUT_FOLDER>/<CASE>/params.json\n",
    "start_date = \"2012-01-01\"\n",
    "weeks = 1\n",
    "n_scenarios = 1\n",
    "\n",
    "## KPI computation phase\n",
    "KPI_INPUT_FOLDER = 'kpi/input'\n",
    "IMAGES_FOLDER = 'kpi/images'\n",
    "\n",
    "## Generation step of chronix2grid\n",
    "if isRunCase118:\n",
    "    \n",
    "    CASE = 'case118_l2rpn'\n",
    "    path_grid = os.path.join(INPUT_FOLDER, CASE)\n",
    "    grid_path = os.path.join(path_grid, \"L2RPN_2020_case118_redesigned.json\")\n",
    "    OUTPUT_FOLDER = os.path.join('generation/output', CASE)\n",
    "    images_folder = os.path.join(IMAGES_FOLDER, CASE)\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "\n",
    "    #Intermediate folder used by dispatch\n",
    "    dispatch_case_folder = os.path.join(INPUT_FOLDER, CASE, 'dispatch')\n",
    "\n",
    "if isRunCase14:\n",
    "\n",
    "    ## Generation step of chronix2grid\n",
    "    CASE = 'case14_realistic'\n",
    "    path_grid = os.path.join(INPUT_FOLDER, CASE)\n",
    "    grid_path = os.path.join(path_grid, \"case14_realistic.json\")\n",
    "    OUTPUT_FOLDER = 'generation/output/case14'\n",
    "    images_folder = os.path.join(IMAGES_FOLDER, CASE)\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "        \n",
    "    #Intermediate folder used by dispatch\n",
    "    dispatch_case_folder = os.path.join(INPUT_FOLDER, 'dispatch/case14/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispatch Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#20min time computation for a year with every generators at monthly resolution --- Fail on month of june\n",
    "#8min time computation for a year with every generators at weekly resolution --- Fail for last 2 weeks of june\n",
    "#10.5min time computation for a year with every generators at daily resolution --- Fail for 17 and 24 of june \n",
    "#=>no thermal on those days, probably due to ramps! But was converging when looking only per carrier type\n",
    "\n",
    "#1min time computation for a year with every carrier at monthly resolution --- Fail on month of june\n",
    "#6min time computation for a year with every carrier at daily resolution --- Fail on month of june\n",
    "\n",
    "\n",
    "# Run the dispatch in the automated process or \"manually\"\n",
    "# If true, params_opf.json is read from disk and used\n",
    "run_automated_dispatch = False\n",
    "\n",
    "losses_pct = 3.0\n",
    "DispatchByCarrierOnly=False\n",
    "\n",
    "params_opf = {\n",
    "    'step_opf_min': 5,\n",
    "    'mode_opf': 'month',\n",
    "    'reactive_comp': 1.025,\n",
    "    'losses_pct': losses_pct,\n",
    "    'dispatch_by_carrier': DispatchByCarrierOnly,\n",
    "    'pyomo': False,\n",
    "    'solver_name': 'cbc'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env118_withoutchron = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                      grid_path=grid_path, # assign it the 118 grid\n",
    "                      chronics_class=ChangeNothing, # tell it to change nothing (not the most usable environment...)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Energy Mix apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Target_EM_percentage=pd.DataFrame(data=[4,6,35,15,40],columns=['target_energy_mix'],\n",
    "                                  index=['solar','wind','nuclear','hydro','thermal'])\n",
    "\n",
    "if isRunCase14:\n",
    "    PeakLoad=308\n",
    "    AverageLoad=257\n",
    "elif isRunCase118:\n",
    "    PeakLoad=4200\n",
    "    AverageLoad=2800\n",
    "    \n",
    "CapacityFactor=pd.DataFrame(data=[15,25,95,30,np.nan],columns=['capacity_factor'],\n",
    "                            index=['solar','wind','nuclear','hydro','thermal'])\n",
    "Capacity_df=EnergyMix_AprioriChecker(env118_withoutchron,Target_EM_percentage, PeakLoad, AverageLoad, CapacityFactor )\n",
    "Capacity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II Generate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can set generation configuration such as number of scenarios, start date, number of weeks, noise intensities, timestep... in INPUT_FOLDER/CASE/params.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II A) Generate loads and renewables\n",
    "\n",
    "Chronix2grid generation process which implements Balthazar method. CSV writting takes long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading parameters\n",
    "year, params, loads_charac, prods_charac, load_weekly_pattern, solar_pattern, params_opf_auto = \\\n",
    "    gu.read_all_configurations(weeks, start_date, CASE, root_dir)\n",
    "print(year)\n",
    "\n",
    "## Whole generation\n",
    "# gen.main(year, n_scenarios, params, INPUT_FOLDER, OUTPUT_FOLDER, prods_charac, loads_charac, lines, solar_pattern, load_weekly_pattern)\n",
    "\n",
    "\n",
    "## OR ============\n",
    "\n",
    "# Separate generation for load and renewables\n",
    "\n",
    "\n",
    "# Create folders\n",
    "dispatch_input_folder = os.path.join(dispatch_case_folder, str(year))\n",
    "dispatch_output_folder = os.path.join(OUTPUT_FOLDER, str(year))\n",
    "os.makedirs(dispatch_input_folder, exist_ok=True)\n",
    "os.makedirs(dispatch_output_folder, exist_ok=True)\n",
    "\n",
    "# Make sure the seeds are the same, whether computation is parallel or sequential\n",
    "seeds = [np.random.randint(low=0, high=2**31) for _ in range(n_scenarios)]\n",
    "\n",
    "\n",
    "# Launch load generation\n",
    "for i, seed in enumerate(seeds):\n",
    "    scenario_dispatch_input_folder = os.path.join(dispatch_input_folder, f'Scenario_{i}')\n",
    "    print(\"================ Generating scenario number \"+str(i)+\" ================\")\n",
    "    load, load_forecasted = gen_loads.main(scenario_dispatch_input_folder, seed, params, loads_charac, \n",
    "                                           load_weekly_pattern, write_results = True)\n",
    "\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $OUTPUT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check load hypothesis (peak and average)\n",
    "\n",
    "**if this differs by too much, you should update the computation of the Energy Mix a priori and revise some calibration if not satisfactory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentPeakLoad=load.sum(axis=1).max()\n",
    "print('the expected peak load was: '+str(PeakLoad))\n",
    "print('the actual peak load is: '+str(CurrentPeakLoad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentAverageLoad=load.sum(axis=1).mean()\n",
    "print('the expected average load was: '+str(AverageLoad))\n",
    "print('the actual average load is: '+str(CurrentAverageLoad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Renewables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dispatcher = ec.Dispatcher.from_gri2op_env(env118_withoutchron)\n",
    "\n",
    "# move the 2 following lines inside the loop if they should be different for each scenario\n",
    "dispatcher.modify_marginal_costs({'hydro': 3, 'nuclear': 8})\n",
    "dispatcher.read_hydro_guide_curves(os.path.join(INPUT_FOLDER, 'patterns', 'hydro_french.csv'))\n",
    "\n",
    "# Launch solar and wind generation\n",
    "for i, seed in enumerate(seeds):\n",
    "    print(\"================ Generating scenario number \"+str(i)+\" ================\")\n",
    "    \n",
    "    scenario_name = f'Scenario_{i}'\n",
    "    input_scenario_folder, output_scneario_folder = du.make_scenario_input_output_directories(\n",
    "        dispatch_input_folder, dispatch_output_folder, scenario_name)\n",
    "    \n",
    "    prod_solar, prod_solar_forecasted, prod_wind, prod_wind_forecasted = gen_enr.main(\n",
    "        input_scenario_folder, seed,params, prods_charac, solar_pattern, write_results = True)\n",
    "    \n",
    "    if run_automated_dispatch:\n",
    "        prods = pd.concat([prod_solar, prod_wind], axis=1)\n",
    "        res_names = dict(wind=prod_wind.columns, solar=prod_solar.columns)\n",
    "        dispatcher.chronix_scenario = ec.ChroniXScenario(load, prods, res_names, scenario_name)\n",
    "\n",
    "        dispatch_results = gen_dispatch.main(dispatcher, input_scenario_folder, output_scneario_folder, \n",
    "                                             seed, params_opf_auto)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls generation/output/case14/2012/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Reading parameters\n",
    "#year, n_scenarios, params, loads_charac, prods_charac, load_weekly_pattern, solar_pattern, lines = gen.read_configuration(INPUT_FOLDER, CASE)\n",
    "#print(year)\n",
    "#gen.main(year, n_scenarios, params, INPUT_FOLDER, OUTPUT_FOLDER, prods_charac, loads_charac, lines, solar_pattern, load_weekly_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(solar_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Ramps and Pmin/Pmax Generator parameters A priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the scenario you want to check first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "\n",
    "# losses_pct = 3.0  # losses as pct of load\n",
    "[isThermalInTrouble,isNuclearInTrouble,IsRampUpInTrouble,IsRampDownInTrouble]=Ramps_Pmax_Pmin_APrioriCheckers(\n",
    "    env118_withoutchron,Capacity_df,dispatch_input_folder,losses_pct,PeakLoad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are the thermal reactors \\\"in trouble\\\": {}\".format(isThermalInTrouble))\n",
    "print(\"Are the nuclear reactors \\\"in trouble\\\": {}\".format(isNuclearInTrouble))\n",
    "print(\"Are the ramp up \\\"in trouble\\\": {}\".format(IsRampUpInTrouble))\n",
    "print(\"Are the ramp down \\\"in trouble\\\": {}\".format(IsRampDownInTrouble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run kpi/Generator_parameter_checker.py\n",
    "Aposteriori_renewableCapacityFactor_Checkers(env118_withoutchron,Capacity_df, dispatch_input_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute some KPIs for solar, wind and load only\n",
    "\n",
    "#### Benchmark \"France\" is set as reference in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "Images are saved in IMAGES_FOLDER/CASE/YEAR/SCENARIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you just want to save a lot of plots without showing it, uncomment this line.\n",
    "# If you want to compute more than 1 scenario, it is recommended not to show the plots on notebook\n",
    "#%%capture\n",
    "if not isSkipKpi:\n",
    "    # Chose number of scenarios to compute KPIs (it can be long to compute it for a lot of scenarios)\n",
    "    n_scenarios_kpis = 1\n",
    "\n",
    "    # Computation\n",
    "    wind_solar_only = True\n",
    "    kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, images_folder, year, CASE, n_scenarios_kpis, wind_solar_only, params, loads_charac, prods_charac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The EconomicDispatch instance : a high level wrapper around a Pypsa net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install PyPSA correctly <br>\n",
    "`pip3 install -U git+http://github.com/PyPSA/PyPSA.git@8d527e25fa9876cac66957448f449a1c901901d2`\n",
    "\n",
    "You also need to install the solver that pypsa is calling. For instance cbc solver. On Fedora do `dnf install coin-or-Cbc.x86_64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import generation.dispatch.EconomicDispatch as ec\n",
    "import generation.thermal.EDispatch_L2RPN2020.run_economic_dispatch as run_economic_dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher = ec.Dispatcher.from_gri2op_env(env118_withoutchron)\n",
    "dispatcher.modify_marginal_costs({'hydro': 3, 'nuclear': 8})\n",
    "dispatcher.read_hydro_guide_curves(os.path.join(INPUT_FOLDER, 'patterns', 'hydro_french.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatcher.plot_ramps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II B) Run a unit commitment model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will use pypsa. To avoid messing with the names, and make sure to have data in the proper shape, it is better, I think, to create the pypsa network directly from the grid2op environment.\n",
    "\n",
    "For more information on unit commitment see https://pypsa.org/examples/unit-commitment.html for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run opf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not run_automated_dispatch:\n",
    "\n",
    "    # The run is by scenario\n",
    "    for subpath in os.listdir(dispatch_input_folder):\n",
    "\n",
    "        if subpath in ['.DS_Store']:\n",
    "            continue\n",
    "\n",
    "        this_path = os.path.join(dispatch_input_folder, subpath)\n",
    "        dispatcher.read_load_and_res_scenario(os.path.join(this_path, 'load_p.csv.bz2'),\n",
    "                                            os.path.join(this_path, 'prod_p.csv.bz2'),\n",
    "                                            scenario_name=subpath)\n",
    "        hydro_constraints = dispatcher.make_hydro_constraints_from_res_load_scenario()\n",
    "        agg_load_without_renew = dispatcher.net_load(losses_pct, name=dispatcher.loads.index[0])\n",
    "\n",
    "        # Example of how to extract info on the largest ramps\n",
    "        print(f'5 largest ramps reached by the agg_load_without_renew:')\n",
    "        print(dispatcher.nlargest_ramps(5, losses_pct))\n",
    "        \n",
    "        params_opf['mode_opf'] = None\n",
    "        \n",
    "        # Run Economic Disptach using submodule EDisptach_L2RPN_2020\n",
    "        # **  **  **  **  **  **  **  **  **  **  **  **  **  **\n",
    "        dispatch_results = dispatcher.run(\n",
    "            agg_load_without_renew,\n",
    "            params=params_opf,\n",
    "            gen_constraints=hydro_constraints,\n",
    "            ramp_mode=run_economic_dispatch.RampMode.hard,\n",
    "            by_carrier=DispatchByCarrierOnly,  # True to run the dispatch only aggregated generators by carrier,\n",
    "            pyomo=False,\n",
    "            solver_name='cbc'\n",
    "        )\n",
    "\n",
    "        chronix_scenario = dispatch_results.chronix\n",
    "\n",
    "        # save prods chronics\n",
    "        dispatcher.save_results(os.path.join(dispatch_output_folder, subpath))\n",
    "\n",
    "        #TODO this should not be done in the notebook, but in chronix2grid ! These files are output of chronix2grid.\n",
    "        import shutil\n",
    "        files_to_move = ['load_p_forecasted.csv.bz2', 'load_q_forecasted.csv.bz2',\n",
    "                     'load_q.csv.bz2', 'prod_v.csv.bz2']\n",
    "        for file_to_move in files_to_move:\n",
    "            shutil.copy(os.path.join(dispatch_input_folder, subpath, file_to_move),\n",
    "                        os.path.join(dispatch_output_folder, subpath, file_to_move))\n",
    "    # TODO if there are failures, write it somewhere, for now it's only detected in the very verbose output cell.\n",
    "    # for example you can do a report at the end 'looking like failures for scenariis xxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypsa\n",
    "pypsa.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chronix_scenario is an object containing all the time series related to the studied scenario : \n",
    "- chronix_scenario.name gives the name of the scenario\n",
    "- chronix_scenario.wind_p (resp. solar_p, prods_dispatch, loads, marginal_prices) gives the Wind DataFrame (resp. Solar, Dispatched generators, loads, marginal_prices)\n",
    "\n",
    "This object should be manipulated in the sequel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below (up until the kpis) will  not run if  run_automated_dispatch = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the max net load is similar than after generating loads and renewables\n",
    "agg_load_without_renew.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at the slcack bus generation for case 118\n",
    "#dispatch_results.chronix.prods_dispatch['gen_68_37'].iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check That Pypsa does not violate the ramps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsRamps=dispatch_results.chronix.prods_dispatch.diff().describe()\n",
    "maxRamps=StatsRamps.loc['max']\n",
    "maxRamps[maxRamps>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_names=list(env118_withoutchron.name_gen)\n",
    "matchIDs=[gen_names.index(el) for el in list(StatsRamps)]\n",
    "gen_ramps=env118_withoutchron.gen_max_ramp_up[matchIDs]\n",
    "gen_subIds=env118_withoutchron.gen_to_subid[matchIDs]\n",
    "\n",
    "RampsToHigh=((maxRamps>gen_ramps).values & (gen_ramps!=0))\n",
    "print('\\n generation above their max rated ramps')\n",
    "print(gen_subIds[RampsToHigh])\n",
    "print('\\n max ramps in environement for generation above their max rated ramps')\n",
    "print(pd.DataFrame(gen_ramps,index=list(StatsRamps)).loc[RampsToHigh])\n",
    "print('\\n max ramps after pypsa')\n",
    "print(maxRamps[RampsToHigh])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check that very high ramps happen when switching months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ramps=dispatch_results.chronix.prods_dispatch.diff()\n",
    "Ramps.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate renewable dispatch\n",
    "\n",
    "#Becareful:check years of opf_dispatch and dispatch\n",
    "print(chronix_scenario.wind_p.index[0])\n",
    "print(chronix_scenario.prods_dispatch.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(chronix_scenario.wind_p.index[0] != chronix_scenario.prods_dispatch.index[0]):\n",
    "    chronix_scenario.prods_dispatch.index=chronix_scenario.wind_p.index\n",
    "if DispatchByCarrierOnly:\n",
    "    chronix_scenario.prods_dispatch=chronix_scenario.prods_dispatch[['nuclear','hydro','thermal']]#makesure nuclear comesfirst, for good plotting after\n",
    "\n",
    "full_opf_dispatch = pd.concat(\n",
    "    [chronix_scenario.prods_dispatch, chronix_scenario.wind_p, chronix_scenario.solar_p],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Keep same order as grid2op\n",
    "if not DispatchByCarrierOnly:\n",
    "    full_opf_dispatch = full_opf_dispatch[env118_withoutchron.name_gen].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not DispatchByCarrierOnly:\n",
    "    nuclear_names = dispatcher.generators[dispatcher.generators.carrier == 'nuclear'].index\n",
    "    hydro_names = dispatcher.generators[dispatcher.generators.carrier == 'hydro'].index\n",
    "    thermal_names = dispatcher.generators[dispatcher.generators.carrier == 'thermal'].index\n",
    "\n",
    "    dispatch_by_fleet=pd.concat([ dispatcher.wind_p, dispatcher.solar_p], axis=1)\n",
    "    dispatch_by_fleet['nuclear'] = full_opf_dispatch[nuclear_names].sum(axis=1).to_frame('Nuclear')\n",
    "    dispatch_by_fleet['hydro'] = full_opf_dispatch[hydro_names].sum(axis=1)\n",
    "    dispatch_by_fleet['thermal'] = full_opf_dispatch[thermal_names].sum(axis=1)\n",
    "    #dispatch_by_fleet=pd.concat([dispatch_by_fleet, dispatch.wind_p, dispatch.solar_p], axis=1)\n",
    "\n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['thermal'] < 0, 'thermal'] = 0\n",
    "\n",
    "    # grid2op env starts in 2007 but read loads are in 2012...\n",
    "    #dispatch_by_fleet = dispatch_by_fleet.loc[dispatch_by_fleet.index.year == 2007,:]\n",
    "\n",
    "    dispatch_by_fleet.plot(figsize=(20, 8), title='Dispatch over 1 year', kind='area')\n",
    "\n",
    "else:\n",
    "    dispatch_by_fleet=full_opf_dispatch\n",
    "    \n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['thermal'] < 0, 'thermal'] = 0 #due to numeric approximation,some thermal values  could be negative\n",
    "    dispatch_by_fleet.loc[dispatch_by_fleet['hydro'] < 0, 'hydro'] = 0\n",
    "    #full_opf_dispatch[full_opf_dispatch['thermal']<0]['thermal'].hist()\n",
    "    dispatch_by_fleet.plot(figsize=(20, 8), title='Dispatch over 1 year', kind='area')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].plot(figsize=(20, 8), title='Dispatch over 1 year - no renewable', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WeekNumber=24\n",
    "dispatch_by_fleet.iloc[(288*7*WeekNumber):(288*7*(WeekNumber+1)), :].plot(figsize=(20, 8), title='Dispatch over 1 week', kind='area')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].iloc[(288*7*WeekNumber):(288*7*(WeekNumber+1)), :].plot(figsize=(20, 8), title='Dispatch over 1 week - no renewable', kind='area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Hydro "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In june, Hydro might be high and the minimum hydro production to respect forces nuclear to decrease its production\n",
    "if not(dispatch_by_fleet[['hydro']].sum().values==0):\n",
    "    minHydroPattern=dispatcher._min_hydro_pu\n",
    "    nCols=minHydroPattern.shape[1]\n",
    "    minHydroPattern.iloc[:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In june, Hydro might be high and the minimum hydro production to respect forces nuclear to decrease its production\n",
    "if not(dispatch_by_fleet[['hydro']].sum().values==0):\n",
    "    maxHydroPattern=dispatcher._max_hydro_pu\n",
    "    nCols=maxHydroPattern.shape[1]\n",
    "    maxHydroPattern.iloc[:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate whether they have same order\n",
    "np.all(full_opf_dispatch.columns == env118_withoutchron.name_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Energy Mix of Dispatch and capacity factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CurrentAverageLoad=load.sum(axis=1).mean()\n",
    "dispatch_by_fleet[['nuclear','hydro','thermal']].mean()/CurrentAverageLoad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_by_fleet[['nuclear','hydro','thermal']].mean()/dispatch_by_fleet[['nuclear','hydro','thermal']].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute some KPIs for dispatch\n",
    "As I never had a dispatch output file, I didn't have a precise output format for the dispatch to be taken into account by the KPI module.So I chose to take the format of the only example i had: chronics exported by a previous script of Camilo with month by month dispatch chronics. \n",
    "- Download these files to have a format example on Nextcloud: https://nextcloud.artelys.com/nextcloud/s/tFirA3TRXrHeFwC\n",
    "- Careful, this example is for year 2007\n",
    "- We should agree on an output format from dispatch. Maybe you could put it on Nextcloud as an example for me"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have to set \"eco2mix\" as comparison in KPI_INPUT_FOLDER/paramsKPI.json\n",
    "**Images were not designed to be plot on a notebook but to be saved as png or zoomable in IMAGES_FOLDER**. In particular, yearly productions and energy mix are better to watch in their written files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not isSkipKpi:\n",
    "    %%capture\n",
    "\n",
    "    wind_solar_only = False\n",
    "    kpis.main(KPI_INPUT_FOLDER, INPUT_FOLDER, OUTPUT_FOLDER, images_folder, year, CASE, n_scenarios, wind_solar_only, params, loads_charac, prods_charac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III Create an environment with the chronics this time\n",
    "\n",
    "This is to test the environment can be used by grid2op. This is what the \"case118_l2rpn\" will look like for the competitions.\n",
    "\n",
    "**NB** The \"Balthazar code\" is fully compatible with the \"GridStateFromFileWithForecasts\". So it is useful to use this class to load back the data. If the data generation process does not provide the same utilities, it is not a problem to write another class, like \"GridStateFromFileWithForecasts\" that can read its format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct the bug in element 7_4_173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO YOU SHOULD NOT DO THAT BUT BE ABLE TO RUN ALL SCENARIOS IN THE RUNNER.\n",
    "\n",
    "# Chose generated scenario\n",
    "# scenario = 'Scenario_15'\n",
    "# scenario_path = os.path.join(OUTPUT_FOLDER, str(year), scenario)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I can't run from the following cell: can't make the dispatch run on my machine and don't data in the right format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from grid2op.Chronics import Multifolder, GridStateFromFileWithForecasts\n",
    "from grid2op.Parameters import Parameters\n",
    "try:\n",
    "    from lightsim2grid.LightSimBackend import LightSimBackend\n",
    "    backend = LightSimBackend()\n",
    "except:\n",
    "    from grid2op.Backend import PandaPowerBackend\n",
    "    backend = PandaPowerBackend()\n",
    "    print(\"You might need to install the LightSimBackend (provisory name) to gain massive speed up\")\n",
    "# don't disconnect powerline on overflow, the thermal limit are not set for now, it would not make sens\n",
    "param = Parameters()\n",
    "param.init_from_dict({\"NO_OVERFLOW_DISCONNECTION\": True})\n",
    "\n",
    "env = grid2op.make(\"blank\",  # to generate a blank environment\n",
    "                   grid_path=grid_path, # assign it the 118 grid\n",
    "                   chronics_class=Multifolder, # tell it to change nothing (not the most usable environment...)\n",
    "                   data_feeding_kwargs= {\n",
    "                       \"path\": os.path.abspath(dispatch_output_folder), \"gridvalueClass\": GridStateFromFileWithForecasts},\n",
    "                   param=param,\n",
    "                   backend=backend\n",
    "                  )\n",
    "# If you remove the \"GridStateFromFileWithForecasts\", from above, chronics will NOT be loaded properly.\n",
    "# GridStateFromFileWithForecasts is the format used for the competition, so it is mandatory that this works!\n",
    "# WITHOUT ANY MODIFICATIONS\n",
    "\n",
    "# Beside the environment should be able to load all data generated, and not one episode.\n",
    "# so please look in grid2op for compatible formats. This is not a valid format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2op.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Have all the chronics been loaded: {}\".format(len(env.chronics_handler.real_data.subpaths) == n_scenarios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set env thermal limit to 1 by default\n",
    "th_lim = np.ones(env.n_line, dtype=np.float)\n",
    "env.set_thermal_limit(th_lim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we can test that we can use a Runner, store the results, and plot the flows on the powerline for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV Validate the generation process\n",
    "\n",
    "For that we use a runner, that will compute the powerflows with a \"do nothing\" agent, and we prevent it to disconnect any power line, even if they are on overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.Runner import Runner\n",
    "import tempfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "path_data_saved = os.path.join(os.path.abspath(os.path.join(dispatch_output_folder, os.pardir)), 'agent_results', scenario_name)\n",
    "os.makedirs(path_data_saved, exist_ok=True)\n",
    "\n",
    "nb_episode = n_scenarios\n",
    "# nb_episode = n_scenarios\n",
    "#nb_steps = 400\n",
    "runner = Runner(**env.get_params_for_runner())\n",
    "\n",
    "# here you might need to change \"nb_episode\" if you generated more than one scenario\n",
    "# this might really take some times... 4 mins per scenario per week [on one core]\n",
    "res = runner.run(nb_episode=nb_episode, path_save=path_data_saved, pbar=tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $path_data_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can study the results, for example by loading the chronics, extracting prod p, load p etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grid2op.EpisodeData import EpisodeData\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "data_this_episode = EpisodeData.from_disk(path_data_saved, res[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows_a = pd.DataFrame(np.array([obs.a_or for obs in data_this_episode.observations]))\n",
    "loads_p = pd.DataFrame(np.array([obs.load_p for obs in data_this_episode.observations]))\n",
    "prods_p = pd.DataFrame(np.array([obs.prod_p for obs in data_this_episode.observations]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ProdTotal=prods_p.sum(axis=1)\n",
    "ConsoTotal=loads_p.sum(axis=1)\n",
    "Pertes=(ProdTotal-ConsoTotal)/ConsoTotal\n",
    "\n",
    "tauxDePerte=Pertes.mean()\n",
    "Pertes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes the KPI you want with that..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prods_p.iplot(kind='scatter', filename='cufflinks/cf-simple-line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go back to **II)** if results are not satisfying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V Export the final results\n",
    "\n",
    "First, regenerate a lot more data, then save then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO generate more data with the same distribution as the one that has been validated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO export them to be usable in a friendly manner"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "env_for_pypsa"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "diff": [
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "display_name",
       "op": "patch"
      },
      {
       "diff": [
        {
         "key": 0,
         "op": "addrange",
         "valuelist": [
          "rte-challenge"
         ]
        },
        {
         "key": 0,
         "length": 1,
         "op": "removerange"
        }
       ],
       "key": "name",
       "op": "patch"
      }
     ],
     "key": "kernelspec",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
